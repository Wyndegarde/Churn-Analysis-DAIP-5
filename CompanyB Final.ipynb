{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\lewis\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorflow) (3.15.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lewis\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "import random\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyB = pd.read_csv('CompanyBData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below we have no rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                     0\n",
       "Account length            0\n",
       "Area code                 0\n",
       "International plan        0\n",
       "Voice mail plan           0\n",
       "Number vmail messages     0\n",
       "Total day minutes         0\n",
       "Total day calls           0\n",
       "Total day charge          0\n",
       "Total eve minutes         0\n",
       "Total eve calls           0\n",
       "Total eve charge          0\n",
       "Total night minutes       0\n",
       "Total night calls         0\n",
       "Total night charge        0\n",
       "Total intl minutes        0\n",
       "Total intl calls          0\n",
       "Total intl charge         0\n",
       "Customer service calls    0\n",
       "Churn                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyB.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count how many unique values are in state and area code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                       51\n",
       "Account length             212\n",
       "Area code                    3\n",
       "International plan           2\n",
       "Voice mail plan              2\n",
       "Number vmail messages       46\n",
       "Total day minutes         1667\n",
       "Total day calls            119\n",
       "Total day charge          1667\n",
       "Total eve minutes         1611\n",
       "Total eve calls            123\n",
       "Total eve charge          1440\n",
       "Total night minutes       1591\n",
       "Total night calls          120\n",
       "Total night charge         933\n",
       "Total intl minutes         162\n",
       "Total intl calls            21\n",
       "Total intl charge          162\n",
       "Customer service calls      10\n",
       "Churn                        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyB.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasons for customers leaving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "There are a total of 3333 customers and 483 are churn giving a 14.49% churn rate\n",
    "\n",
    "Does churn vary by state, area code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  Account length  Area code  International plan  Voice mail plan  \\\n",
       "Churn                                                                          \n",
       "False   2850            2850       2850                2850             2850   \n",
       "True     483             483        483                 483              483   \n",
       "\n",
       "       Number vmail messages  Total day minutes  Total day calls  \\\n",
       "Churn                                                              \n",
       "False                   2850               2850             2850   \n",
       "True                     483                483              483   \n",
       "\n",
       "       Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "Churn                                                                           \n",
       "False              2850               2850             2850              2850   \n",
       "True                483                483              483               483   \n",
       "\n",
       "       Total night minutes  Total night calls  Total night charge  \\\n",
       "Churn                                                               \n",
       "False                 2850               2850                2850   \n",
       "True                   483                483                 483   \n",
       "\n",
       "       Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "Churn                                                            \n",
       "False                2850              2850               2850   \n",
       "True                  483               483                483   \n",
       "\n",
       "       Customer service calls  \n",
       "Churn                          \n",
       "False                    2850  \n",
       "True                      483  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyB.groupby(['Churn']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States churn rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x25c1e2e55e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "states_churn = companyB.groupby(['State'])['Churn'].mean().copy()\n",
    "states_churn_plot = states_churn.plot.bar(figsize=(16, 12))\n",
    "states_churn_plot.axhline(y=0.1449, color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like state is an important variable when determining churn, would be worth adding to model. Perhaps could replace state column values with the churn rate of each state in order to keep it to one column ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area code churn rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area code\n",
       "408    0.145585\n",
       "415    0.142598\n",
       "510    0.148810\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyB.groupby(['Area code'])['Churn'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churn rate does not appear to vary by area code and so we can reasonably conclude this variable is not important and will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean variables\n",
    "\n",
    "Does churn rate vary depending on whether customer has international plan or voice mail plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### International plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Churn rate')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x25c1e2c9e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bools_churn = companyB[['International plan', 'Voice mail plan', 'Churn']]\n",
    "\n",
    "int_plan_plot = bools_churn.groupby(['International plan'])['Churn'].mean().plot.bar(y='Churn rate',figsize=(8, 6))\n",
    "int_plan_plot.set_ylabel('Churn rate')\n",
    "int_plan_plot.axhline(y=0.1449, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voice mail plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Churn rate')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x25c697ba130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "voice_plan_plot = bools_churn.groupby(['Voice mail plan'])['Churn'].mean().plot.bar(y='Churn rate',figsize=(8, 6))\n",
    "voice_plan_plot.set_ylabel('Churn rate')\n",
    "voice_plan_plot.axhline(y=0.1449, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric values\n",
    "\n",
    "Comparing numeric values to churn rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyB_numeric = companyB.copy()\n",
    "companyB_numeric = companyB_numeric.drop(['State', 'Area code', 'International plan','Voice mail plan'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account length</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>100.793684</td>\n",
       "      <td>8.604561</td>\n",
       "      <td>175.175754</td>\n",
       "      <td>100.283158</td>\n",
       "      <td>29.780421</td>\n",
       "      <td>199.043298</td>\n",
       "      <td>100.038596</td>\n",
       "      <td>16.918909</td>\n",
       "      <td>200.133193</td>\n",
       "      <td>100.058246</td>\n",
       "      <td>9.006074</td>\n",
       "      <td>10.158877</td>\n",
       "      <td>4.532982</td>\n",
       "      <td>2.743404</td>\n",
       "      <td>1.449825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>102.664596</td>\n",
       "      <td>5.115942</td>\n",
       "      <td>206.914079</td>\n",
       "      <td>101.335404</td>\n",
       "      <td>35.175921</td>\n",
       "      <td>212.410145</td>\n",
       "      <td>100.561077</td>\n",
       "      <td>18.054969</td>\n",
       "      <td>205.231677</td>\n",
       "      <td>100.399586</td>\n",
       "      <td>9.235528</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>4.163561</td>\n",
       "      <td>2.889545</td>\n",
       "      <td>2.229814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Account length  Number vmail messages  Total day minutes  \\\n",
       "Churn                                                             \n",
       "False      100.793684               8.604561         175.175754   \n",
       "True       102.664596               5.115942         206.914079   \n",
       "\n",
       "       Total day calls  Total day charge  Total eve minutes  Total eve calls  \\\n",
       "Churn                                                                          \n",
       "False       100.283158         29.780421         199.043298       100.038596   \n",
       "True        101.335404         35.175921         212.410145       100.561077   \n",
       "\n",
       "       Total eve charge  Total night minutes  Total night calls  \\\n",
       "Churn                                                             \n",
       "False         16.918909           200.133193         100.058246   \n",
       "True          18.054969           205.231677         100.399586   \n",
       "\n",
       "       Total night charge  Total intl minutes  Total intl calls  \\\n",
       "Churn                                                             \n",
       "False            9.006074           10.158877          4.532982   \n",
       "True             9.235528           10.700000          4.163561   \n",
       "\n",
       "       Total intl charge  Customer service calls  \n",
       "Churn                                             \n",
       "False           2.743404                1.449825  \n",
       "True            2.889545                2.229814  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyB_numeric.groupby('Churn').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andrew Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "International plan\n",
       "No     0.114950\n",
       "Yes    0.424149\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "State\n",
       "AK    0.057692\n",
       "AL    0.100000\n",
       "AR    0.200000\n",
       "AZ    0.062500\n",
       "CA    0.264706\n",
       "CO    0.136364\n",
       "CT    0.162162\n",
       "DC    0.092593\n",
       "DE    0.147541\n",
       "FL    0.126984\n",
       "GA    0.148148\n",
       "HI    0.056604\n",
       "IA    0.068182\n",
       "ID    0.123288\n",
       "IL    0.086207\n",
       "IN    0.126761\n",
       "KS    0.185714\n",
       "KY    0.135593\n",
       "LA    0.078431\n",
       "MA    0.169231\n",
       "MD    0.242857\n",
       "ME    0.209677\n",
       "MI    0.219178\n",
       "MN    0.178571\n",
       "MO    0.111111\n",
       "MS    0.215385\n",
       "MT    0.205882\n",
       "NC    0.161765\n",
       "ND    0.096774\n",
       "NE    0.081967\n",
       "NH    0.160714\n",
       "NJ    0.264706\n",
       "NM    0.096774\n",
       "NV    0.212121\n",
       "NY    0.180723\n",
       "OH    0.128205\n",
       "OK    0.147541\n",
       "OR    0.141026\n",
       "PA    0.177778\n",
       "RI    0.092308\n",
       "SC    0.233333\n",
       "SD    0.133333\n",
       "TN    0.094340\n",
       "TX    0.250000\n",
       "UT    0.138889\n",
       "VA    0.064935\n",
       "VT    0.109589\n",
       "WA    0.212121\n",
       "WI    0.089744\n",
       "WV    0.094340\n",
       "WY    0.116883\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#International plan y/n churn rates\n",
    "bools_churn.groupby(['International plan'])['Churn'].mean()\n",
    "#california and hawaii churn rates\n",
    "companyB.groupby(['State'])['Churn'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yFull = companyB['Churn'].copy()\n",
    "xdirty = companyB.copy()\n",
    "del xdirty['Churn']\n",
    "del xdirty['Area code']\n",
    "del xdirty['International plan']\n",
    "del xdirty['Voice mail plan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort out binary columns (International plan and Voice mail plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = companyB[['International plan','Voice mail plan']].copy()\n",
    "binary_cols['International plan'] = binary_cols['International plan'].map({'No':0, 'Yes':1})\n",
    "binary_cols['Voice mail plan'] = binary_cols['Voice mail plan'].map({'No':0, 'Yes':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming state column to show churn rate for that state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_test = companyB[['State','Churn']]\n",
    "\n",
    "#Turn series into dictionary\n",
    "states_churn = companyB.groupby(['State'])['Churn'].mean().copy()\n",
    "states_churn_dictionary = states_churn.to_dict()\n",
    "xdirty = xdirty.replace({'State':states_churn_dictionary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scale = xdirty.drop('State',axis=1)\n",
    "x_scale_attribs = list(x_scale)\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "x_scale[x_scale_attribs] = std_scaler.fit_transform(x_scale[x_scale_attribs])\n",
    "\n",
    "x_clean = x_scale.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clean = x_clean.join(xdirty['State'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rejoin scaled values with binary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clean = x_clean.join(binary_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert churn values into 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yFull = yFull.map({False:0, True:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join yFull and x_clean then transform into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyB_combined = x_clean.join(yFull).copy()\n",
    "companyB_combined = companyB_combined.to_numpy()\n",
    "companyB_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the array has 19 values per row, one of which being the dependent variable. 3333 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Notes to remember what I've done \n",
    "\n",
    "Added an input for state which inputs the average churn rate for that state (this has intentionally not been scaled as rates are 0-1\n",
    "\n",
    "Added L2 regularisation, this initially decreased accuracy for both training and test, in response I increased epochs however accuracy remains lower. Overfitting does seem to have been reduced as training and test accuracy now very close.\n",
    "\n",
    "Added dropouts but seems to harm performance \n",
    "\n",
    "Changed activation to scaled ELU\n",
    "    Doing so necessitates changing kernal initializer to lecun\n",
    "    then dropped the kernal regluariser as I think selu takes care of this\n",
    "    resulted in solid improvment of the model\n",
    "    Seems to have reintroduced problem of overfitting\n",
    "    \n",
    "To do:\n",
    "\n",
    "Implementing batch normalisation with Keras page 447\n",
    "    Just add a BatchNormalization layer before or after each hidden layers activation function, and optionally add a BN layer as well as the first layer in your model\n",
    "    \n",
    "Adding dropout back with selu activation results in 93% accuracy and minimal overfitting (increased epochs can yield 94%)\n",
    "\n",
    "Keras model was wrapped in an object which allows for hyperparameter tuning via gridsearch or randomziedsearch\n",
    "\n",
    "Will use randomizeed search due to the number of potential parameters \n",
    "    Bergstra and Bengio published an amazing paper where they demonstrated the inefficiency of Grid Search.\n",
    "\n",
    "Results of function with (n_hidden=3, n_neurons = 100, input_shape=[18], learn=3e-3, dropout_rate=0.05):\n",
    "    95.5% accuracy on comfusion matrix\n",
    "    \n",
    "    \n",
    "Implementing class weights to determine how much they improve recall and how that compares with loss of accuracy\n",
    "    This seems to incur slight overfitting without really improving recall\n",
    "    \n",
    "Following on from above, could try using loss weights which sounds similiar but is a little different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2733, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(600, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3333 values so say 600 are test and then 300 are validation\n",
    "\n",
    "testFull = companyB_combined[:600].copy()\n",
    "trainFull = companyB_combined[600:].copy()\n",
    "#validationFull = companyB_combined[3000:].copy()\n",
    "trainFull.shape\n",
    "testFull.shape\n",
    "\n",
    "\n",
    "xTest = testFull[:,0:18]\n",
    "yTest = testFull[:,18]\n",
    "\n",
    "xTrain = trainFull[:,0:18]\n",
    "yTrain = trainFull[:,18]\n",
    "\n",
    "#xValidation = validationFull[:,0:17]\n",
    "#yValidation = validationFull[:,17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 2s 3ms/step - loss: 0.4246 - accuracy: 0.8203 - val_loss: 0.2407 - val_accuracy: 0.8967\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4298 - accuracy: 0.8309 - val_loss: 0.2968 - val_accuracy: 0.8767\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.8067 - val_loss: 0.2902 - val_accuracy: 0.8750\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4330 - accuracy: 0.8097 - val_loss: 0.2537 - val_accuracy: 0.8933\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4156 - accuracy: 0.8275 - val_loss: 0.2654 - val_accuracy: 0.8950\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4118 - accuracy: 0.8407 - val_loss: 0.2678 - val_accuracy: 0.8950\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4025 - accuracy: 0.8269 - val_loss: 0.2486 - val_accuracy: 0.9067\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4381 - accuracy: 0.8093 - val_loss: 0.2611 - val_accuracy: 0.9017\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4245 - accuracy: 0.8162 - val_loss: 0.2959 - val_accuracy: 0.8817\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4042 - accuracy: 0.8237 - val_loss: 0.2482 - val_accuracy: 0.9083\n"
     ]
    }
   ],
   "source": [
    "#Create empty arrays to hold metrics\n",
    "train_accuracy_array = []\n",
    "train_recall_array = []\n",
    "train_precision_array = []\n",
    "\n",
    "test_accuracy_array = []\n",
    "test_recall_array = []\n",
    "test_precision_array = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    def build_model(n_hidden=3, n_neurons = 30, learn=3e-3, dropout_rate=0.04):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.InputLayer(input_shape=[18]))\n",
    "        for layer in range(n_hidden):\n",
    "            model.add(keras.layers.Dropout(dropout_rate))\n",
    "            model.add(keras.layers.Dense(n_neurons, activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "        model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "        opt = keras.optimizers.Nadam(learning_rate=learn)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    keras_classifier = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "    early_stopping = EarlyStopping(patience = 20, restore_best_weights=True)\n",
    "    model = keras_classifier.fit(xTrain, yTrain, epochs=1, batch_size=8,validation_data=(xTest, yTest),callbacks=[early_stopping])\n",
    "    \n",
    "    #get predictions for xtrain and x test\n",
    "    y_pred_train = keras_classifier.predict(xTrain)\n",
    "    y_pred_test = keras_classifier.predict(xTest)\n",
    "    \n",
    "    #Get metrics\n",
    "    train_acc = accuracy_score(yTrain , np.rint(y_pred_train))*100\n",
    "    train_recall = recall_score(yTrain , np.rint(y_pred_train))\n",
    "    train_prec = precision_score(yTrain , np.rint(y_pred_train))*100\n",
    "    \n",
    "    test_acc = accuracy_score(yTest , np.rint(y_pred_test))*100\n",
    "    test_recall = recall_score(yTest , np.rint(y_pred_test))\n",
    "    test_prec = precision_score(yTest , np.rint(y_pred_test))*100\n",
    "    \n",
    "    #Insert metrics into relevant arrays\n",
    "    train_accuracy_array.append(train_acc)\n",
    "    train_recall_array.append(train_recall)\n",
    "    train_precision_array.append(train_prec)\n",
    "    \n",
    "    test_accuracy_array.append(test_acc)\n",
    "    test_recall_array.append(test_recall)\n",
    "    test_precision_array.append(test_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get average of each metric from base NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to get the average of a list\n",
    "def avg_list(x):\n",
    "    return sum(x) / len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train accuracy: 90.09879253567509\n",
      "Mean train recall: 0.44961832061068707\n",
      "Mean train precision: 76.99954914867632\n",
      "Mean test accuracy: 89.29999999999998\n",
      "Mean test recall: 0.4211111111111111\n",
      "Mean test precision: 76.21465732543498\n"
     ]
    }
   ],
   "source": [
    "print('Mean train accuracy: ' + str(avg_list(train_accuracy_array)))\n",
    "print('Mean train recall: ' + str(avg_list(train_recall_array)))\n",
    "print('Mean train precision: ' + str(avg_list(train_precision_array)))\n",
    "\n",
    "print('Mean test accuracy: ' + str(avg_list(test_accuracy_array)))\n",
    "print('Mean test recall: ' + str(avg_list(test_recall_array)))\n",
    "print('Mean test precision: ' + str(avg_list(test_precision_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "model = KerasClassifier(build_fn=build_model) \n",
    "\n",
    "# Specify parameters and distributions\n",
    "n_hidden =range(10)\n",
    "n_neurons = range(300)\n",
    "\n",
    "#Prepare dictionary for search\n",
    "param_dist = dict(n_hidden=n_hidden, n_neurons=n_neurons)\n",
    "\n",
    "#Search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(estimator=model, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=1, \n",
    "\t\t\t\t\t\t\t\t   verbose=1)\n",
    "\n",
    "#early_stopping = EarlyStopping(patience = 20, restore_best_weights=True)\n",
    "#model = model.fit(xTrain, yTrain, epochs=100, batch_size=8,validation_data=(xTest, yTest),callbacks=[early_stopping])\n",
    "\n",
    "random_search.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics, Confusion matrices and learning curves\n",
    "\n",
    "These metrics are for last model loop above\n",
    "\n",
    "We argue that the most important part of the confusion matrix is the bottom left corner which shows churn that was not identified as these are customers lost, top right shows non-churn who were mistaken for churn (and so perhaps sent a deal) however the cost of this is worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2267,   73],\n",
       "       [ 173,  220]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 90.99890230515916\n",
      "Train recall: 0.5597964376590331\n",
      "Train precision: 75.0853242320819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[493,  17],\n",
       "       [ 38,  52]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 90.83333333333333\n",
      "Test recall: 0.5777777777777777\n",
      "Test precision: 75.36231884057972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cc90cf9ac0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix for train\n",
    "y_pred_train = keras_classifier.predict(xTrain)\n",
    "confusion_matrix_train = sklearn.metrics.confusion_matrix(yTrain, np.rint(y_pred_train))\n",
    "confusion_matrix_train\n",
    "\n",
    "\n",
    "print('Train accuracy: ' + str(accuracy_score(yTrain , np.rint(y_pred_train))*100))\n",
    "print('Train recall: ' + str(recall_score(yTrain , np.rint(y_pred_train))))\n",
    "print('Train precision: ' + str(precision_score(yTrain , np.rint(y_pred_train))*100))\n",
    "\n",
    "\n",
    "# Confusion matrix for test\n",
    "y_pred = keras_classifier.predict(xTest)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(yTest, np.rint(y_pred))\n",
    "confusion_matrix\n",
    "\n",
    "print('Test accuracy: ' + str(accuracy_score(yTest, np.rint(y_pred))*100))\n",
    "print('Test recall: ' + str(recall_score(yTest, np.rint(y_pred))))\n",
    "print('Test precision: ' + str(precision_score(yTest , np.rint(y_pred))*100))\n",
    "\n",
    "#Learning curves\n",
    "pd.DataFrame(model.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0617 - accuracy: 0.6807 - val_loss: 0.4298 - val_accuracy: 0.8100\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 748us/step - loss: 0.8493 - accuracy: 0.7892 - val_loss: 0.3545 - val_accuracy: 0.8583\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.7234 - accuracy: 0.8403 - val_loss: 0.3585 - val_accuracy: 0.8800\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.7301 - accuracy: 0.8412 - val_loss: 0.3864 - val_accuracy: 0.8600\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 760us/step - loss: 0.6601 - accuracy: 0.8588 - val_loss: 0.4066 - val_accuracy: 0.8450\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.6404 - accuracy: 0.8566 - val_loss: 0.4294 - val_accuracy: 0.8450\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.6851 - accuracy: 0.8498 - val_loss: 0.2734 - val_accuracy: 0.8900\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.5450 - accuracy: 0.8762 - val_loss: 0.3604 - val_accuracy: 0.8650\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.6216 - accuracy: 0.8655 - val_loss: 0.3612 - val_accuracy: 0.8650\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.6536 - accuracy: 0.8630 - val_loss: 0.3249 - val_accuracy: 0.8967\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5946 - accuracy: 0.8906 - val_loss: 0.3382 - val_accuracy: 0.8817\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.5900 - accuracy: 0.8821 - val_loss: 0.3282 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.5907 - accuracy: 0.8755 - val_loss: 0.2777 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5861 - accuracy: 0.8885 - val_loss: 0.3828 - val_accuracy: 0.8600\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.5832 - accuracy: 0.8891 - val_loss: 0.3034 - val_accuracy: 0.9033\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.5967 - accuracy: 0.8764 - val_loss: 0.2499 - val_accuracy: 0.9100\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 748us/step - loss: 0.5606 - accuracy: 0.9000 - val_loss: 0.3139 - val_accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.5817 - accuracy: 0.8828 - val_loss: 0.2828 - val_accuracy: 0.9067\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5757 - accuracy: 0.8989 - val_loss: 0.3007 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.5337 - accuracy: 0.9025 - val_loss: 0.3164 - val_accuracy: 0.8900\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.5672 - accuracy: 0.8930 - val_loss: 0.4315 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.5993 - accuracy: 0.8751 - val_loss: 0.2846 - val_accuracy: 0.9133\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.5478 - accuracy: 0.9019 - val_loss: 0.2790 - val_accuracy: 0.9117\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 711us/step - loss: 0.5435 - accuracy: 0.8840 - val_loss: 0.3236 - val_accuracy: 0.8833\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5979 - accuracy: 0.8774 - val_loss: 0.2751 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 738us/step - loss: 0.5279 - accuracy: 0.9005 - val_loss: 0.2635 - val_accuracy: 0.9100\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.5294 - accuracy: 0.8920 - val_loss: 0.2604 - val_accuracy: 0.9150\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.5288 - accuracy: 0.8964 - val_loss: 0.3387 - val_accuracy: 0.8917\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.4763 - accuracy: 0.9087 - val_loss: 0.3323 - val_accuracy: 0.8817\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5018 - accuracy: 0.8945 - val_loss: 0.2713 - val_accuracy: 0.9133\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.5211 - accuracy: 0.8994 - val_loss: 0.2551 - val_accuracy: 0.9167\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.5485 - accuracy: 0.9055 - val_loss: 0.2579 - val_accuracy: 0.9150\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4975 - accuracy: 0.9026 - val_loss: 0.2620 - val_accuracy: 0.9217\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.4828 - accuracy: 0.9002 - val_loss: 0.3847 - val_accuracy: 0.8533\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5437 - accuracy: 0.8858 - val_loss: 0.2757 - val_accuracy: 0.8983\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.4692 - accuracy: 0.9026 - val_loss: 0.2631 - val_accuracy: 0.9100\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0600 - accuracy: 0.6702 - val_loss: 0.4301 - val_accuracy: 0.8133\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 714us/step - loss: 0.8488 - accuracy: 0.7689 - val_loss: 0.3822 - val_accuracy: 0.8450\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 704us/step - loss: 0.7679 - accuracy: 0.8174 - val_loss: 0.4065 - val_accuracy: 0.8450\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 742us/step - loss: 0.7278 - accuracy: 0.8142 - val_loss: 0.3949 - val_accuracy: 0.8617\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.7200 - accuracy: 0.8210 - val_loss: 0.3634 - val_accuracy: 0.8717\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.7010 - accuracy: 0.8378 - val_loss: 0.3711 - val_accuracy: 0.8517\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 718us/step - loss: 0.7069 - accuracy: 0.8487 - val_loss: 0.2776 - val_accuracy: 0.8967\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.7825 - accuracy: 0.8372 - val_loss: 0.3870 - val_accuracy: 0.8367\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 732us/step - loss: 0.6162 - accuracy: 0.8600 - val_loss: 0.3533 - val_accuracy: 0.8683\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.6724 - accuracy: 0.8560 - val_loss: 0.2728 - val_accuracy: 0.8950\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 710us/step - loss: 0.6185 - accuracy: 0.8784 - val_loss: 0.3204 - val_accuracy: 0.8700\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.6215 - accuracy: 0.8559 - val_loss: 0.2476 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 697us/step - loss: 0.6131 - accuracy: 0.8831 - val_loss: 0.3034 - val_accuracy: 0.8933\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.6362 - accuracy: 0.8635 - val_loss: 0.3854 - val_accuracy: 0.8583\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 716us/step - loss: 0.5662 - accuracy: 0.8839 - val_loss: 0.4745 - val_accuracy: 0.7850\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 735us/step - loss: 0.6119 - accuracy: 0.8533 - val_loss: 0.3345 - val_accuracy: 0.8883\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 689us/step - loss: 0.5933 - accuracy: 0.8779 - val_loss: 0.3877 - val_accuracy: 0.8450\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.6073 - accuracy: 0.8819 - val_loss: 0.3247 - val_accuracy: 0.8917\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 720us/step - loss: 0.5391 - accuracy: 0.8870 - val_loss: 0.2958 - val_accuracy: 0.9067\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 756us/step - loss: 0.6270 - accuracy: 0.8733 - val_loss: 0.4417 - val_accuracy: 0.8250\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 707us/step - loss: 0.5354 - accuracy: 0.8818 - val_loss: 0.2614 - val_accuracy: 0.9200\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6180 - accuracy: 0.8861 - val_loss: 0.3555 - val_accuracy: 0.8617\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.5720 - accuracy: 0.8797 - val_loss: 0.2936 - val_accuracy: 0.8950\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.6116 - accuracy: 0.8780 - val_loss: 0.2380 - val_accuracy: 0.9250\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.6064 - accuracy: 0.8902 - val_loss: 0.2854 - val_accuracy: 0.9133\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.5971 - accuracy: 0.8854 - val_loss: 0.3068 - val_accuracy: 0.8900\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 729us/step - loss: 0.5983 - accuracy: 0.8933 - val_loss: 0.2712 - val_accuracy: 0.9217\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 741us/step - loss: 0.4777 - accuracy: 0.9075 - val_loss: 0.3216 - val_accuracy: 0.9050\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.5249 - accuracy: 0.8925 - val_loss: 0.2725 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 747us/step - loss: 0.5473 - accuracy: 0.8980 - val_loss: 0.2686 - val_accuracy: 0.9050\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.5582 - accuracy: 0.8951 - val_loss: 0.2868 - val_accuracy: 0.9083\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 730us/step - loss: 0.5041 - accuracy: 0.9114 - val_loss: 0.2593 - val_accuracy: 0.9133\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.4796 - accuracy: 0.9150 - val_loss: 0.3040 - val_accuracy: 0.8950\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5040 - accuracy: 0.9098 - val_loss: 0.3130 - val_accuracy: 0.8883\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4992 - accuracy: 0.9051 - val_loss: 0.2820 - val_accuracy: 0.9067\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4830 - accuracy: 0.9056 - val_loss: 0.2773 - val_accuracy: 0.9033\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.5425 - accuracy: 0.9020 - val_loss: 0.2812 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.4820 - accuracy: 0.9026 - val_loss: 0.2645 - val_accuracy: 0.9217\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.9118 - val_loss: 0.3269 - val_accuracy: 0.8783\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5632 - accuracy: 0.8905 - val_loss: 0.2428 - val_accuracy: 0.9233\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.5020 - accuracy: 0.9058 - val_loss: 0.2717 - val_accuracy: 0.9167\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.4658 - accuracy: 0.9128 - val_loss: 0.2618 - val_accuracy: 0.9217\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.5379 - accuracy: 0.9016 - val_loss: 0.3422 - val_accuracy: 0.8867\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.4475 - accuracy: 0.9159 - val_loss: 0.2629 - val_accuracy: 0.9183\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0537 - accuracy: 0.6724 - val_loss: 0.5436 - val_accuracy: 0.7367\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 710us/step - loss: 0.7483 - accuracy: 0.7963 - val_loss: 0.4284 - val_accuracy: 0.8067\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.7701 - accuracy: 0.7932 - val_loss: 0.3524 - val_accuracy: 0.8517\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 704us/step - loss: 0.7776 - accuracy: 0.8188 - val_loss: 0.3675 - val_accuracy: 0.8533\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.7382 - accuracy: 0.8238 - val_loss: 0.3299 - val_accuracy: 0.8783\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 713us/step - loss: 0.7636 - accuracy: 0.8192 - val_loss: 0.3408 - val_accuracy: 0.8467\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.6740 - accuracy: 0.8390 - val_loss: 0.4338 - val_accuracy: 0.8150\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 703us/step - loss: 0.6768 - accuracy: 0.8400 - val_loss: 0.3377 - val_accuracy: 0.8800\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.5905 - accuracy: 0.8733 - val_loss: 0.4926 - val_accuracy: 0.7650\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.6810 - accuracy: 0.8357 - val_loss: 0.3295 - val_accuracy: 0.8833\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.6526 - accuracy: 0.8604 - val_loss: 0.4670 - val_accuracy: 0.7700\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 708us/step - loss: 0.6370 - accuracy: 0.8419 - val_loss: 0.3007 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6279 - accuracy: 0.8633 - val_loss: 0.3143 - val_accuracy: 0.8933\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.6886 - accuracy: 0.8718 - val_loss: 0.3294 - val_accuracy: 0.8783\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.6349 - accuracy: 0.8816 - val_loss: 0.3023 - val_accuracy: 0.8883\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.6135 - accuracy: 0.8691 - val_loss: 0.2730 - val_accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5828 - accuracy: 0.8947 - val_loss: 0.2613 - val_accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5784 - accuracy: 0.8841 - val_loss: 0.3456 - val_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 737us/step - loss: 0.5253 - accuracy: 0.8899 - val_loss: 0.3017 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 743us/step - loss: 0.5335 - accuracy: 0.8966 - val_loss: 0.3239 - val_accuracy: 0.8733\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 726us/step - loss: 0.5123 - accuracy: 0.8990 - val_loss: 0.3449 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 738us/step - loss: 0.6119 - accuracy: 0.8695 - val_loss: 0.2750 - val_accuracy: 0.9167\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 738us/step - loss: 0.5045 - accuracy: 0.9051 - val_loss: 0.3197 - val_accuracy: 0.8917\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.5778 - accuracy: 0.8792 - val_loss: 0.3991 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5119 - accuracy: 0.8983 - val_loss: 0.3024 - val_accuracy: 0.8783\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.5397 - accuracy: 0.8931 - val_loss: 0.2571 - val_accuracy: 0.9067\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.4779 - accuracy: 0.9171 - val_loss: 0.2962 - val_accuracy: 0.9083\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 739us/step - loss: 0.5946 - accuracy: 0.8734 - val_loss: 0.2370 - val_accuracy: 0.9383\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 741us/step - loss: 0.4866 - accuracy: 0.9157 - val_loss: 0.3062 - val_accuracy: 0.8967\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.5203 - accuracy: 0.8855 - val_loss: 0.2507 - val_accuracy: 0.9067\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.5746 - accuracy: 0.8785 - val_loss: 0.2897 - val_accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.5006 - accuracy: 0.8947 - val_loss: 0.3030 - val_accuracy: 0.9200\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.4466 - accuracy: 0.9027 - val_loss: 0.4019 - val_accuracy: 0.8167\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.5071 - accuracy: 0.8821 - val_loss: 0.2999 - val_accuracy: 0.8917\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5438 - accuracy: 0.8934 - val_loss: 0.2185 - val_accuracy: 0.9267\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.4479 - accuracy: 0.9082 - val_loss: 0.2900 - val_accuracy: 0.9117\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 739us/step - loss: 0.5281 - accuracy: 0.8929 - val_loss: 0.2450 - val_accuracy: 0.9283\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5039 - accuracy: 0.9113 - val_loss: 0.2074 - val_accuracy: 0.9450\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.5061 - accuracy: 0.9070 - val_loss: 0.2703 - val_accuracy: 0.9117\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.4653 - accuracy: 0.9148 - val_loss: 0.2954 - val_accuracy: 0.8933\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.4949 - accuracy: 0.9001 - val_loss: 0.2492 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 726us/step - loss: 0.5043 - accuracy: 0.8969 - val_loss: 0.2630 - val_accuracy: 0.9117\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.4776 - accuracy: 0.9067 - val_loss: 0.3199 - val_accuracy: 0.8833\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.4629 - accuracy: 0.9136 - val_loss: 0.2363 - val_accuracy: 0.9133\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.4978 - accuracy: 0.9069 - val_loss: 0.2573 - val_accuracy: 0.9083\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 716us/step - loss: 0.4979 - accuracy: 0.9122 - val_loss: 0.2214 - val_accuracy: 0.9267\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.4560 - accuracy: 0.9141 - val_loss: 0.2878 - val_accuracy: 0.8900\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.4233 - accuracy: 0.9159 - val_loss: 0.3454 - val_accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5473 - accuracy: 0.8718 - val_loss: 0.3805 - val_accuracy: 0.8417\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.4584 - accuracy: 0.9145 - val_loss: 0.2956 - val_accuracy: 0.8867\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 900us/step - loss: 0.4597 - accuracy: 0.9062 - val_loss: 0.2751 - val_accuracy: 0.9050\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.4011 - accuracy: 0.9183 - val_loss: 0.2483 - val_accuracy: 0.9133\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.4377 - accuracy: 0.9297 - val_loss: 0.2897 - val_accuracy: 0.8933\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.3931 - accuracy: 0.9116 - val_loss: 0.2912 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 742us/step - loss: 0.4371 - accuracy: 0.9051 - val_loss: 0.2053 - val_accuracy: 0.9283\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 730us/step - loss: 0.5304 - accuracy: 0.8898 - val_loss: 0.2181 - val_accuracy: 0.9233\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 716us/step - loss: 0.4737 - accuracy: 0.9071 - val_loss: 0.2915 - val_accuracy: 0.8833\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.4411 - accuracy: 0.9061 - val_loss: 0.2427 - val_accuracy: 0.9133\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.4611 - accuracy: 0.9143 - val_loss: 0.2220 - val_accuracy: 0.9233\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.4329 - accuracy: 0.9154 - val_loss: 0.1941 - val_accuracy: 0.9383\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 715us/step - loss: 0.4096 - accuracy: 0.9177 - val_loss: 0.3393 - val_accuracy: 0.8567\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.4179 - accuracy: 0.9017 - val_loss: 0.2434 - val_accuracy: 0.9067\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 716us/step - loss: 0.4539 - accuracy: 0.9174 - val_loss: 0.2452 - val_accuracy: 0.9183\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 742us/step - loss: 0.4596 - accuracy: 0.9088 - val_loss: 0.2561 - val_accuracy: 0.9133\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 708us/step - loss: 0.4040 - accuracy: 0.9261 - val_loss: 0.2559 - val_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4108 - accuracy: 0.9181 - val_loss: 0.2675 - val_accuracy: 0.8983\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.3811 - accuracy: 0.9184 - val_loss: 0.2808 - val_accuracy: 0.8783\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.3877 - accuracy: 0.9227 - val_loss: 0.2558 - val_accuracy: 0.9050\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 718us/step - loss: 0.4649 - accuracy: 0.9006 - val_loss: 0.2367 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.3949 - accuracy: 0.9250 - val_loss: 0.2537 - val_accuracy: 0.9017\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 710us/step - loss: 0.3724 - accuracy: 0.9248 - val_loss: 0.2254 - val_accuracy: 0.9283\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.3762 - accuracy: 0.9380 - val_loss: 0.2566 - val_accuracy: 0.9083\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 720us/step - loss: 0.3869 - accuracy: 0.9262 - val_loss: 0.2028 - val_accuracy: 0.9367\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.3661 - accuracy: 0.9342 - val_loss: 0.2655 - val_accuracy: 0.8983\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 707us/step - loss: 0.4563 - accuracy: 0.9062 - val_loss: 0.2253 - val_accuracy: 0.9267\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 748us/step - loss: 0.4503 - accuracy: 0.9045 - val_loss: 0.2342 - val_accuracy: 0.9133\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.4293 - accuracy: 0.9220 - val_loss: 0.2378 - val_accuracy: 0.9150\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.4145 - accuracy: 0.9153 - val_loss: 0.2398 - val_accuracy: 0.9167\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 709us/step - loss: 0.4518 - accuracy: 0.9180 - val_loss: 0.2602 - val_accuracy: 0.9083\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4240 - accuracy: 0.9233 - val_loss: 0.2174 - val_accuracy: 0.9283\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0176 - accuracy: 0.6972 - val_loss: 0.4364 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.8154 - accuracy: 0.7808 - val_loss: 0.3806 - val_accuracy: 0.8600\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.7892 - accuracy: 0.8260 - val_loss: 0.4150 - val_accuracy: 0.8400\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.6994 - accuracy: 0.8323 - val_loss: 0.3549 - val_accuracy: 0.8533\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.6996 - accuracy: 0.8360 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.6896 - accuracy: 0.8575 - val_loss: 0.4119 - val_accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.6889 - accuracy: 0.8569 - val_loss: 0.3059 - val_accuracy: 0.8983\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 713us/step - loss: 0.6817 - accuracy: 0.8542 - val_loss: 0.3465 - val_accuracy: 0.8867\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 720us/step - loss: 0.6849 - accuracy: 0.8569 - val_loss: 0.3150 - val_accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.6428 - accuracy: 0.8574 - val_loss: 0.3734 - val_accuracy: 0.8617\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.6792 - accuracy: 0.8502 - val_loss: 0.3375 - val_accuracy: 0.8767\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.6750 - accuracy: 0.8545 - val_loss: 0.3321 - val_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 739us/step - loss: 0.6209 - accuracy: 0.8785 - val_loss: 0.2790 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 740us/step - loss: 0.6533 - accuracy: 0.8714 - val_loss: 0.2926 - val_accuracy: 0.8950\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.6013 - accuracy: 0.8914 - val_loss: 0.3031 - val_accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.6373 - accuracy: 0.8673 - val_loss: 0.2847 - val_accuracy: 0.9067\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.5663 - accuracy: 0.8787 - val_loss: 0.3241 - val_accuracy: 0.8933\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5620 - accuracy: 0.8901 - val_loss: 0.2859 - val_accuracy: 0.9083\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.6732 - accuracy: 0.8731 - val_loss: 0.3224 - val_accuracy: 0.8800\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 743us/step - loss: 0.6570 - accuracy: 0.8663 - val_loss: 0.2410 - val_accuracy: 0.9250\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.5605 - accuracy: 0.9091 - val_loss: 0.2794 - val_accuracy: 0.8983\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 741us/step - loss: 0.5614 - accuracy: 0.9022 - val_loss: 0.2926 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.5198 - accuracy: 0.8991 - val_loss: 0.3673 - val_accuracy: 0.8767\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.5488 - accuracy: 0.8795 - val_loss: 0.2963 - val_accuracy: 0.9117\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.5338 - accuracy: 0.8989 - val_loss: 0.2804 - val_accuracy: 0.9017\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6125 - accuracy: 0.8856 - val_loss: 0.3249 - val_accuracy: 0.8917\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.8870 - val_loss: 0.3251 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.5014 - accuracy: 0.9029 - val_loss: 0.2169 - val_accuracy: 0.9317\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5226 - accuracy: 0.9023 - val_loss: 0.3043 - val_accuracy: 0.8867\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.5895 - accuracy: 0.8866 - val_loss: 0.2691 - val_accuracy: 0.9117\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5476 - accuracy: 0.8993 - val_loss: 0.2836 - val_accuracy: 0.9050\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.5792 - accuracy: 0.8969 - val_loss: 0.2691 - val_accuracy: 0.9100\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.5366 - accuracy: 0.9033 - val_loss: 0.2446 - val_accuracy: 0.9267\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.5099 - accuracy: 0.9111 - val_loss: 0.2444 - val_accuracy: 0.9183\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.5196 - accuracy: 0.8995 - val_loss: 0.2508 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5428 - accuracy: 0.8985 - val_loss: 0.2384 - val_accuracy: 0.9283\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.5207 - accuracy: 0.8991 - val_loss: 0.2024 - val_accuracy: 0.9400\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.4729 - accuracy: 0.9220 - val_loss: 0.3214 - val_accuracy: 0.8850\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.4851 - accuracy: 0.8967 - val_loss: 0.3589 - val_accuracy: 0.8683\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5038 - accuracy: 0.9028 - val_loss: 0.3409 - val_accuracy: 0.8733\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.4733 - accuracy: 0.8939 - val_loss: 0.2995 - val_accuracy: 0.8967\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4515 - accuracy: 0.9065 - val_loss: 0.2694 - val_accuracy: 0.9133\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.4084 - accuracy: 0.9163 - val_loss: 0.2325 - val_accuracy: 0.9250\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.4560 - accuracy: 0.9031 - val_loss: 0.2396 - val_accuracy: 0.9117\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.4366 - accuracy: 0.9265 - val_loss: 0.2712 - val_accuracy: 0.8983\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.4541 - accuracy: 0.9034 - val_loss: 0.2511 - val_accuracy: 0.9150\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 726us/step - loss: 0.4860 - accuracy: 0.9033 - val_loss: 0.3155 - val_accuracy: 0.8883\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.5005 - accuracy: 0.9047 - val_loss: 0.2415 - val_accuracy: 0.9233\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 708us/step - loss: 0.4801 - accuracy: 0.9189 - val_loss: 0.2350 - val_accuracy: 0.9183\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 713us/step - loss: 0.4123 - accuracy: 0.9255 - val_loss: 0.2613 - val_accuracy: 0.9117\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.4336 - accuracy: 0.9230 - val_loss: 0.2999 - val_accuracy: 0.8783\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 702us/step - loss: 0.4336 - accuracy: 0.9104 - val_loss: 0.2924 - val_accuracy: 0.8933\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.3966 - accuracy: 0.9293 - val_loss: 0.2863 - val_accuracy: 0.8933\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 726us/step - loss: 0.4213 - accuracy: 0.9121 - val_loss: 0.2344 - val_accuracy: 0.9267\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.4507 - accuracy: 0.9096 - val_loss: 0.2150 - val_accuracy: 0.9383\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.4560 - accuracy: 0.9090 - val_loss: 0.2667 - val_accuracy: 0.9117\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 725us/step - loss: 0.4203 - accuracy: 0.9211 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1130 - accuracy: 0.6199 - val_loss: 0.4353 - val_accuracy: 0.7933\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.8333 - accuracy: 0.7866 - val_loss: 0.3662 - val_accuracy: 0.8500\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7641 - accuracy: 0.8336 - val_loss: 0.4029 - val_accuracy: 0.8450\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.6847 - accuracy: 0.8330 - val_loss: 0.3121 - val_accuracy: 0.8867\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.7762 - accuracy: 0.8422 - val_loss: 0.3410 - val_accuracy: 0.8733\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7124 - accuracy: 0.8525 - val_loss: 0.3593 - val_accuracy: 0.8650\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.6865 - accuracy: 0.8374 - val_loss: 0.2987 - val_accuracy: 0.8883\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5847 - accuracy: 0.8845 - val_loss: 0.3944 - val_accuracy: 0.8567\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6539 - accuracy: 0.8507 - val_loss: 0.3403 - val_accuracy: 0.8850\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.6040 - accuracy: 0.8628 - val_loss: 0.3337 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 747us/step - loss: 0.6070 - accuracy: 0.8739 - val_loss: 0.3148 - val_accuracy: 0.8883\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.5979 - accuracy: 0.8695 - val_loss: 0.3708 - val_accuracy: 0.8733\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.6353 - accuracy: 0.8677 - val_loss: 0.3161 - val_accuracy: 0.8850\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5888 - accuracy: 0.8790 - val_loss: 0.2671 - val_accuracy: 0.9083\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5248 - accuracy: 0.8948 - val_loss: 0.2598 - val_accuracy: 0.9083\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.5669 - accuracy: 0.8936 - val_loss: 0.3194 - val_accuracy: 0.8783\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5836 - accuracy: 0.8719 - val_loss: 0.3178 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.5512 - accuracy: 0.8860 - val_loss: 0.3373 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.5104 - accuracy: 0.8895 - val_loss: 0.3019 - val_accuracy: 0.8950\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.5424 - accuracy: 0.8876 - val_loss: 0.3922 - val_accuracy: 0.8450\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.6451 - accuracy: 0.8611 - val_loss: 0.2981 - val_accuracy: 0.8717\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5677 - accuracy: 0.8893 - val_loss: 0.2833 - val_accuracy: 0.8933\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 730us/step - loss: 0.5286 - accuracy: 0.8948 - val_loss: 0.2991 - val_accuracy: 0.8917\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.5104 - accuracy: 0.8952 - val_loss: 0.2981 - val_accuracy: 0.8967\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.8848 - val_loss: 0.3178 - val_accuracy: 0.8833\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.5552 - accuracy: 0.8883 - val_loss: 0.2467 - val_accuracy: 0.9217\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5454 - accuracy: 0.8973 - val_loss: 0.3209 - val_accuracy: 0.8850\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.5047 - accuracy: 0.9088 - val_loss: 0.2141 - val_accuracy: 0.9367\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5537 - accuracy: 0.8954 - val_loss: 0.3172 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5561 - accuracy: 0.8833 - val_loss: 0.2290 - val_accuracy: 0.9183\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.4957 - accuracy: 0.9076 - val_loss: 0.2797 - val_accuracy: 0.8917\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.4532 - accuracy: 0.9062 - val_loss: 0.3019 - val_accuracy: 0.8833\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5321 - accuracy: 0.8976 - val_loss: 0.3168 - val_accuracy: 0.8767\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.4766 - accuracy: 0.9038 - val_loss: 0.2343 - val_accuracy: 0.9167\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5372 - accuracy: 0.8958 - val_loss: 0.2396 - val_accuracy: 0.9117\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4986 - accuracy: 0.8967 - val_loss: 0.2118 - val_accuracy: 0.9300\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.5141 - accuracy: 0.9080 - val_loss: 0.2512 - val_accuracy: 0.9083\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4739 - accuracy: 0.8968 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.4933 - accuracy: 0.9003 - val_loss: 0.3301 - val_accuracy: 0.8683\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.4582 - accuracy: 0.9044 - val_loss: 0.2363 - val_accuracy: 0.9183\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.5094 - accuracy: 0.9033 - val_loss: 0.2513 - val_accuracy: 0.9183\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.4969 - accuracy: 0.9066 - val_loss: 0.3413 - val_accuracy: 0.8583\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.4730 - accuracy: 0.9009 - val_loss: 0.2313 - val_accuracy: 0.9283\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4428 - accuracy: 0.9185 - val_loss: 0.2343 - val_accuracy: 0.9267\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.4951 - accuracy: 0.9097 - val_loss: 0.2188 - val_accuracy: 0.9200\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.4596 - accuracy: 0.9109 - val_loss: 0.2104 - val_accuracy: 0.9300\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.4465 - accuracy: 0.9205 - val_loss: 0.2695 - val_accuracy: 0.9017\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.4314 - accuracy: 0.9064 - val_loss: 0.2299 - val_accuracy: 0.9150\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.4842 - accuracy: 0.9118 - val_loss: 0.2327 - val_accuracy: 0.9217\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4737 - accuracy: 0.9193 - val_loss: 0.2216 - val_accuracy: 0.9283\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4499 - accuracy: 0.9142 - val_loss: 0.3149 - val_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.4670 - accuracy: 0.9016 - val_loss: 0.2690 - val_accuracy: 0.8850\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.4600 - accuracy: 0.9036 - val_loss: 0.2386 - val_accuracy: 0.9117\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.4253 - accuracy: 0.9131 - val_loss: 0.3006 - val_accuracy: 0.8733\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5211 - accuracy: 0.8852 - val_loss: 0.2959 - val_accuracy: 0.8867\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 743us/step - loss: 0.4680 - accuracy: 0.9092 - val_loss: 0.2741 - val_accuracy: 0.8883\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.3693 - accuracy: 0.9218 - val_loss: 0.2834 - val_accuracy: 0.8850\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.3588 - accuracy: 0.9200 - val_loss: 0.2395 - val_accuracy: 0.9100\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.4168 - accuracy: 0.9118 - val_loss: 0.3121 - val_accuracy: 0.8583\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.4558 - accuracy: 0.9097 - val_loss: 0.3228 - val_accuracy: 0.8817\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4583 - accuracy: 0.9051 - val_loss: 0.3591 - val_accuracy: 0.8583\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.3761 - accuracy: 0.9176 - val_loss: 0.3258 - val_accuracy: 0.8917\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.4136 - accuracy: 0.9074 - val_loss: 0.2953 - val_accuracy: 0.8600\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.4375 - accuracy: 0.9068 - val_loss: 0.3176 - val_accuracy: 0.8700\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5066 - accuracy: 0.8980 - val_loss: 0.2493 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.3880 - accuracy: 0.9216 - val_loss: 0.2430 - val_accuracy: 0.9167\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1145 - accuracy: 0.6455 - val_loss: 0.4060 - val_accuracy: 0.8317\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.7931 - accuracy: 0.7952 - val_loss: 0.4696 - val_accuracy: 0.7783\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.7563 - accuracy: 0.8155 - val_loss: 0.4515 - val_accuracy: 0.7983\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.7177 - accuracy: 0.8274 - val_loss: 0.3631 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.6804 - accuracy: 0.8497 - val_loss: 0.3420 - val_accuracy: 0.8750\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.7403 - accuracy: 0.8335 - val_loss: 0.3663 - val_accuracy: 0.8567\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 745us/step - loss: 0.6569 - accuracy: 0.8603 - val_loss: 0.3208 - val_accuracy: 0.8783\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.6386 - accuracy: 0.8668 - val_loss: 0.3678 - val_accuracy: 0.8783\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.6063 - accuracy: 0.8669 - val_loss: 0.3178 - val_accuracy: 0.8767\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6263 - accuracy: 0.8700 - val_loss: 0.2647 - val_accuracy: 0.9083\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 742us/step - loss: 0.5686 - accuracy: 0.8761 - val_loss: 0.3106 - val_accuracy: 0.8933\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.5999 - accuracy: 0.8612 - val_loss: 0.2448 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.8797 - val_loss: 0.3982 - val_accuracy: 0.8517\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.5537 - accuracy: 0.8754 - val_loss: 0.3418 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.5662 - accuracy: 0.8864 - val_loss: 0.3295 - val_accuracy: 0.8833\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 714us/step - loss: 0.5553 - accuracy: 0.8819 - val_loss: 0.3098 - val_accuracy: 0.8800\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.6014 - accuracy: 0.8815 - val_loss: 0.3044 - val_accuracy: 0.8933\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.6110 - accuracy: 0.8895 - val_loss: 0.3005 - val_accuracy: 0.8800\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5662 - accuracy: 0.8988 - val_loss: 0.3915 - val_accuracy: 0.8383\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.5563 - accuracy: 0.8750 - val_loss: 0.2739 - val_accuracy: 0.9083\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5565 - accuracy: 0.8933 - val_loss: 0.2555 - val_accuracy: 0.9117\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.6104 - accuracy: 0.8798 - val_loss: 0.2646 - val_accuracy: 0.9017\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.5477 - accuracy: 0.9011 - val_loss: 0.2759 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5726 - accuracy: 0.8881 - val_loss: 0.2680 - val_accuracy: 0.9183\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5825 - accuracy: 0.8802 - val_loss: 0.2753 - val_accuracy: 0.9033\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 743us/step - loss: 0.6270 - accuracy: 0.8834 - val_loss: 0.2709 - val_accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.5409 - accuracy: 0.8996 - val_loss: 0.2539 - val_accuracy: 0.9250\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5552 - accuracy: 0.9029 - val_loss: 0.3587 - val_accuracy: 0.8700\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.5572 - accuracy: 0.8873 - val_loss: 0.2780 - val_accuracy: 0.9083\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4734 - accuracy: 0.9049 - val_loss: 0.3635 - val_accuracy: 0.8517\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5545 - accuracy: 0.8828 - val_loss: 0.2621 - val_accuracy: 0.9167\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.5225 - accuracy: 0.9057 - val_loss: 0.3123 - val_accuracy: 0.8867\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0947 - accuracy: 0.6392 - val_loss: 0.4749 - val_accuracy: 0.7817\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.8646 - accuracy: 0.7621 - val_loss: 0.4490 - val_accuracy: 0.8117\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7803 - accuracy: 0.7993 - val_loss: 0.3239 - val_accuracy: 0.8917\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.6975 - accuracy: 0.8560 - val_loss: 0.3980 - val_accuracy: 0.8383\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7236 - accuracy: 0.8350 - val_loss: 0.3825 - val_accuracy: 0.8567\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.6306 - accuracy: 0.8576 - val_loss: 0.2971 - val_accuracy: 0.8883\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.6696 - accuracy: 0.8619 - val_loss: 0.3662 - val_accuracy: 0.8550\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5840 - accuracy: 0.8745 - val_loss: 0.3643 - val_accuracy: 0.8650\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.6649 - accuracy: 0.8592 - val_loss: 0.2897 - val_accuracy: 0.9017\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6453 - accuracy: 0.8663 - val_loss: 0.2872 - val_accuracy: 0.8867\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5965 - accuracy: 0.8783 - val_loss: 0.3321 - val_accuracy: 0.8917\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6257 - accuracy: 0.8555 - val_loss: 0.3841 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5637 - accuracy: 0.8764 - val_loss: 0.3056 - val_accuracy: 0.8783\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.6004 - accuracy: 0.8730 - val_loss: 0.2652 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.6622 - accuracy: 0.8816 - val_loss: 0.2896 - val_accuracy: 0.8967\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.6710 - accuracy: 0.8666 - val_loss: 0.2618 - val_accuracy: 0.9083\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.5503 - accuracy: 0.8940 - val_loss: 0.3236 - val_accuracy: 0.8883\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 748us/step - loss: 0.5709 - accuracy: 0.8799 - val_loss: 0.2580 - val_accuracy: 0.9217\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.5636 - accuracy: 0.8885 - val_loss: 0.3360 - val_accuracy: 0.8683\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.6358 - accuracy: 0.8731 - val_loss: 0.2790 - val_accuracy: 0.9117\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5221 - accuracy: 0.8918 - val_loss: 0.3467 - val_accuracy: 0.8817\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.5556 - accuracy: 0.8833 - val_loss: 0.2438 - val_accuracy: 0.9217\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.5715 - accuracy: 0.8938 - val_loss: 0.2634 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5176 - accuracy: 0.9065 - val_loss: 0.2578 - val_accuracy: 0.8983\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.5560 - accuracy: 0.8974 - val_loss: 0.2670 - val_accuracy: 0.8983\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.5622 - accuracy: 0.9017 - val_loss: 0.2913 - val_accuracy: 0.8933\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.5399 - accuracy: 0.8992 - val_loss: 0.3107 - val_accuracy: 0.8967\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5196 - accuracy: 0.9052 - val_loss: 0.2240 - val_accuracy: 0.9217\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.4853 - accuracy: 0.9162 - val_loss: 0.2265 - val_accuracy: 0.9300\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.5140 - accuracy: 0.9052 - val_loss: 0.2377 - val_accuracy: 0.9183\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 720us/step - loss: 0.4795 - accuracy: 0.9120 - val_loss: 0.2306 - val_accuracy: 0.9217\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.5418 - accuracy: 0.8864 - val_loss: 0.2831 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 728us/step - loss: 0.5043 - accuracy: 0.8927 - val_loss: 0.3692 - val_accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.5039 - accuracy: 0.8863 - val_loss: 0.2830 - val_accuracy: 0.9033\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.5035 - accuracy: 0.8850 - val_loss: 0.2832 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.4905 - accuracy: 0.8996 - val_loss: 0.3169 - val_accuracy: 0.8917\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.4668 - accuracy: 0.9079 - val_loss: 0.2438 - val_accuracy: 0.9267\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5063 - accuracy: 0.8961 - val_loss: 0.2188 - val_accuracy: 0.9333\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 747us/step - loss: 0.5369 - accuracy: 0.8911 - val_loss: 0.2371 - val_accuracy: 0.9167\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.5117 - accuracy: 0.9011 - val_loss: 0.2575 - val_accuracy: 0.9167\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.5072 - accuracy: 0.8910 - val_loss: 0.2936 - val_accuracy: 0.8867\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.4121 - accuracy: 0.9120 - val_loss: 0.3471 - val_accuracy: 0.8500\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 732us/step - loss: 0.4345 - accuracy: 0.9067 - val_loss: 0.2900 - val_accuracy: 0.8983\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.4473 - accuracy: 0.8984 - val_loss: 0.1994 - val_accuracy: 0.9450\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.4377 - accuracy: 0.9188 - val_loss: 0.2352 - val_accuracy: 0.9083\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.5054 - accuracy: 0.8941 - val_loss: 0.3293 - val_accuracy: 0.8883\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 730us/step - loss: 0.4371 - accuracy: 0.9167 - val_loss: 0.3370 - val_accuracy: 0.8550\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.4809 - accuracy: 0.8916 - val_loss: 0.1879 - val_accuracy: 0.9367\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 723us/step - loss: 0.4637 - accuracy: 0.9127 - val_loss: 0.2580 - val_accuracy: 0.9183\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.3906 - accuracy: 0.9213 - val_loss: 0.2245 - val_accuracy: 0.9333\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.5105 - accuracy: 0.8919 - val_loss: 0.1914 - val_accuracy: 0.9400\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.5319 - accuracy: 0.9000 - val_loss: 0.2088 - val_accuracy: 0.9367\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 728us/step - loss: 0.4086 - accuracy: 0.9277 - val_loss: 0.2882 - val_accuracy: 0.9050\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.4677 - accuracy: 0.9051 - val_loss: 0.2880 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.5318 - accuracy: 0.8981 - val_loss: 0.2025 - val_accuracy: 0.9283\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5354 - accuracy: 0.9050 - val_loss: 0.2424 - val_accuracy: 0.9300\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.4248 - accuracy: 0.9225 - val_loss: 0.2104 - val_accuracy: 0.9350\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4126 - accuracy: 0.9075 - val_loss: 0.3399 - val_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 733us/step - loss: 0.4178 - accuracy: 0.9157 - val_loss: 0.2557 - val_accuracy: 0.9083\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4848 - accuracy: 0.9072 - val_loss: 0.2434 - val_accuracy: 0.9050\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 735us/step - loss: 0.4748 - accuracy: 0.9145 - val_loss: 0.2239 - val_accuracy: 0.9383\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 745us/step - loss: 0.3998 - accuracy: 0.9128 - val_loss: 0.2690 - val_accuracy: 0.9117\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4238 - accuracy: 0.9118 - val_loss: 0.2005 - val_accuracy: 0.9383\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.4507 - accuracy: 0.9220 - val_loss: 0.2724 - val_accuracy: 0.9067\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 732us/step - loss: 0.3437 - accuracy: 0.9319 - val_loss: 0.1911 - val_accuracy: 0.9317\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 732us/step - loss: 0.3532 - accuracy: 0.9310 - val_loss: 0.2449 - val_accuracy: 0.9100\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 739us/step - loss: 0.3600 - accuracy: 0.9076 - val_loss: 0.1834 - val_accuracy: 0.9350\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 726us/step - loss: 0.3831 - accuracy: 0.9149 - val_loss: 0.2466 - val_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 735us/step - loss: 0.3870 - accuracy: 0.9255 - val_loss: 0.1933 - val_accuracy: 0.9283\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.4236 - accuracy: 0.9157 - val_loss: 0.2316 - val_accuracy: 0.9233\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 756us/step - loss: 0.3712 - accuracy: 0.9307 - val_loss: 0.2608 - val_accuracy: 0.8883\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 728us/step - loss: 0.4494 - accuracy: 0.8985 - val_loss: 0.2138 - val_accuracy: 0.9233\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.3986 - accuracy: 0.9197 - val_loss: 0.2427 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.4148 - accuracy: 0.9132 - val_loss: 0.2169 - val_accuracy: 0.9350\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 737us/step - loss: 0.4424 - accuracy: 0.9241 - val_loss: 0.2266 - val_accuracy: 0.9100\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 723us/step - loss: 0.4057 - accuracy: 0.9189 - val_loss: 0.2164 - val_accuracy: 0.9283\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.3002 - accuracy: 0.9424 - val_loss: 0.3405 - val_accuracy: 0.8633\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.4226 - accuracy: 0.9064 - val_loss: 0.2704 - val_accuracy: 0.9083\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.3609 - accuracy: 0.9238 - val_loss: 0.2258 - val_accuracy: 0.9183\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.3259 - accuracy: 0.9357 - val_loss: 0.2512 - val_accuracy: 0.9017\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.3980 - accuracy: 0.9256 - val_loss: 0.2411 - val_accuracy: 0.9283\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 760us/step - loss: 0.4451 - accuracy: 0.9079 - val_loss: 0.1885 - val_accuracy: 0.9333\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 729us/step - loss: 0.3729 - accuracy: 0.9236 - val_loss: 0.2627 - val_accuracy: 0.9083\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.3092 - accuracy: 0.9372 - val_loss: 0.2883 - val_accuracy: 0.8867\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 712us/step - loss: 0.4079 - accuracy: 0.9237 - val_loss: 0.2439 - val_accuracy: 0.9117\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.3255 - accuracy: 0.9389 - val_loss: 0.3442 - val_accuracy: 0.8733\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 741us/step - loss: 0.3621 - accuracy: 0.9191 - val_loss: 0.2551 - val_accuracy: 0.8983\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0739 - accuracy: 0.6427 - val_loss: 0.4697 - val_accuracy: 0.7833\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.8504 - accuracy: 0.7660 - val_loss: 0.3518 - val_accuracy: 0.8683\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.7772 - accuracy: 0.7983 - val_loss: 0.3200 - val_accuracy: 0.8817\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.7171 - accuracy: 0.8269 - val_loss: 0.3159 - val_accuracy: 0.8650\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7110 - accuracy: 0.8432 - val_loss: 0.4046 - val_accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.7528 - accuracy: 0.8142 - val_loss: 0.4067 - val_accuracy: 0.8350\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6888 - accuracy: 0.8389 - val_loss: 0.3456 - val_accuracy: 0.8700\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6938 - accuracy: 0.8430 - val_loss: 0.2499 - val_accuracy: 0.9033\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6165 - accuracy: 0.8665 - val_loss: 0.3509 - val_accuracy: 0.8583\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 733us/step - loss: 0.6284 - accuracy: 0.8690 - val_loss: 0.2884 - val_accuracy: 0.9017\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.6437 - accuracy: 0.8665 - val_loss: 0.2656 - val_accuracy: 0.9017\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 714us/step - loss: 0.6622 - accuracy: 0.8587 - val_loss: 0.3937 - val_accuracy: 0.8467\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.6282 - accuracy: 0.8537 - val_loss: 0.3237 - val_accuracy: 0.8800\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6141 - accuracy: 0.8672 - val_loss: 0.3056 - val_accuracy: 0.8933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5958 - accuracy: 0.8757 - val_loss: 0.2499 - val_accuracy: 0.9017\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.6475 - accuracy: 0.8803 - val_loss: 0.3101 - val_accuracy: 0.8850\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5856 - accuracy: 0.8839 - val_loss: 0.2768 - val_accuracy: 0.9133\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.5466 - accuracy: 0.8879 - val_loss: 0.3479 - val_accuracy: 0.8733\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.5548 - accuracy: 0.8948 - val_loss: 0.3391 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5744 - accuracy: 0.8751 - val_loss: 0.4010 - val_accuracy: 0.8483\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.5981 - accuracy: 0.8708 - val_loss: 0.3721 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.5492 - accuracy: 0.8816 - val_loss: 0.2459 - val_accuracy: 0.9117\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5312 - accuracy: 0.8996 - val_loss: 0.4012 - val_accuracy: 0.8517\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.6313 - accuracy: 0.8679 - val_loss: 0.3063 - val_accuracy: 0.8817\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5374 - accuracy: 0.8902 - val_loss: 0.2831 - val_accuracy: 0.9067\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5341 - accuracy: 0.8876 - val_loss: 0.2579 - val_accuracy: 0.9150\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.5529 - accuracy: 0.8982 - val_loss: 0.3151 - val_accuracy: 0.8800\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.5625 - accuracy: 0.8898 - val_loss: 0.2136 - val_accuracy: 0.9367\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.5054 - accuracy: 0.9059 - val_loss: 0.3350 - val_accuracy: 0.8800\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.5515 - accuracy: 0.8978 - val_loss: 0.2585 - val_accuracy: 0.9117\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 741us/step - loss: 0.5261 - accuracy: 0.8934 - val_loss: 0.3438 - val_accuracy: 0.8833\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5305 - accuracy: 0.9041 - val_loss: 0.3056 - val_accuracy: 0.8967\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.4898 - accuracy: 0.9077 - val_loss: 0.2198 - val_accuracy: 0.9283\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5411 - accuracy: 0.8877 - val_loss: 0.2669 - val_accuracy: 0.9033\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.4556 - accuracy: 0.9194 - val_loss: 0.3106 - val_accuracy: 0.8817\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5068 - accuracy: 0.9013 - val_loss: 0.2108 - val_accuracy: 0.9400\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.4691 - accuracy: 0.9126 - val_loss: 0.2639 - val_accuracy: 0.9183\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.4597 - accuracy: 0.9162 - val_loss: 0.2542 - val_accuracy: 0.9133\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.4865 - accuracy: 0.9068 - val_loss: 0.3256 - val_accuracy: 0.8883\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.4721 - accuracy: 0.9164 - val_loss: 0.1925 - val_accuracy: 0.9433\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.5180 - accuracy: 0.9016 - val_loss: 0.2326 - val_accuracy: 0.9300\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.4629 - accuracy: 0.9242 - val_loss: 0.2757 - val_accuracy: 0.9050\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.4725 - accuracy: 0.9058 - val_loss: 0.2230 - val_accuracy: 0.9367\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.4555 - accuracy: 0.9155 - val_loss: 0.2784 - val_accuracy: 0.9117\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.4422 - accuracy: 0.9136 - val_loss: 0.2810 - val_accuracy: 0.9117\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.4179 - accuracy: 0.9140 - val_loss: 0.2647 - val_accuracy: 0.9117\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.4783 - accuracy: 0.9206 - val_loss: 0.2556 - val_accuracy: 0.9133\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.4626 - accuracy: 0.9172 - val_loss: 0.2865 - val_accuracy: 0.8983\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.4274 - accuracy: 0.9103 - val_loss: 0.2461 - val_accuracy: 0.9250\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4840 - accuracy: 0.9030 - val_loss: 0.2344 - val_accuracy: 0.9333\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.4130 - accuracy: 0.9355 - val_loss: 0.2166 - val_accuracy: 0.9317\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.3951 - accuracy: 0.9183 - val_loss: 0.2532 - val_accuracy: 0.9233\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.4232 - accuracy: 0.9211 - val_loss: 0.2355 - val_accuracy: 0.9267\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4764 - accuracy: 0.9168 - val_loss: 0.2462 - val_accuracy: 0.9217\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.4047 - accuracy: 0.9166 - val_loss: 0.2187 - val_accuracy: 0.9450\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.4257 - accuracy: 0.9228 - val_loss: 0.2455 - val_accuracy: 0.9317\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.4464 - accuracy: 0.9218 - val_loss: 0.2082 - val_accuracy: 0.9333\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.4369 - accuracy: 0.9282 - val_loss: 0.2033 - val_accuracy: 0.9400\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 745us/step - loss: 0.4366 - accuracy: 0.9200 - val_loss: 0.2392 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.3779 - accuracy: 0.9321 - val_loss: 0.2540 - val_accuracy: 0.9250\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0167 - accuracy: 0.6828 - val_loss: 0.4742 - val_accuracy: 0.7867\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.8282 - accuracy: 0.7833 - val_loss: 0.4199 - val_accuracy: 0.8450\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.7542 - accuracy: 0.8024 - val_loss: 0.3342 - val_accuracy: 0.8717\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.7026 - accuracy: 0.8334 - val_loss: 0.3053 - val_accuracy: 0.8867\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 725us/step - loss: 0.7142 - accuracy: 0.8345 - val_loss: 0.3037 - val_accuracy: 0.8950\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.7235 - accuracy: 0.8474 - val_loss: 0.3434 - val_accuracy: 0.8717\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 740us/step - loss: 0.6430 - accuracy: 0.8498 - val_loss: 0.3398 - val_accuracy: 0.8617\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.6314 - accuracy: 0.8419 - val_loss: 0.3700 - val_accuracy: 0.8583\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 736us/step - loss: 0.6236 - accuracy: 0.8515 - val_loss: 0.3137 - val_accuracy: 0.8867\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 728us/step - loss: 0.6838 - accuracy: 0.8638 - val_loss: 0.2741 - val_accuracy: 0.8917\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 735us/step - loss: 0.6484 - accuracy: 0.8503 - val_loss: 0.3143 - val_accuracy: 0.9033\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 729us/step - loss: 0.5714 - accuracy: 0.8878 - val_loss: 0.3064 - val_accuracy: 0.8983\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 730us/step - loss: 0.6315 - accuracy: 0.8663 - val_loss: 0.3174 - val_accuracy: 0.8767\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 729us/step - loss: 0.5586 - accuracy: 0.8935 - val_loss: 0.3805 - val_accuracy: 0.8683\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 714us/step - loss: 0.6106 - accuracy: 0.8821 - val_loss: 0.2708 - val_accuracy: 0.9083\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.6647 - accuracy: 0.8783 - val_loss: 0.3245 - val_accuracy: 0.8950\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 719us/step - loss: 0.5596 - accuracy: 0.8871 - val_loss: 0.2780 - val_accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.5657 - accuracy: 0.8842 - val_loss: 0.3979 - val_accuracy: 0.8467\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.5050 - accuracy: 0.9015 - val_loss: 0.3159 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 722us/step - loss: 0.5357 - accuracy: 0.8989 - val_loss: 0.2651 - val_accuracy: 0.9150\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 723us/step - loss: 0.5862 - accuracy: 0.8903 - val_loss: 0.2636 - val_accuracy: 0.9150\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.6332 - accuracy: 0.8809 - val_loss: 0.3064 - val_accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.5933 - accuracy: 0.8908 - val_loss: 0.3180 - val_accuracy: 0.8967\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 738us/step - loss: 0.5630 - accuracy: 0.8902 - val_loss: 0.3963 - val_accuracy: 0.8650\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 732us/step - loss: 0.5580 - accuracy: 0.8911 - val_loss: 0.2789 - val_accuracy: 0.9200\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 741us/step - loss: 0.6021 - accuracy: 0.8869 - val_loss: 0.2802 - val_accuracy: 0.9217\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 728us/step - loss: 0.5416 - accuracy: 0.8991 - val_loss: 0.2884 - val_accuracy: 0.9067\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.4339 - accuracy: 0.9135 - val_loss: 0.2361 - val_accuracy: 0.9250\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.4797 - accuracy: 0.9037 - val_loss: 0.2520 - val_accuracy: 0.9217\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 733us/step - loss: 0.5096 - accuracy: 0.8977 - val_loss: 0.3341 - val_accuracy: 0.9050\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5321 - accuracy: 0.8950 - val_loss: 0.3030 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5546 - accuracy: 0.8924 - val_loss: 0.2601 - val_accuracy: 0.9150\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.4683 - accuracy: 0.9195 - val_loss: 0.3854 - val_accuracy: 0.8600\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4671 - accuracy: 0.9002 - val_loss: 0.3022 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 732us/step - loss: 0.4690 - accuracy: 0.9174 - val_loss: 0.2653 - val_accuracy: 0.9250\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 739us/step - loss: 0.5340 - accuracy: 0.8895 - val_loss: 0.2511 - val_accuracy: 0.9167\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 711us/step - loss: 0.4927 - accuracy: 0.9038 - val_loss: 0.2971 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.4761 - accuracy: 0.9138 - val_loss: 0.3076 - val_accuracy: 0.9167\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.4621 - accuracy: 0.9134 - val_loss: 0.2575 - val_accuracy: 0.9250\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.4601 - accuracy: 0.9126 - val_loss: 0.2033 - val_accuracy: 0.9417\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.4792 - accuracy: 0.9125 - val_loss: 0.2494 - val_accuracy: 0.9167\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4838 - accuracy: 0.9203 - val_loss: 0.2942 - val_accuracy: 0.9050\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.4520 - accuracy: 0.9182 - val_loss: 0.2723 - val_accuracy: 0.9117\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.4787 - accuracy: 0.8980 - val_loss: 0.2630 - val_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.4496 - accuracy: 0.9034 - val_loss: 0.2777 - val_accuracy: 0.9050\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5050 - accuracy: 0.9140 - val_loss: 0.2440 - val_accuracy: 0.9200\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.5213 - accuracy: 0.8979 - val_loss: 0.2584 - val_accuracy: 0.9217\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.4321 - accuracy: 0.9151 - val_loss: 0.2519 - val_accuracy: 0.9200\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.4678 - accuracy: 0.9074 - val_loss: 0.2618 - val_accuracy: 0.9250\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.4593 - accuracy: 0.9120 - val_loss: 0.2182 - val_accuracy: 0.9267\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.4525 - accuracy: 0.9184 - val_loss: 0.2750 - val_accuracy: 0.9017\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.3864 - accuracy: 0.9288 - val_loss: 0.2470 - val_accuracy: 0.9200\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.4607 - accuracy: 0.9206 - val_loss: 0.2335 - val_accuracy: 0.9350\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.4884 - accuracy: 0.9185 - val_loss: 0.2633 - val_accuracy: 0.9200\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.4615 - accuracy: 0.9179 - val_loss: 0.3050 - val_accuracy: 0.9083\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4405 - accuracy: 0.9141 - val_loss: 0.2225 - val_accuracy: 0.9300\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4089 - accuracy: 0.9225 - val_loss: 0.2491 - val_accuracy: 0.9083\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.4547 - accuracy: 0.9042 - val_loss: 0.2632 - val_accuracy: 0.9133\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 969us/step - loss: 0.5119 - accuracy: 0.9035 - val_loss: 0.2447 - val_accuracy: 0.9183\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.3639 - accuracy: 0.9323 - val_loss: 0.2825 - val_accuracy: 0.9083\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0420 - accuracy: 0.6812 - val_loss: 0.3546 - val_accuracy: 0.8733\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7695 - accuracy: 0.8104 - val_loss: 0.5169 - val_accuracy: 0.7750\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.7847 - accuracy: 0.7963 - val_loss: 0.3309 - val_accuracy: 0.8783\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.7260 - accuracy: 0.8321 - val_loss: 0.3492 - val_accuracy: 0.8717\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.6527 - accuracy: 0.8583 - val_loss: 0.4476 - val_accuracy: 0.8217\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7126 - accuracy: 0.8321 - val_loss: 0.3794 - val_accuracy: 0.8683\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6957 - accuracy: 0.8528 - val_loss: 0.3495 - val_accuracy: 0.8600\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.7229 - accuracy: 0.8368 - val_loss: 0.4605 - val_accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.6444 - accuracy: 0.8490 - val_loss: 0.3992 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6226 - accuracy: 0.8449 - val_loss: 0.3078 - val_accuracy: 0.8767\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.7019 - accuracy: 0.8391 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5915 - accuracy: 0.8729 - val_loss: 0.3157 - val_accuracy: 0.8833\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.7006 - accuracy: 0.8543 - val_loss: 0.3309 - val_accuracy: 0.8717\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6374 - accuracy: 0.8612 - val_loss: 0.2820 - val_accuracy: 0.8933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.6143 - accuracy: 0.8706 - val_loss: 0.3655 - val_accuracy: 0.8450\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.5475 - accuracy: 0.8739 - val_loss: 0.3950 - val_accuracy: 0.8533\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.6799 - accuracy: 0.8544 - val_loss: 0.3243 - val_accuracy: 0.8783\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5920 - accuracy: 0.8755 - val_loss: 0.2416 - val_accuracy: 0.9217\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.6102 - accuracy: 0.8793 - val_loss: 0.2335 - val_accuracy: 0.9133\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.5506 - accuracy: 0.8860 - val_loss: 0.2980 - val_accuracy: 0.8983\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.5484 - accuracy: 0.8901 - val_loss: 0.2602 - val_accuracy: 0.9133\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5969 - accuracy: 0.8702 - val_loss: 0.2662 - val_accuracy: 0.9100\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.5616 - accuracy: 0.8858 - val_loss: 0.2659 - val_accuracy: 0.9017\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.5028 - accuracy: 0.8944 - val_loss: 0.2507 - val_accuracy: 0.9133\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.5156 - accuracy: 0.9065 - val_loss: 0.3511 - val_accuracy: 0.8650\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5241 - accuracy: 0.8953 - val_loss: 0.2669 - val_accuracy: 0.8950\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.5382 - accuracy: 0.8814 - val_loss: 0.2500 - val_accuracy: 0.9217\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5105 - accuracy: 0.8943 - val_loss: 0.2969 - val_accuracy: 0.8833\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.5141 - accuracy: 0.8849 - val_loss: 0.3674 - val_accuracy: 0.8717\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5230 - accuracy: 0.8895 - val_loss: 0.4078 - val_accuracy: 0.8317\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5445 - accuracy: 0.8679 - val_loss: 0.2539 - val_accuracy: 0.9200\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.4692 - accuracy: 0.9137 - val_loss: 0.3026 - val_accuracy: 0.8983\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5649 - accuracy: 0.8987 - val_loss: 0.2250 - val_accuracy: 0.9183\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.4876 - accuracy: 0.9016 - val_loss: 0.2751 - val_accuracy: 0.9150\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.4785 - accuracy: 0.9119 - val_loss: 0.2284 - val_accuracy: 0.9300\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4912 - accuracy: 0.9099 - val_loss: 0.3667 - val_accuracy: 0.8283\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.4992 - accuracy: 0.8956 - val_loss: 0.2909 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.4707 - accuracy: 0.9093 - val_loss: 0.2729 - val_accuracy: 0.9133\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.5010 - accuracy: 0.8915 - val_loss: 0.2652 - val_accuracy: 0.9150\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 733us/step - loss: 0.4428 - accuracy: 0.9171 - val_loss: 0.2319 - val_accuracy: 0.9217\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.5595 - accuracy: 0.8954 - val_loss: 0.2534 - val_accuracy: 0.9167\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5018 - accuracy: 0.9143 - val_loss: 0.3299 - val_accuracy: 0.8583\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.3946 - accuracy: 0.9130 - val_loss: 0.3521 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.4942 - accuracy: 0.8977 - val_loss: 0.2514 - val_accuracy: 0.9183\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.4765 - accuracy: 0.9114 - val_loss: 0.3053 - val_accuracy: 0.8783\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5240 - accuracy: 0.8891 - val_loss: 0.2693 - val_accuracy: 0.9033\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4263 - accuracy: 0.9169 - val_loss: 0.2897 - val_accuracy: 0.8933\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.4266 - accuracy: 0.9141 - val_loss: 0.2766 - val_accuracy: 0.9033\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 745us/step - loss: 0.5318 - accuracy: 0.9002 - val_loss: 0.2582 - val_accuracy: 0.9217\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.4016 - accuracy: 0.9122 - val_loss: 0.2605 - val_accuracy: 0.9067\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.4159 - accuracy: 0.9167 - val_loss: 0.3025 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.9137 - val_loss: 0.2591 - val_accuracy: 0.9200\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4830 - accuracy: 0.9083 - val_loss: 0.2811 - val_accuracy: 0.9067\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1009 - accuracy: 0.6252 - val_loss: 0.6025 - val_accuracy: 0.7033\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.8460 - accuracy: 0.7679 - val_loss: 0.4084 - val_accuracy: 0.8250\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.8199 - accuracy: 0.8017 - val_loss: 0.3509 - val_accuracy: 0.8517\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.7644 - accuracy: 0.8135 - val_loss: 0.2881 - val_accuracy: 0.8833\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.7038 - accuracy: 0.8336 - val_loss: 0.3327 - val_accuracy: 0.8750\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.6872 - accuracy: 0.8431 - val_loss: 0.3364 - val_accuracy: 0.8767\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6717 - accuracy: 0.8600 - val_loss: 0.3446 - val_accuracy: 0.8650\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 726us/step - loss: 0.6637 - accuracy: 0.8536 - val_loss: 0.3429 - val_accuracy: 0.8867\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.6384 - accuracy: 0.8632 - val_loss: 0.3012 - val_accuracy: 0.8950\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.7110 - accuracy: 0.8456 - val_loss: 0.3186 - val_accuracy: 0.8933\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.6808 - accuracy: 0.8733 - val_loss: 0.3156 - val_accuracy: 0.8767\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5891 - accuracy: 0.8789 - val_loss: 0.3019 - val_accuracy: 0.8950\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.5880 - accuracy: 0.8803 - val_loss: 0.4139 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.5628 - accuracy: 0.8783 - val_loss: 0.2804 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.6098 - accuracy: 0.8740 - val_loss: 0.2835 - val_accuracy: 0.9050\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5587 - accuracy: 0.9000 - val_loss: 0.2406 - val_accuracy: 0.9150\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.5671 - accuracy: 0.8986 - val_loss: 0.2881 - val_accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.6209 - accuracy: 0.8780 - val_loss: 0.2943 - val_accuracy: 0.8933\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.5633 - accuracy: 0.8949 - val_loss: 0.3370 - val_accuracy: 0.8733\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 740us/step - loss: 0.5999 - accuracy: 0.8902 - val_loss: 0.3806 - val_accuracy: 0.8883\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5862 - accuracy: 0.8830 - val_loss: 0.3484 - val_accuracy: 0.8900\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.5723 - accuracy: 0.8820 - val_loss: 0.2950 - val_accuracy: 0.9150\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.5050 - accuracy: 0.9061 - val_loss: 0.3311 - val_accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5828 - accuracy: 0.8718 - val_loss: 0.3637 - val_accuracy: 0.8933\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 733us/step - loss: 0.5707 - accuracy: 0.8931 - val_loss: 0.3103 - val_accuracy: 0.8933\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5427 - accuracy: 0.8984 - val_loss: 0.2906 - val_accuracy: 0.9050\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.4856 - accuracy: 0.9002 - val_loss: 0.3212 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.4487 - accuracy: 0.9107 - val_loss: 0.3558 - val_accuracy: 0.8867\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5063 - accuracy: 0.8922 - val_loss: 0.3408 - val_accuracy: 0.8900\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.5484 - accuracy: 0.8938 - val_loss: 0.3061 - val_accuracy: 0.8883\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5639 - accuracy: 0.8818 - val_loss: 0.2243 - val_accuracy: 0.9383\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5405 - accuracy: 0.8918 - val_loss: 0.2649 - val_accuracy: 0.9183\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4808 - accuracy: 0.9051 - val_loss: 0.2606 - val_accuracy: 0.9200\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.4857 - accuracy: 0.9138 - val_loss: 0.2776 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.4552 - accuracy: 0.9128 - val_loss: 0.2647 - val_accuracy: 0.9300\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5374 - accuracy: 0.8963 - val_loss: 0.2222 - val_accuracy: 0.9250\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 739us/step - loss: 0.4805 - accuracy: 0.9135 - val_loss: 0.2791 - val_accuracy: 0.9017\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.5388 - accuracy: 0.8931 - val_loss: 0.3447 - val_accuracy: 0.8817\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5379 - accuracy: 0.8941 - val_loss: 0.2410 - val_accuracy: 0.9283\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.4896 - accuracy: 0.9206 - val_loss: 0.2467 - val_accuracy: 0.9133\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5169 - accuracy: 0.9036 - val_loss: 0.2357 - val_accuracy: 0.9350\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.4922 - accuracy: 0.9123 - val_loss: 0.3135 - val_accuracy: 0.8983\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.9238 - val_loss: 0.2422 - val_accuracy: 0.9117\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.4641 - accuracy: 0.9123 - val_loss: 0.2800 - val_accuracy: 0.9067\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.5107 - accuracy: 0.8949 - val_loss: 0.2622 - val_accuracy: 0.9150\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 738us/step - loss: 0.4837 - accuracy: 0.9205 - val_loss: 0.2807 - val_accuracy: 0.9083\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.4507 - accuracy: 0.9136 - val_loss: 0.3374 - val_accuracy: 0.8883\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4932 - accuracy: 0.8967 - val_loss: 0.2548 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.4540 - accuracy: 0.9297 - val_loss: 0.2588 - val_accuracy: 0.9267\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.5153 - accuracy: 0.9041 - val_loss: 0.2392 - val_accuracy: 0.9367\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4625 - accuracy: 0.9094 - val_loss: 0.2418 - val_accuracy: 0.9183\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.4819 - accuracy: 0.8923 - val_loss: 0.2456 - val_accuracy: 0.9200\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 988us/step - loss: 0.4038 - accuracy: 0.9236 - val_loss: 0.2614 - val_accuracy: 0.9150\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.4245 - accuracy: 0.9156 - val_loss: 0.2622 - val_accuracy: 0.9183\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4676 - accuracy: 0.9149 - val_loss: 0.2528 - val_accuracy: 0.9183\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.4389 - accuracy: 0.9221 - val_loss: 0.3146 - val_accuracy: 0.8783\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1252 - accuracy: 0.6301 - val_loss: 0.4577 - val_accuracy: 0.8083\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.8283 - accuracy: 0.7759 - val_loss: 0.4530 - val_accuracy: 0.8050\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.7641 - accuracy: 0.8102 - val_loss: 0.4749 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.7350 - accuracy: 0.8364 - val_loss: 0.3325 - val_accuracy: 0.8850\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.7549 - accuracy: 0.8232 - val_loss: 0.3411 - val_accuracy: 0.8583\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7704 - accuracy: 0.8371 - val_loss: 0.3214 - val_accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.7133 - accuracy: 0.8586 - val_loss: 0.3141 - val_accuracy: 0.9117\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.7528 - accuracy: 0.8376 - val_loss: 0.3303 - val_accuracy: 0.8633\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.6454 - accuracy: 0.8579 - val_loss: 0.3247 - val_accuracy: 0.8733\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.6639 - accuracy: 0.8737 - val_loss: 0.3295 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.6118 - accuracy: 0.8805 - val_loss: 0.3258 - val_accuracy: 0.9017\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6030 - accuracy: 0.8808 - val_loss: 0.2705 - val_accuracy: 0.9067\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5886 - accuracy: 0.8870 - val_loss: 0.3028 - val_accuracy: 0.8867\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 976us/step - loss: 0.6058 - accuracy: 0.8693 - val_loss: 0.2992 - val_accuracy: 0.8867\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.6421 - accuracy: 0.8646 - val_loss: 0.3164 - val_accuracy: 0.8967\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 976us/step - loss: 0.6113 - accuracy: 0.8793 - val_loss: 0.3148 - val_accuracy: 0.8867\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.6327 - accuracy: 0.8718 - val_loss: 0.3661 - val_accuracy: 0.8767\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.5774 - accuracy: 0.8740 - val_loss: 0.2999 - val_accuracy: 0.8950\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5348 - accuracy: 0.8933 - val_loss: 0.2827 - val_accuracy: 0.8917\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5649 - accuracy: 0.8924 - val_loss: 0.2318 - val_accuracy: 0.9333\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.5447 - accuracy: 0.8951 - val_loss: 0.2922 - val_accuracy: 0.9050\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5325 - accuracy: 0.8920 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.5773 - accuracy: 0.8915 - val_loss: 0.2942 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.5697 - accuracy: 0.8910 - val_loss: 0.2514 - val_accuracy: 0.9133\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5612 - accuracy: 0.8972 - val_loss: 0.2648 - val_accuracy: 0.9100\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5134 - accuracy: 0.9003 - val_loss: 0.3407 - val_accuracy: 0.8833\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5899 - accuracy: 0.8825 - val_loss: 0.2899 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.5169 - accuracy: 0.8987 - val_loss: 0.3352 - val_accuracy: 0.8850\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.5824 - accuracy: 0.8960 - val_loss: 0.3497 - val_accuracy: 0.8783\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.5441 - accuracy: 0.8926 - val_loss: 0.2441 - val_accuracy: 0.9250\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.5690 - accuracy: 0.9048 - val_loss: 0.2530 - val_accuracy: 0.9133\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.6026 - accuracy: 0.8912 - val_loss: 0.2254 - val_accuracy: 0.9150\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.5375 - accuracy: 0.9090 - val_loss: 0.2788 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5729 - accuracy: 0.9104 - val_loss: 0.2163 - val_accuracy: 0.9317\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 745us/step - loss: 0.5753 - accuracy: 0.9032 - val_loss: 0.2372 - val_accuracy: 0.9300\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.4775 - accuracy: 0.9120 - val_loss: 0.2888 - val_accuracy: 0.8950\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.5501 - accuracy: 0.8850 - val_loss: 0.2826 - val_accuracy: 0.8983\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5083 - accuracy: 0.9077 - val_loss: 0.2956 - val_accuracy: 0.8983\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.5596 - accuracy: 0.8919 - val_loss: 0.2378 - val_accuracy: 0.9267\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.5060 - accuracy: 0.9083 - val_loss: 0.3284 - val_accuracy: 0.8917\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5112 - accuracy: 0.8948 - val_loss: 0.2545 - val_accuracy: 0.9233\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.4243 - accuracy: 0.9234 - val_loss: 0.3062 - val_accuracy: 0.9067\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.4886 - accuracy: 0.9018 - val_loss: 0.1809 - val_accuracy: 0.9483\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 723us/step - loss: 0.5135 - accuracy: 0.9140 - val_loss: 0.3310 - val_accuracy: 0.8783\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.4490 - accuracy: 0.9077 - val_loss: 0.2682 - val_accuracy: 0.9133\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 735us/step - loss: 0.4947 - accuracy: 0.9099 - val_loss: 0.2741 - val_accuracy: 0.9067\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.5167 - accuracy: 0.9063 - val_loss: 0.1986 - val_accuracy: 0.9417\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.5296 - accuracy: 0.8970 - val_loss: 0.2610 - val_accuracy: 0.9133\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.5003 - accuracy: 0.8967 - val_loss: 0.1949 - val_accuracy: 0.9517\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.4449 - accuracy: 0.9262 - val_loss: 0.2884 - val_accuracy: 0.8933\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 725us/step - loss: 0.4355 - accuracy: 0.9191 - val_loss: 0.2801 - val_accuracy: 0.9050\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.4769 - accuracy: 0.9150 - val_loss: 0.3565 - val_accuracy: 0.8500\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 727us/step - loss: 0.4282 - accuracy: 0.9238 - val_loss: 0.2248 - val_accuracy: 0.9317\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4325 - accuracy: 0.9195 - val_loss: 0.2218 - val_accuracy: 0.9317\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 738us/step - loss: 0.4077 - accuracy: 0.9215 - val_loss: 0.2230 - val_accuracy: 0.9300\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4374 - accuracy: 0.9185 - val_loss: 0.2079 - val_accuracy: 0.9350\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.5049 - accuracy: 0.9142 - val_loss: 0.2396 - val_accuracy: 0.9217\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.4705 - accuracy: 0.9001 - val_loss: 0.2505 - val_accuracy: 0.9100\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.4841 - accuracy: 0.9026 - val_loss: 0.2754 - val_accuracy: 0.9117\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.4237 - accuracy: 0.9151 - val_loss: 0.2533 - val_accuracy: 0.9183\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.4412 - accuracy: 0.9049 - val_loss: 0.1916 - val_accuracy: 0.9400\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.5393 - accuracy: 0.9102 - val_loss: 0.2785 - val_accuracy: 0.9133\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.4741 - accuracy: 0.9005 - val_loss: 0.2642 - val_accuracy: 0.9033\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1075 - accuracy: 0.6687 - val_loss: 0.3967 - val_accuracy: 0.8483\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.8433 - accuracy: 0.7873 - val_loss: 0.4356 - val_accuracy: 0.8150\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.7664 - accuracy: 0.8201 - val_loss: 0.4510 - val_accuracy: 0.8167\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.7942 - accuracy: 0.8091 - val_loss: 0.2949 - val_accuracy: 0.8983\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.7280 - accuracy: 0.8370 - val_loss: 0.3744 - val_accuracy: 0.8617\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.6817 - accuracy: 0.8451 - val_loss: 0.3715 - val_accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.6087 - accuracy: 0.8628 - val_loss: 0.4078 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.6637 - accuracy: 0.8501 - val_loss: 0.3604 - val_accuracy: 0.8567\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.6516 - accuracy: 0.8557 - val_loss: 0.3314 - val_accuracy: 0.8633\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 721us/step - loss: 0.6262 - accuracy: 0.8697 - val_loss: 0.2765 - val_accuracy: 0.8983\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5811 - accuracy: 0.8874 - val_loss: 0.3757 - val_accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.6188 - accuracy: 0.8751 - val_loss: 0.3361 - val_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.6750 - accuracy: 0.8594 - val_loss: 0.2837 - val_accuracy: 0.8917\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.6022 - accuracy: 0.8692 - val_loss: 0.2924 - val_accuracy: 0.8933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.6484 - accuracy: 0.8766 - val_loss: 0.3213 - val_accuracy: 0.8683\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.6507 - accuracy: 0.8697 - val_loss: 0.2873 - val_accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.6159 - accuracy: 0.8847 - val_loss: 0.3374 - val_accuracy: 0.8883\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 742us/step - loss: 0.5062 - accuracy: 0.8997 - val_loss: 0.2955 - val_accuracy: 0.8900\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.5985 - accuracy: 0.8709 - val_loss: 0.3200 - val_accuracy: 0.8917\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.5773 - accuracy: 0.8869 - val_loss: 0.3383 - val_accuracy: 0.8733\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.5679 - accuracy: 0.8789 - val_loss: 0.4258 - val_accuracy: 0.8350\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.5365 - accuracy: 0.8897 - val_loss: 0.3713 - val_accuracy: 0.8833\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.5974 - accuracy: 0.8846 - val_loss: 0.2631 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.5946 - accuracy: 0.8808 - val_loss: 0.2847 - val_accuracy: 0.9033\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5343 - accuracy: 0.9024 - val_loss: 0.2383 - val_accuracy: 0.9417\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5279 - accuracy: 0.9027 - val_loss: 0.2666 - val_accuracy: 0.9050\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.5925 - accuracy: 0.8983 - val_loss: 0.3326 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5253 - accuracy: 0.8963 - val_loss: 0.3189 - val_accuracy: 0.8983\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.5393 - accuracy: 0.9030 - val_loss: 0.2669 - val_accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.5465 - accuracy: 0.9012 - val_loss: 0.2319 - val_accuracy: 0.9267\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.5231 - accuracy: 0.9080 - val_loss: 0.2819 - val_accuracy: 0.9267\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.5344 - accuracy: 0.8997 - val_loss: 0.3180 - val_accuracy: 0.8950\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 728us/step - loss: 0.5320 - accuracy: 0.8873 - val_loss: 0.2843 - val_accuracy: 0.9233\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5170 - accuracy: 0.9062 - val_loss: 0.2763 - val_accuracy: 0.9283\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.4801 - accuracy: 0.9090 - val_loss: 0.2908 - val_accuracy: 0.9050\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4922 - accuracy: 0.9045 - val_loss: 0.2890 - val_accuracy: 0.9167\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 738us/step - loss: 0.5266 - accuracy: 0.9014 - val_loss: 0.2791 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5263 - accuracy: 0.8905 - val_loss: 0.2797 - val_accuracy: 0.9133\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.4518 - accuracy: 0.9137 - val_loss: 0.3112 - val_accuracy: 0.8983\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.4903 - accuracy: 0.9130 - val_loss: 0.2570 - val_accuracy: 0.9167\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.4933 - accuracy: 0.9001 - val_loss: 0.2163 - val_accuracy: 0.9400\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.4866 - accuracy: 0.9124 - val_loss: 0.2213 - val_accuracy: 0.9317\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.4337 - accuracy: 0.9191 - val_loss: 0.3298 - val_accuracy: 0.8583\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.4099 - accuracy: 0.9173 - val_loss: 0.3159 - val_accuracy: 0.8783\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.5402 - accuracy: 0.8974 - val_loss: 0.2223 - val_accuracy: 0.9233\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.5051 - accuracy: 0.9193 - val_loss: 0.2859 - val_accuracy: 0.9050\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.4941 - accuracy: 0.9081 - val_loss: 0.2315 - val_accuracy: 0.9317\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 745us/step - loss: 0.3916 - accuracy: 0.9287 - val_loss: 0.2532 - val_accuracy: 0.9217\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.4281 - accuracy: 0.9202 - val_loss: 0.2527 - val_accuracy: 0.9267\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.5099 - accuracy: 0.9004 - val_loss: 0.3025 - val_accuracy: 0.8983\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.4351 - accuracy: 0.9082 - val_loss: 0.2425 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4286 - accuracy: 0.9245 - val_loss: 0.2223 - val_accuracy: 0.9283\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.4068 - accuracy: 0.9252 - val_loss: 0.3129 - val_accuracy: 0.8767\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.4541 - accuracy: 0.9032 - val_loss: 0.2941 - val_accuracy: 0.9050\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.3684 - accuracy: 0.9220 - val_loss: 0.3352 - val_accuracy: 0.8883\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.4042 - accuracy: 0.9157 - val_loss: 0.2317 - val_accuracy: 0.9267\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4620 - accuracy: 0.9098 - val_loss: 0.3090 - val_accuracy: 0.8767\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.3771 - accuracy: 0.9262 - val_loss: 0.2428 - val_accuracy: 0.9183\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.4142 - accuracy: 0.9151 - val_loss: 0.3216 - val_accuracy: 0.8700\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4590 - accuracy: 0.9127 - val_loss: 0.2099 - val_accuracy: 0.9383\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4401 - accuracy: 0.9194 - val_loss: 0.3558 - val_accuracy: 0.8683\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 747us/step - loss: 0.4438 - accuracy: 0.9176 - val_loss: 0.2279 - val_accuracy: 0.9250\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.4608 - accuracy: 0.9185 - val_loss: 0.2344 - val_accuracy: 0.9250\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.3990 - accuracy: 0.9353 - val_loss: 0.2693 - val_accuracy: 0.9133\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.4326 - accuracy: 0.9223 - val_loss: 0.2536 - val_accuracy: 0.9017\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.3927 - accuracy: 0.9291 - val_loss: 0.2423 - val_accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.4035 - accuracy: 0.9139 - val_loss: 0.2325 - val_accuracy: 0.9217\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.4519 - accuracy: 0.9040 - val_loss: 0.2948 - val_accuracy: 0.9150\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.4592 - accuracy: 0.9178 - val_loss: 0.3143 - val_accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.3941 - accuracy: 0.9157 - val_loss: 0.2451 - val_accuracy: 0.9233\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.3457 - accuracy: 0.93 - 0s 813us/step - loss: 0.3512 - accuracy: 0.9325 - val_loss: 0.3054 - val_accuracy: 0.9017\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.4119 - accuracy: 0.8968 - val_loss: 0.2296 - val_accuracy: 0.9233\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.4530 - accuracy: 0.9211 - val_loss: 0.2672 - val_accuracy: 0.9150\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4026 - accuracy: 0.9149 - val_loss: 0.3245 - val_accuracy: 0.8567\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.3365 - accuracy: 0.9284 - val_loss: 0.2178 - val_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.3893 - accuracy: 0.9237 - val_loss: 0.2842 - val_accuracy: 0.9050\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.3763 - accuracy: 0.9254 - val_loss: 0.2348 - val_accuracy: 0.9150\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.3585 - accuracy: 0.9260 - val_loss: 0.3318 - val_accuracy: 0.8683\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.3693 - accuracy: 0.9236 - val_loss: 0.2962 - val_accuracy: 0.8850\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.4041 - accuracy: 0.9190 - val_loss: 0.3324 - val_accuracy: 0.8533\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1361 - accuracy: 0.6467 - val_loss: 0.5192 - val_accuracy: 0.7683\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.7826 - accuracy: 0.7766 - val_loss: 0.4190 - val_accuracy: 0.8267\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.7537 - accuracy: 0.8178 - val_loss: 0.3959 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.7351 - accuracy: 0.8185 - val_loss: 0.3181 - val_accuracy: 0.8800\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.7428 - accuracy: 0.8328 - val_loss: 0.3859 - val_accuracy: 0.8550\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.7063 - accuracy: 0.8277 - val_loss: 0.3676 - val_accuracy: 0.8483\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.6273 - accuracy: 0.8617 - val_loss: 0.3832 - val_accuracy: 0.8517\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.6171 - accuracy: 0.8578 - val_loss: 0.3231 - val_accuracy: 0.8817\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.6568 - accuracy: 0.8644 - val_loss: 0.3097 - val_accuracy: 0.8867\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6839 - accuracy: 0.8569 - val_loss: 0.4041 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.5762 - accuracy: 0.8724 - val_loss: 0.3349 - val_accuracy: 0.8833\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.7369 - accuracy: 0.8352 - val_loss: 0.3436 - val_accuracy: 0.8550\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.6247 - accuracy: 0.8655 - val_loss: 0.3323 - val_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.6426 - accuracy: 0.8624 - val_loss: 0.2970 - val_accuracy: 0.8917\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6323 - accuracy: 0.8606 - val_loss: 0.4070 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.6696 - accuracy: 0.8517 - val_loss: 0.3778 - val_accuracy: 0.8683\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 963us/step - loss: 0.6159 - accuracy: 0.8672 - val_loss: 0.3487 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.6163 - accuracy: 0.8732 - val_loss: 0.3593 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.5999 - accuracy: 0.8757 - val_loss: 0.2317 - val_accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.5873 - accuracy: 0.8914 - val_loss: 0.3011 - val_accuracy: 0.8817\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.6215 - accuracy: 0.8788 - val_loss: 0.2547 - val_accuracy: 0.9283\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.5421 - accuracy: 0.8935 - val_loss: 0.2995 - val_accuracy: 0.9033\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.5309 - accuracy: 0.9053 - val_loss: 0.2534 - val_accuracy: 0.9117\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5244 - accuracy: 0.9088 - val_loss: 0.2653 - val_accuracy: 0.9117\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5020 - accuracy: 0.9227 - val_loss: 0.3286 - val_accuracy: 0.8850\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5589 - accuracy: 0.8871 - val_loss: 0.3143 - val_accuracy: 0.8883\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5281 - accuracy: 0.8880 - val_loss: 0.2563 - val_accuracy: 0.9083\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.5037 - accuracy: 0.9052 - val_loss: 0.3409 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 731us/step - loss: 0.5388 - accuracy: 0.9025 - val_loss: 0.2980 - val_accuracy: 0.8917\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5983 - accuracy: 0.8880 - val_loss: 0.2971 - val_accuracy: 0.8883\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.4835 - accuracy: 0.9032 - val_loss: 0.3170 - val_accuracy: 0.9050\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.4454 - accuracy: 0.9162 - val_loss: 0.2942 - val_accuracy: 0.9117\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.5387 - accuracy: 0.9020 - val_loss: 0.2522 - val_accuracy: 0.9100\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5428 - accuracy: 0.9001 - val_loss: 0.3476 - val_accuracy: 0.8850\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.4747 - accuracy: 0.9053 - val_loss: 0.2361 - val_accuracy: 0.9267\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.4871 - accuracy: 0.9070 - val_loss: 0.2596 - val_accuracy: 0.9117\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5254 - accuracy: 0.9019 - val_loss: 0.2722 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.5255 - accuracy: 0.8872 - val_loss: 0.3424 - val_accuracy: 0.8817\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.4714 - accuracy: 0.9076 - val_loss: 0.2708 - val_accuracy: 0.9183\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1275 - accuracy: 0.6391 - val_loss: 0.4643 - val_accuracy: 0.7967\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 723us/step - loss: 0.8367 - accuracy: 0.7928 - val_loss: 0.4514 - val_accuracy: 0.8067\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.7772 - accuracy: 0.8043 - val_loss: 0.3897 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.7458 - accuracy: 0.8120 - val_loss: 0.3798 - val_accuracy: 0.8517\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.6698 - accuracy: 0.8505 - val_loss: 0.3749 - val_accuracy: 0.8450\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.6934 - accuracy: 0.8514 - val_loss: 0.4411 - val_accuracy: 0.8100\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.6744 - accuracy: 0.8374 - val_loss: 0.3650 - val_accuracy: 0.8533\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.6481 - accuracy: 0.8512 - val_loss: 0.3323 - val_accuracy: 0.8733\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.6466 - accuracy: 0.8568 - val_loss: 0.3158 - val_accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.6142 - accuracy: 0.8710 - val_loss: 0.3246 - val_accuracy: 0.8917\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.6269 - accuracy: 0.8643 - val_loss: 0.3068 - val_accuracy: 0.8917\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.6341 - accuracy: 0.8701 - val_loss: 0.3057 - val_accuracy: 0.9017\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.5610 - accuracy: 0.8965 - val_loss: 0.3448 - val_accuracy: 0.8517\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.6025 - accuracy: 0.8850 - val_loss: 0.2807 - val_accuracy: 0.9100\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.6173 - accuracy: 0.8785 - val_loss: 0.3158 - val_accuracy: 0.8850\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5957 - accuracy: 0.8833 - val_loss: 0.3324 - val_accuracy: 0.8850\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.5708 - accuracy: 0.8915 - val_loss: 0.3747 - val_accuracy: 0.8633\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6139 - accuracy: 0.8785 - val_loss: 0.2653 - val_accuracy: 0.9033\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.5383 - accuracy: 0.8830 - val_loss: 0.2974 - val_accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.5594 - accuracy: 0.8961 - val_loss: 0.2463 - val_accuracy: 0.9183\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.4778 - accuracy: 0.9087 - val_loss: 0.2953 - val_accuracy: 0.8967\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.6082 - accuracy: 0.8799 - val_loss: 0.2530 - val_accuracy: 0.9083\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.5188 - accuracy: 0.9077 - val_loss: 0.2717 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.5666 - accuracy: 0.8969 - val_loss: 0.2163 - val_accuracy: 0.9267\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5578 - accuracy: 0.8947 - val_loss: 0.2863 - val_accuracy: 0.9017\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.5617 - accuracy: 0.8859 - val_loss: 0.3161 - val_accuracy: 0.8917\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.5661 - accuracy: 0.8916 - val_loss: 0.2131 - val_accuracy: 0.9283\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.5237 - accuracy: 0.9013 - val_loss: 0.3105 - val_accuracy: 0.8917\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5458 - accuracy: 0.8946 - val_loss: 0.3088 - val_accuracy: 0.9017\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 978us/step - loss: 0.5606 - accuracy: 0.8887 - val_loss: 0.2552 - val_accuracy: 0.9083\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.9090 - val_loss: 0.2999 - val_accuracy: 0.9017\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5866 - accuracy: 0.8912 - val_loss: 0.2096 - val_accuracy: 0.9333\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.4982 - accuracy: 0.9087 - val_loss: 0.2813 - val_accuracy: 0.9083\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.4417 - accuracy: 0.9200 - val_loss: 0.2789 - val_accuracy: 0.9117\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4978 - accuracy: 0.8976 - val_loss: 0.2906 - val_accuracy: 0.9033\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.4461 - accuracy: 0.9154 - val_loss: 0.4279 - val_accuracy: 0.8017\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.4857 - accuracy: 0.8949 - val_loss: 0.2658 - val_accuracy: 0.9200\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.4905 - accuracy: 0.9022 - val_loss: 0.2522 - val_accuracy: 0.9250\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.4392 - accuracy: 0.9146 - val_loss: 0.3079 - val_accuracy: 0.8883\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.4445 - accuracy: 0.9005 - val_loss: 0.3845 - val_accuracy: 0.8400\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.4331 - accuracy: 0.9171 - val_loss: 0.2939 - val_accuracy: 0.8883\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.4913 - accuracy: 0.9025 - val_loss: 0.3623 - val_accuracy: 0.8550\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.4441 - accuracy: 0.9023 - val_loss: 0.2711 - val_accuracy: 0.8983\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.4754 - accuracy: 0.9101 - val_loss: 0.3355 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.4634 - accuracy: 0.9124 - val_loss: 0.3469 - val_accuracy: 0.8650\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.5037 - accuracy: 0.9012 - val_loss: 0.1845 - val_accuracy: 0.9417\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5067 - accuracy: 0.9153 - val_loss: 0.2451 - val_accuracy: 0.9233\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.4820 - accuracy: 0.9038 - val_loss: 0.2459 - val_accuracy: 0.9267\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.4513 - accuracy: 0.9094 - val_loss: 0.2907 - val_accuracy: 0.8833\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.3840 - accuracy: 0.9275 - val_loss: 0.2451 - val_accuracy: 0.9117\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4376 - accuracy: 0.9118 - val_loss: 0.2101 - val_accuracy: 0.9300\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.4173 - accuracy: 0.9177 - val_loss: 0.2806 - val_accuracy: 0.9117\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.4542 - accuracy: 0.9109 - val_loss: 0.2308 - val_accuracy: 0.9233\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.4155 - accuracy: 0.9196 - val_loss: 0.3389 - val_accuracy: 0.8733\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4768 - accuracy: 0.8981 - val_loss: 0.2721 - val_accuracy: 0.9017\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.4525 - accuracy: 0.9088 - val_loss: 0.2982 - val_accuracy: 0.8783\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.4995 - accuracy: 0.9027 - val_loss: 0.2536 - val_accuracy: 0.9150\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4255 - accuracy: 0.9192 - val_loss: 0.2173 - val_accuracy: 0.9383\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5325 - accuracy: 0.9014 - val_loss: 0.3252 - val_accuracy: 0.8917\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.4245 - accuracy: 0.9051 - val_loss: 0.2158 - val_accuracy: 0.9283\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.4225 - accuracy: 0.9154 - val_loss: 0.2691 - val_accuracy: 0.8983\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.3927 - accuracy: 0.9182 - val_loss: 0.2303 - val_accuracy: 0.9233\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.4608 - accuracy: 0.8983 - val_loss: 0.1940 - val_accuracy: 0.9400\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.3612 - accuracy: 0.9336 - val_loss: 0.2809 - val_accuracy: 0.8983\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.3841 - accuracy: 0.9120 - val_loss: 0.2861 - val_accuracy: 0.8983\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.4495 - accuracy: 0.8997 - val_loss: 0.2693 - val_accuracy: 0.8933\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0992 - accuracy: 0.6423 - val_loss: 0.4457 - val_accuracy: 0.8150\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.7934 - accuracy: 0.7935 - val_loss: 0.4341 - val_accuracy: 0.8233\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.8515 - accuracy: 0.7861 - val_loss: 0.3808 - val_accuracy: 0.8400\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 743us/step - loss: 0.7348 - accuracy: 0.8431 - val_loss: 0.3045 - val_accuracy: 0.8833\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.7296 - accuracy: 0.8377 - val_loss: 0.3533 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 749us/step - loss: 0.7008 - accuracy: 0.8488 - val_loss: 0.3083 - val_accuracy: 0.8833\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.6393 - accuracy: 0.8703 - val_loss: 0.4130 - val_accuracy: 0.8367\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 756us/step - loss: 0.6381 - accuracy: 0.8444 - val_loss: 0.3652 - val_accuracy: 0.8717\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.6238 - accuracy: 0.8644 - val_loss: 0.3011 - val_accuracy: 0.9017\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.6926 - accuracy: 0.8501 - val_loss: 0.3601 - val_accuracy: 0.8867\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.6069 - accuracy: 0.8650 - val_loss: 0.3630 - val_accuracy: 0.8850\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.6460 - accuracy: 0.8747 - val_loss: 0.3477 - val_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.6222 - accuracy: 0.8668 - val_loss: 0.3578 - val_accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 743us/step - loss: 0.5777 - accuracy: 0.8852 - val_loss: 0.3458 - val_accuracy: 0.8833\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.6543 - accuracy: 0.8616 - val_loss: 0.2681 - val_accuracy: 0.9017\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.6706 - accuracy: 0.8699 - val_loss: 0.3400 - val_accuracy: 0.8800\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.6399 - accuracy: 0.8641 - val_loss: 0.2574 - val_accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.6100 - accuracy: 0.8764 - val_loss: 0.2899 - val_accuracy: 0.8967\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5786 - accuracy: 0.8832 - val_loss: 0.2646 - val_accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5433 - accuracy: 0.8956 - val_loss: 0.2958 - val_accuracy: 0.8867\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.5520 - accuracy: 0.8966 - val_loss: 0.2997 - val_accuracy: 0.8933\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.5293 - accuracy: 0.8973 - val_loss: 0.2489 - val_accuracy: 0.9250\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.5716 - accuracy: 0.8901 - val_loss: 0.2427 - val_accuracy: 0.9150\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.5832 - accuracy: 0.8938 - val_loss: 0.2897 - val_accuracy: 0.9017\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 754us/step - loss: 0.5514 - accuracy: 0.9021 - val_loss: 0.2843 - val_accuracy: 0.8867\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.5737 - accuracy: 0.8911 - val_loss: 0.2771 - val_accuracy: 0.8867\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.5284 - accuracy: 0.8918 - val_loss: 0.2672 - val_accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.5663 - accuracy: 0.8897 - val_loss: 0.2681 - val_accuracy: 0.9117\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5205 - accuracy: 0.8960 - val_loss: 0.2754 - val_accuracy: 0.9183\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.4850 - accuracy: 0.9154 - val_loss: 0.2767 - val_accuracy: 0.9150\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 760us/step - loss: 0.4683 - accuracy: 0.9155 - val_loss: 0.2468 - val_accuracy: 0.9250\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.5853 - accuracy: 0.9014 - val_loss: 0.3342 - val_accuracy: 0.8867\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5028 - accuracy: 0.8962 - val_loss: 0.3582 - val_accuracy: 0.8650\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.5059 - accuracy: 0.8912 - val_loss: 0.3763 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.5395 - accuracy: 0.8932 - val_loss: 0.3214 - val_accuracy: 0.8950\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.5515 - accuracy: 0.8959 - val_loss: 0.3172 - val_accuracy: 0.9017\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5025 - accuracy: 0.9057 - val_loss: 0.2796 - val_accuracy: 0.9100\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.4794 - accuracy: 0.9094 - val_loss: 0.2908 - val_accuracy: 0.9100\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.4623 - accuracy: 0.9114 - val_loss: 0.2271 - val_accuracy: 0.9233\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.4247 - accuracy: 0.9263 - val_loss: 0.3004 - val_accuracy: 0.9133\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.4777 - accuracy: 0.8949 - val_loss: 0.2579 - val_accuracy: 0.9283\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5186 - accuracy: 0.9038 - val_loss: 0.2146 - val_accuracy: 0.9233\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5100 - accuracy: 0.9113 - val_loss: 0.2390 - val_accuracy: 0.9083\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.4666 - accuracy: 0.9180 - val_loss: 0.3581 - val_accuracy: 0.8383\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.3905 - accuracy: 0.9203 - val_loss: 0.4195 - val_accuracy: 0.8400\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.4276 - accuracy: 0.9110 - val_loss: 0.2604 - val_accuracy: 0.9217\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4302 - accuracy: 0.9155 - val_loss: 0.2620 - val_accuracy: 0.9133\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.4148 - accuracy: 0.9127 - val_loss: 0.2922 - val_accuracy: 0.8967\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.4615 - accuracy: 0.9071 - val_loss: 0.2467 - val_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 756us/step - loss: 0.4462 - accuracy: 0.9183 - val_loss: 0.2629 - val_accuracy: 0.9133\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.4311 - accuracy: 0.9121 - val_loss: 0.2492 - val_accuracy: 0.9100\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.4274 - accuracy: 0.9213 - val_loss: 0.3217 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.4533 - accuracy: 0.8986 - val_loss: 0.2427 - val_accuracy: 0.9217\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.4225 - accuracy: 0.9196 - val_loss: 0.2522 - val_accuracy: 0.9067\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4360 - accuracy: 0.9093 - val_loss: 0.3565 - val_accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.4367 - accuracy: 0.9076 - val_loss: 0.2504 - val_accuracy: 0.9167\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.4573 - accuracy: 0.9227 - val_loss: 0.2925 - val_accuracy: 0.8867\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.4070 - accuracy: 0.9122 - val_loss: 0.2820 - val_accuracy: 0.9017\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.4105 - accuracy: 0.9049 - val_loss: 0.2636 - val_accuracy: 0.8950\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.4483 - accuracy: 0.9191 - val_loss: 0.2636 - val_accuracy: 0.9017\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.3808 - accuracy: 0.9226 - val_loss: 0.2230 - val_accuracy: 0.9267\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.4163 - accuracy: 0.9232 - val_loss: 0.2546 - val_accuracy: 0.9067\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0877 - accuracy: 0.6545 - val_loss: 0.5096 - val_accuracy: 0.7700\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9058 - accuracy: 0.7395 - val_loss: 0.4542 - val_accuracy: 0.7983\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.7684 - accuracy: 0.8047 - val_loss: 0.4029 - val_accuracy: 0.8317\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.7115 - accuracy: 0.8258 - val_loss: 0.3473 - val_accuracy: 0.8550\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6631 - accuracy: 0.8376 - val_loss: 0.3182 - val_accuracy: 0.8767\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.7045 - accuracy: 0.8413 - val_loss: 0.3091 - val_accuracy: 0.8800\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7229 - accuracy: 0.8480 - val_loss: 0.3093 - val_accuracy: 0.8917\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.8687 - val_loss: 0.3409 - val_accuracy: 0.8650\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6227 - accuracy: 0.8655 - val_loss: 0.3810 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.6593 - accuracy: 0.8626 - val_loss: 0.3495 - val_accuracy: 0.8717\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5994 - accuracy: 0.8777 - val_loss: 0.3913 - val_accuracy: 0.8450\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6286 - accuracy: 0.8633 - val_loss: 0.2767 - val_accuracy: 0.8933\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.6559 - accuracy: 0.8696 - val_loss: 0.2860 - val_accuracy: 0.9017\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 745us/step - loss: 0.6651 - accuracy: 0.8695 - val_loss: 0.2440 - val_accuracy: 0.9133\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 900us/step - loss: 0.6488 - accuracy: 0.8808 - val_loss: 0.3386 - val_accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.6970 - accuracy: 0.8521 - val_loss: 0.3184 - val_accuracy: 0.8817\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.6116 - accuracy: 0.8784 - val_loss: 0.2491 - val_accuracy: 0.9150\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6244 - accuracy: 0.8879 - val_loss: 0.3478 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.6084 - accuracy: 0.8664 - val_loss: 0.2321 - val_accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.6454 - accuracy: 0.8841 - val_loss: 0.3266 - val_accuracy: 0.8867\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.5704 - accuracy: 0.9028 - val_loss: 0.2585 - val_accuracy: 0.9133\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.5910 - accuracy: 0.8798 - val_loss: 0.3453 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.5700 - accuracy: 0.8857 - val_loss: 0.2916 - val_accuracy: 0.8933\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.5750 - accuracy: 0.8987 - val_loss: 0.2717 - val_accuracy: 0.9017\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5975 - accuracy: 0.8736 - val_loss: 0.2318 - val_accuracy: 0.9250\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.6008 - accuracy: 0.8980 - val_loss: 0.2612 - val_accuracy: 0.9117\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.5409 - accuracy: 0.8850 - val_loss: 0.3047 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 772us/step - loss: 0.5586 - accuracy: 0.8849 - val_loss: 0.2929 - val_accuracy: 0.9017\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.5093 - accuracy: 0.8970 - val_loss: 0.2553 - val_accuracy: 0.9083\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5515 - accuracy: 0.8952 - val_loss: 0.2695 - val_accuracy: 0.9050\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.5052 - accuracy: 0.8996 - val_loss: 0.2858 - val_accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.4880 - accuracy: 0.9005 - val_loss: 0.2754 - val_accuracy: 0.9117\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.5409 - accuracy: 0.8974 - val_loss: 0.2574 - val_accuracy: 0.9183\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5504 - accuracy: 0.8853 - val_loss: 0.3290 - val_accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5537 - accuracy: 0.8872 - val_loss: 0.2773 - val_accuracy: 0.9217\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4675 - accuracy: 0.9175 - val_loss: 0.2328 - val_accuracy: 0.9283\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4742 - accuracy: 0.9119 - val_loss: 0.3179 - val_accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.4468 - accuracy: 0.9026 - val_loss: 0.2661 - val_accuracy: 0.9117\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.4376 - accuracy: 0.9204 - val_loss: 0.2537 - val_accuracy: 0.9100\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5282 - accuracy: 0.9093 - val_loss: 0.2547 - val_accuracy: 0.9200\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.4422 - accuracy: 0.9108 - val_loss: 0.3112 - val_accuracy: 0.8883\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5134 - accuracy: 0.9029 - val_loss: 0.2113 - val_accuracy: 0.9300\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.4919 - accuracy: 0.9104 - val_loss: 0.2914 - val_accuracy: 0.9083\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.4952 - accuracy: 0.9003 - val_loss: 0.3027 - val_accuracy: 0.8800\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.4660 - accuracy: 0.9059 - val_loss: 0.2497 - val_accuracy: 0.9167\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.4184 - accuracy: 0.9184 - val_loss: 0.2853 - val_accuracy: 0.8950\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.4283 - accuracy: 0.9175 - val_loss: 0.2568 - val_accuracy: 0.9100\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.3811 - accuracy: 0.9199 - val_loss: 0.3327 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.4748 - accuracy: 0.8978 - val_loss: 0.2493 - val_accuracy: 0.9150\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4654 - accuracy: 0.9112 - val_loss: 0.2588 - val_accuracy: 0.9017\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.4728 - accuracy: 0.9203 - val_loss: 0.2273 - val_accuracy: 0.9317\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.4489 - accuracy: 0.9091 - val_loss: 0.2603 - val_accuracy: 0.9150\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.4357 - accuracy: 0.9102 - val_loss: 0.2715 - val_accuracy: 0.8950\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.4142 - accuracy: 0.9133 - val_loss: 0.3509 - val_accuracy: 0.8583\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.4186 - accuracy: 0.9147 - val_loss: 0.2750 - val_accuracy: 0.9100\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.4700 - accuracy: 0.9027 - val_loss: 0.2713 - val_accuracy: 0.8967\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4055 - accuracy: 0.9191 - val_loss: 0.2450 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.4463 - accuracy: 0.9118 - val_loss: 0.2406 - val_accuracy: 0.9133\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4415 - accuracy: 0.9127 - val_loss: 0.3670 - val_accuracy: 0.8517\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.3968 - accuracy: 0.9214 - val_loss: 0.2785 - val_accuracy: 0.8900\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.3715 - accuracy: 0.9195 - val_loss: 0.3025 - val_accuracy: 0.8833\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.4199 - accuracy: 0.9127 - val_loss: 0.2652 - val_accuracy: 0.9033\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1380 - accuracy: 0.6017 - val_loss: 0.5438 - val_accuracy: 0.7583\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.8852 - accuracy: 0.7582 - val_loss: 0.4107 - val_accuracy: 0.8317\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.7880 - accuracy: 0.8074 - val_loss: 0.3712 - val_accuracy: 0.8700\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.7130 - accuracy: 0.8294 - val_loss: 0.3635 - val_accuracy: 0.8533\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.7027 - accuracy: 0.8318 - val_loss: 0.3348 - val_accuracy: 0.8783\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.7025 - accuracy: 0.8420 - val_loss: 0.3350 - val_accuracy: 0.8683\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.6618 - accuracy: 0.8469 - val_loss: 0.3355 - val_accuracy: 0.8733\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.7019 - accuracy: 0.8428 - val_loss: 0.2827 - val_accuracy: 0.9117\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.6391 - accuracy: 0.8580 - val_loss: 0.3730 - val_accuracy: 0.8583\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 756us/step - loss: 0.6703 - accuracy: 0.8568 - val_loss: 0.3889 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.6611 - accuracy: 0.8591 - val_loss: 0.3058 - val_accuracy: 0.8783\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 733us/step - loss: 0.6521 - accuracy: 0.8666 - val_loss: 0.3037 - val_accuracy: 0.8883\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.5941 - accuracy: 0.8788 - val_loss: 0.2795 - val_accuracy: 0.9017\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.6404 - accuracy: 0.8701 - val_loss: 0.3000 - val_accuracy: 0.8950\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.5936 - accuracy: 0.8756 - val_loss: 0.2997 - val_accuracy: 0.9033\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.6157 - accuracy: 0.8757 - val_loss: 0.2969 - val_accuracy: 0.8867\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5918 - accuracy: 0.8845 - val_loss: 0.2853 - val_accuracy: 0.9050\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.5688 - accuracy: 0.8938 - val_loss: 0.3541 - val_accuracy: 0.8867\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.6479 - accuracy: 0.8696 - val_loss: 0.2528 - val_accuracy: 0.9117\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.6364 - accuracy: 0.8841 - val_loss: 0.2629 - val_accuracy: 0.9117\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.5837 - accuracy: 0.8991 - val_loss: 0.2633 - val_accuracy: 0.9150\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.5424 - accuracy: 0.9058 - val_loss: 0.2761 - val_accuracy: 0.9017\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.5664 - accuracy: 0.8956 - val_loss: 0.3035 - val_accuracy: 0.8917\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.5247 - accuracy: 0.8917 - val_loss: 0.3024 - val_accuracy: 0.9217\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5428 - accuracy: 0.9052 - val_loss: 0.2786 - val_accuracy: 0.9133\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.6284 - accuracy: 0.8909 - val_loss: 0.2523 - val_accuracy: 0.9200\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5417 - accuracy: 0.8922 - val_loss: 0.2776 - val_accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5601 - accuracy: 0.8889 - val_loss: 0.2090 - val_accuracy: 0.9383\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.5021 - accuracy: 0.9142 - val_loss: 0.2611 - val_accuracy: 0.9267\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.4758 - accuracy: 0.9098 - val_loss: 0.2597 - val_accuracy: 0.9217\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5041 - accuracy: 0.9072 - val_loss: 0.2695 - val_accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.5222 - accuracy: 0.9108 - val_loss: 0.2531 - val_accuracy: 0.9317\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5677 - accuracy: 0.9002 - val_loss: 0.2421 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.4679 - accuracy: 0.9130 - val_loss: 0.2823 - val_accuracy: 0.9033\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.4782 - accuracy: 0.9143 - val_loss: 0.2434 - val_accuracy: 0.9267\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 760us/step - loss: 0.4271 - accuracy: 0.9148 - val_loss: 0.2982 - val_accuracy: 0.9067\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5198 - accuracy: 0.8973 - val_loss: 0.2338 - val_accuracy: 0.9367\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5072 - accuracy: 0.9156 - val_loss: 0.3530 - val_accuracy: 0.8800\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.4665 - accuracy: 0.9049 - val_loss: 0.2398 - val_accuracy: 0.9333\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 756us/step - loss: 0.5003 - accuracy: 0.9043 - val_loss: 0.2631 - val_accuracy: 0.9217\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5293 - accuracy: 0.9011 - val_loss: 0.2301 - val_accuracy: 0.9183\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.4935 - accuracy: 0.9146 - val_loss: 0.2695 - val_accuracy: 0.9100\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 735us/step - loss: 0.5325 - accuracy: 0.9025 - val_loss: 0.2974 - val_accuracy: 0.8917\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4917 - accuracy: 0.9037 - val_loss: 0.2909 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.4849 - accuracy: 0.9143 - val_loss: 0.2559 - val_accuracy: 0.9200\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.5049 - accuracy: 0.9204 - val_loss: 0.2254 - val_accuracy: 0.9267\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5410 - accuracy: 0.9066 - val_loss: 0.2526 - val_accuracy: 0.9183\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 734us/step - loss: 0.5309 - accuracy: 0.8931 - val_loss: 0.1994 - val_accuracy: 0.9417\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.4358 - accuracy: 0.9251 - val_loss: 0.2999 - val_accuracy: 0.8967\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.5054 - accuracy: 0.9027 - val_loss: 0.2083 - val_accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4375 - accuracy: 0.9217 - val_loss: 0.2337 - val_accuracy: 0.9333\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.4241 - accuracy: 0.9179 - val_loss: 0.2602 - val_accuracy: 0.9167\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4359 - accuracy: 0.9204 - val_loss: 0.2984 - val_accuracy: 0.9050\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.4413 - accuracy: 0.9167 - val_loss: 0.2575 - val_accuracy: 0.9183\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.9262 - val_loss: 0.2613 - val_accuracy: 0.9033\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.9284 - val_loss: 0.2789 - val_accuracy: 0.9100\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.4396 - accuracy: 0.9181 - val_loss: 0.2276 - val_accuracy: 0.9250\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4752 - accuracy: 0.9239 - val_loss: 0.2665 - val_accuracy: 0.9083\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.4388 - accuracy: 0.9088 - val_loss: 0.2143 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.4755 - accuracy: 0.9115 - val_loss: 0.2435 - val_accuracy: 0.9183\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.3982 - accuracy: 0.9286 - val_loss: 0.2635 - val_accuracy: 0.8967\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.4510 - accuracy: 0.9076 - val_loss: 0.2310 - val_accuracy: 0.9267\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.3916 - accuracy: 0.9290 - val_loss: 0.2764 - val_accuracy: 0.9067\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.4250 - accuracy: 0.9118 - val_loss: 0.2881 - val_accuracy: 0.9033\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5215 - accuracy: 0.9060 - val_loss: 0.2286 - val_accuracy: 0.9250\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.4196 - accuracy: 0.9165 - val_loss: 0.2639 - val_accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.3931 - accuracy: 0.9277 - val_loss: 0.2889 - val_accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.3611 - accuracy: 0.9216 - val_loss: 0.2948 - val_accuracy: 0.8817\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1198 - accuracy: 0.6554 - val_loss: 0.5079 - val_accuracy: 0.7950\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7826 - accuracy: 0.8101 - val_loss: 0.4395 - val_accuracy: 0.8033\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.7984 - accuracy: 0.8013 - val_loss: 0.4029 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.7377 - accuracy: 0.8211 - val_loss: 0.3860 - val_accuracy: 0.8600\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.6920 - accuracy: 0.8390 - val_loss: 0.3053 - val_accuracy: 0.8817\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.7403 - accuracy: 0.8459 - val_loss: 0.3866 - val_accuracy: 0.8450\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.6902 - accuracy: 0.8442 - val_loss: 0.4249 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.6678 - accuracy: 0.8570 - val_loss: 0.3352 - val_accuracy: 0.8717\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.6534 - accuracy: 0.8634 - val_loss: 0.2997 - val_accuracy: 0.8933\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.6035 - accuracy: 0.8758 - val_loss: 0.3406 - val_accuracy: 0.8683\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.7002 - accuracy: 0.8584 - val_loss: 0.3813 - val_accuracy: 0.8550\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.6040 - accuracy: 0.8763 - val_loss: 0.3090 - val_accuracy: 0.8983\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.6095 - accuracy: 0.8784 - val_loss: 0.3356 - val_accuracy: 0.8800\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.5867 - accuracy: 0.8824 - val_loss: 0.3463 - val_accuracy: 0.8717\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5863 - accuracy: 0.8777 - val_loss: 0.3191 - val_accuracy: 0.8917\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6476 - accuracy: 0.8718 - val_loss: 0.3296 - val_accuracy: 0.8883\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6168 - accuracy: 0.8823 - val_loss: 0.3007 - val_accuracy: 0.9017\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.5649 - accuracy: 0.8956 - val_loss: 0.2683 - val_accuracy: 0.9017\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.5374 - accuracy: 0.8910 - val_loss: 0.3421 - val_accuracy: 0.8717\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5653 - accuracy: 0.8877 - val_loss: 0.3058 - val_accuracy: 0.8967\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.6060 - accuracy: 0.8861 - val_loss: 0.2679 - val_accuracy: 0.9067\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5727 - accuracy: 0.8968 - val_loss: 0.3043 - val_accuracy: 0.9017\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5521 - accuracy: 0.8982 - val_loss: 0.2784 - val_accuracy: 0.9117\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5508 - accuracy: 0.8955 - val_loss: 0.2126 - val_accuracy: 0.9300\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6055 - accuracy: 0.8919 - val_loss: 0.3154 - val_accuracy: 0.8867\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.5206 - accuracy: 0.9076 - val_loss: 0.3192 - val_accuracy: 0.8900\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.5329 - accuracy: 0.8916 - val_loss: 0.3459 - val_accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.5300 - accuracy: 0.9001 - val_loss: 0.2778 - val_accuracy: 0.9117\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 747us/step - loss: 0.5466 - accuracy: 0.8983 - val_loss: 0.2327 - val_accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5313 - accuracy: 0.9033 - val_loss: 0.3376 - val_accuracy: 0.8933\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5187 - accuracy: 0.8786 - val_loss: 0.2429 - val_accuracy: 0.9150\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.5536 - accuracy: 0.8978 - val_loss: 0.3451 - val_accuracy: 0.8717\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5183 - accuracy: 0.8930 - val_loss: 0.2328 - val_accuracy: 0.9267\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.5810 - accuracy: 0.8992 - val_loss: 0.2767 - val_accuracy: 0.9117\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.4694 - accuracy: 0.9031 - val_loss: 0.2928 - val_accuracy: 0.9050\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.5252 - accuracy: 0.9149 - val_loss: 0.2492 - val_accuracy: 0.9133\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5874 - accuracy: 0.8929 - val_loss: 0.2322 - val_accuracy: 0.9183\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.5033 - accuracy: 0.9083 - val_loss: 0.3102 - val_accuracy: 0.9033\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.4862 - accuracy: 0.9105 - val_loss: 0.2100 - val_accuracy: 0.9417\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.4692 - accuracy: 0.9181 - val_loss: 0.3037 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.4951 - accuracy: 0.9012 - val_loss: 0.2074 - val_accuracy: 0.9300\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5322 - accuracy: 0.9068 - val_loss: 0.3077 - val_accuracy: 0.8967\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4411 - accuracy: 0.9174 - val_loss: 0.2714 - val_accuracy: 0.9083\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.4776 - accuracy: 0.9133 - val_loss: 0.2318 - val_accuracy: 0.9183\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4704 - accuracy: 0.9169 - val_loss: 0.2846 - val_accuracy: 0.9017\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5446 - accuracy: 0.8984 - val_loss: 0.2758 - val_accuracy: 0.9100\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.4756 - accuracy: 0.9111 - val_loss: 0.2004 - val_accuracy: 0.9317\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.4938 - accuracy: 0.9256 - val_loss: 0.2527 - val_accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.4616 - accuracy: 0.9100 - val_loss: 0.2912 - val_accuracy: 0.8967\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4839 - accuracy: 0.9109 - val_loss: 0.2388 - val_accuracy: 0.9217\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.4255 - accuracy: 0.9202 - val_loss: 0.3022 - val_accuracy: 0.8950\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5130 - accuracy: 0.9063 - val_loss: 0.2789 - val_accuracy: 0.9050\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.5398 - accuracy: 0.9063 - val_loss: 0.2651 - val_accuracy: 0.9183\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.5105 - accuracy: 0.9042 - val_loss: 0.2699 - val_accuracy: 0.9117\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.4363 - accuracy: 0.9163 - val_loss: 0.2165 - val_accuracy: 0.9383\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.4692 - accuracy: 0.9160 - val_loss: 0.2097 - val_accuracy: 0.9250\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.4053 - accuracy: 0.9256 - val_loss: 0.2726 - val_accuracy: 0.9083\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.4447 - accuracy: 0.9188 - val_loss: 0.2219 - val_accuracy: 0.9300\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.4283 - accuracy: 0.9235 - val_loss: 0.2683 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.4601 - accuracy: 0.9077 - val_loss: 0.2561 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.4616 - accuracy: 0.9122 - val_loss: 0.3327 - val_accuracy: 0.8833\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.4251 - accuracy: 0.9156 - val_loss: 0.2366 - val_accuracy: 0.9200\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4863 - accuracy: 0.9130 - val_loss: 0.3005 - val_accuracy: 0.8850\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5041 - accuracy: 0.8967 - val_loss: 0.2307 - val_accuracy: 0.9283\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.4612 - accuracy: 0.9168 - val_loss: 0.2749 - val_accuracy: 0.9017\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4611 - accuracy: 0.9098 - val_loss: 0.3114 - val_accuracy: 0.8750\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.4246 - accuracy: 0.9070 - val_loss: 0.2602 - val_accuracy: 0.9100\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0955 - accuracy: 0.6541 - val_loss: 0.5011 - val_accuracy: 0.7717\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.8024 - accuracy: 0.7882 - val_loss: 0.4297 - val_accuracy: 0.8283\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.7877 - accuracy: 0.8038 - val_loss: 0.4286 - val_accuracy: 0.8183\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.6977 - accuracy: 0.8343 - val_loss: 0.3592 - val_accuracy: 0.8667\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7647 - accuracy: 0.8311 - val_loss: 0.3324 - val_accuracy: 0.8817\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6312 - accuracy: 0.8678 - val_loss: 0.3463 - val_accuracy: 0.8750\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6596 - accuracy: 0.8625 - val_loss: 0.3021 - val_accuracy: 0.8833\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6701 - accuracy: 0.8492 - val_loss: 0.4230 - val_accuracy: 0.8417\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6393 - accuracy: 0.8556 - val_loss: 0.3493 - val_accuracy: 0.8567\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7046 - accuracy: 0.8569 - val_loss: 0.3674 - val_accuracy: 0.8550\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6637 - accuracy: 0.8551 - val_loss: 0.2905 - val_accuracy: 0.8967\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.6469 - accuracy: 0.8716 - val_loss: 0.2667 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5692 - accuracy: 0.8908 - val_loss: 0.3852 - val_accuracy: 0.8600\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6027 - accuracy: 0.8662 - val_loss: 0.2877 - val_accuracy: 0.8933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.5606 - accuracy: 0.8953 - val_loss: 0.4898 - val_accuracy: 0.8033\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.5796 - accuracy: 0.8821 - val_loss: 0.2604 - val_accuracy: 0.9117\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.5719 - accuracy: 0.9029 - val_loss: 0.2605 - val_accuracy: 0.9300\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.5072 - accuracy: 0.8991 - val_loss: 0.2872 - val_accuracy: 0.9033\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.5293 - accuracy: 0.8908 - val_loss: 0.3401 - val_accuracy: 0.8817\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.5896 - accuracy: 0.8753 - val_loss: 0.2809 - val_accuracy: 0.8967\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.5964 - accuracy: 0.8828 - val_loss: 0.3021 - val_accuracy: 0.9017\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5438 - accuracy: 0.9036 - val_loss: 0.2838 - val_accuracy: 0.8967\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5963 - accuracy: 0.8839 - val_loss: 0.3092 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.5464 - accuracy: 0.8936 - val_loss: 0.2352 - val_accuracy: 0.9317\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.5496 - accuracy: 0.9044 - val_loss: 0.3556 - val_accuracy: 0.8700\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.5217 - accuracy: 0.8963 - val_loss: 0.2885 - val_accuracy: 0.9083\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5368 - accuracy: 0.8926 - val_loss: 0.2856 - val_accuracy: 0.9067\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.4390 - accuracy: 0.9162 - val_loss: 0.3852 - val_accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.5370 - accuracy: 0.8891 - val_loss: 0.2827 - val_accuracy: 0.9133\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.4573 - accuracy: 0.9161 - val_loss: 0.2666 - val_accuracy: 0.9200\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.5144 - accuracy: 0.9053 - val_loss: 0.2141 - val_accuracy: 0.9350\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5445 - accuracy: 0.9052 - val_loss: 0.2116 - val_accuracy: 0.9300\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.4992 - accuracy: 0.9128 - val_loss: 0.2588 - val_accuracy: 0.9117\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.5252 - accuracy: 0.9058 - val_loss: 0.2304 - val_accuracy: 0.9317\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6184 - accuracy: 0.9025 - val_loss: 0.2326 - val_accuracy: 0.9200\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.5054 - accuracy: 0.9134 - val_loss: 0.3224 - val_accuracy: 0.9050\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5194 - accuracy: 0.9121 - val_loss: 0.2605 - val_accuracy: 0.9150\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5762 - accuracy: 0.9038 - val_loss: 0.2546 - val_accuracy: 0.9083\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5747 - accuracy: 0.9039 - val_loss: 0.3464 - val_accuracy: 0.8817\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4767 - accuracy: 0.9106 - val_loss: 0.2486 - val_accuracy: 0.9083\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.4323 - accuracy: 0.9148 - val_loss: 0.2653 - val_accuracy: 0.9083\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.4457 - accuracy: 0.9093 - val_loss: 0.2657 - val_accuracy: 0.9183\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.4536 - accuracy: 0.9156 - val_loss: 0.2713 - val_accuracy: 0.9233\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5674 - accuracy: 0.8934 - val_loss: 0.3272 - val_accuracy: 0.8817\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.4142 - accuracy: 0.9187 - val_loss: 0.3236 - val_accuracy: 0.8833\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.4591 - accuracy: 0.9127 - val_loss: 0.2899 - val_accuracy: 0.8933\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.4615 - accuracy: 0.9179 - val_loss: 0.3540 - val_accuracy: 0.8567\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.4133 - accuracy: 0.9154 - val_loss: 0.2499 - val_accuracy: 0.9233\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4266 - accuracy: 0.9268 - val_loss: 0.2492 - val_accuracy: 0.9200\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.5139 - accuracy: 0.9045 - val_loss: 0.2324 - val_accuracy: 0.9267\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.5374 - accuracy: 0.9076 - val_loss: 0.3520 - val_accuracy: 0.8817\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.5360 - accuracy: 0.9091 - val_loss: 0.2330 - val_accuracy: 0.9217\n",
      "7\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2913 - accuracy: 0.5746 - val_loss: 0.5313 - val_accuracy: 0.7433\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8998 - accuracy: 0.7549 - val_loss: 0.4779 - val_accuracy: 0.7900\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8608 - accuracy: 0.7767 - val_loss: 0.3671 - val_accuracy: 0.8600\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8511 - accuracy: 0.8014 - val_loss: 0.2752 - val_accuracy: 0.8933\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7322 - accuracy: 0.8311 - val_loss: 0.3641 - val_accuracy: 0.8383\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.7055 - accuracy: 0.8459 - val_loss: 0.4101 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.7759 - accuracy: 0.8233 - val_loss: 0.3786 - val_accuracy: 0.8433\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7741 - accuracy: 0.8224 - val_loss: 0.4033 - val_accuracy: 0.8617\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7228 - accuracy: 0.8325 - val_loss: 0.3022 - val_accuracy: 0.8967\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.7021 - accuracy: 0.8491 - val_loss: 0.2983 - val_accuracy: 0.9017\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.7057 - accuracy: 0.8564 - val_loss: 0.2844 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.6118 - accuracy: 0.8809 - val_loss: 0.3692 - val_accuracy: 0.8633\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.6868 - accuracy: 0.8550 - val_loss: 0.2677 - val_accuracy: 0.9117\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.6582 - accuracy: 0.8662 - val_loss: 0.3739 - val_accuracy: 0.8833\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6494 - accuracy: 0.8845 - val_loss: 0.4605 - val_accuracy: 0.8100\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.6178 - accuracy: 0.8680 - val_loss: 0.3484 - val_accuracy: 0.8567\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.6262 - accuracy: 0.8800 - val_loss: 0.3004 - val_accuracy: 0.9117\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.6950 - accuracy: 0.8817 - val_loss: 0.3475 - val_accuracy: 0.8717\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.6629 - accuracy: 0.8596 - val_loss: 0.2912 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7022 - accuracy: 0.8758 - val_loss: 0.3129 - val_accuracy: 0.8883\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5577 - accuracy: 0.8849 - val_loss: 0.2879 - val_accuracy: 0.9067\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5952 - accuracy: 0.8990 - val_loss: 0.3229 - val_accuracy: 0.8950\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.5993 - accuracy: 0.8833 - val_loss: 0.3990 - val_accuracy: 0.8817\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.8947 - val_loss: 0.2842 - val_accuracy: 0.9067\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 981us/step - loss: 0.5518 - accuracy: 0.8998 - val_loss: 0.2807 - val_accuracy: 0.9233\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.6251 - accuracy: 0.8847 - val_loss: 0.3284 - val_accuracy: 0.8933\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5219 - accuracy: 0.9053 - val_loss: 0.2957 - val_accuracy: 0.9133\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5704 - accuracy: 0.8915 - val_loss: 0.2665 - val_accuracy: 0.9250\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.4656 - accuracy: 0.9225 - val_loss: 0.2618 - val_accuracy: 0.9150\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.5598 - accuracy: 0.9081 - val_loss: 0.2596 - val_accuracy: 0.9183\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.5337 - accuracy: 0.9126 - val_loss: 0.3642 - val_accuracy: 0.8867\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.6134 - accuracy: 0.8916 - val_loss: 0.2600 - val_accuracy: 0.9250\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.6280 - accuracy: 0.8897 - val_loss: 0.2170 - val_accuracy: 0.9417\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.5863 - accuracy: 0.8973 - val_loss: 0.3249 - val_accuracy: 0.8967\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5263 - accuracy: 0.9120 - val_loss: 0.2722 - val_accuracy: 0.9150\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6112 - accuracy: 0.8891 - val_loss: 0.3513 - val_accuracy: 0.8867\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.6189 - accuracy: 0.8801 - val_loss: 0.2796 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.5306 - accuracy: 0.9058 - val_loss: 0.2942 - val_accuracy: 0.9167\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5127 - accuracy: 0.9122 - val_loss: 0.2724 - val_accuracy: 0.9167\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5626 - accuracy: 0.8992 - val_loss: 0.2760 - val_accuracy: 0.9150\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5475 - accuracy: 0.9047 - val_loss: 0.2905 - val_accuracy: 0.9133\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.5172 - accuracy: 0.8996 - val_loss: 0.2827 - val_accuracy: 0.8983\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 756us/step - loss: 0.5534 - accuracy: 0.8962 - val_loss: 0.3357 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.4944 - accuracy: 0.9061 - val_loss: 0.2751 - val_accuracy: 0.9200\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4741 - accuracy: 0.9223 - val_loss: 0.2675 - val_accuracy: 0.9150\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4497 - accuracy: 0.9219 - val_loss: 0.2711 - val_accuracy: 0.9017\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5546 - accuracy: 0.9036 - val_loss: 0.2773 - val_accuracy: 0.9133\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5648 - accuracy: 0.8882 - val_loss: 0.2344 - val_accuracy: 0.9217\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4850 - accuracy: 0.9139 - val_loss: 0.2722 - val_accuracy: 0.9083\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.4904 - accuracy: 0.9089 - val_loss: 0.2555 - val_accuracy: 0.9250\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 773us/step - loss: 0.5489 - accuracy: 0.9018 - val_loss: 0.3021 - val_accuracy: 0.8917\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.5326 - accuracy: 0.8952 - val_loss: 0.3000 - val_accuracy: 0.8950\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5304 - accuracy: 0.8942 - val_loss: 0.2666 - val_accuracy: 0.9150\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1702 - accuracy: 0.6365 - val_loss: 0.5082 - val_accuracy: 0.7650\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.9274 - accuracy: 0.7406 - val_loss: 0.3541 - val_accuracy: 0.8750\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.7792 - accuracy: 0.8261 - val_loss: 0.4598 - val_accuracy: 0.7983\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.8385 - accuracy: 0.7980 - val_loss: 0.4337 - val_accuracy: 0.8150\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.7477 - accuracy: 0.8356 - val_loss: 0.3680 - val_accuracy: 0.8550\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.6699 - accuracy: 0.8449 - val_loss: 0.4355 - val_accuracy: 0.8283\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.7843 - accuracy: 0.8272 - val_loss: 0.3199 - val_accuracy: 0.8767\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6985 - accuracy: 0.8544 - val_loss: 0.3813 - val_accuracy: 0.8483\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.7570 - accuracy: 0.8265 - val_loss: 0.4249 - val_accuracy: 0.8400\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7249 - accuracy: 0.8415 - val_loss: 0.3785 - val_accuracy: 0.8417\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.7640 - accuracy: 0.8411 - val_loss: 0.2529 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.7018 - accuracy: 0.8617 - val_loss: 0.2715 - val_accuracy: 0.9050\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.7477 - accuracy: 0.8580 - val_loss: 0.2880 - val_accuracy: 0.8850\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.6613 - accuracy: 0.8555 - val_loss: 0.5344 - val_accuracy: 0.7700\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.6942 - accuracy: 0.8537 - val_loss: 0.3313 - val_accuracy: 0.8783\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.6069 - accuracy: 0.8774 - val_loss: 0.3453 - val_accuracy: 0.8717\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.6016 - accuracy: 0.8751 - val_loss: 0.3196 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6204 - accuracy: 0.8747 - val_loss: 0.2742 - val_accuracy: 0.9017\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.6197 - accuracy: 0.8702 - val_loss: 0.2612 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6511 - accuracy: 0.8717 - val_loss: 0.3237 - val_accuracy: 0.8817\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5743 - accuracy: 0.8797 - val_loss: 0.3277 - val_accuracy: 0.8833\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.6232 - accuracy: 0.8876 - val_loss: 0.3649 - val_accuracy: 0.8717\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.8967 - val_loss: 0.4010 - val_accuracy: 0.8383\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5797 - accuracy: 0.8878 - val_loss: 0.2814 - val_accuracy: 0.9017\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6095 - accuracy: 0.8848 - val_loss: 0.3524 - val_accuracy: 0.8583\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.6131 - accuracy: 0.8733 - val_loss: 0.3265 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5902 - accuracy: 0.8847 - val_loss: 0.2686 - val_accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5248 - accuracy: 0.9067 - val_loss: 0.2788 - val_accuracy: 0.8967\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6134 - accuracy: 0.8883 - val_loss: 0.3105 - val_accuracy: 0.8783\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5591 - accuracy: 0.8882 - val_loss: 0.2389 - val_accuracy: 0.9117\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.5148 - accuracy: 0.8976 - val_loss: 0.2866 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.5144 - accuracy: 0.8959 - val_loss: 0.3685 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5354 - accuracy: 0.8986 - val_loss: 0.2759 - val_accuracy: 0.8817\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5280 - accuracy: 0.8959 - val_loss: 0.3754 - val_accuracy: 0.8450\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5297 - accuracy: 0.8930 - val_loss: 0.3401 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5271 - accuracy: 0.8939 - val_loss: 0.2729 - val_accuracy: 0.9050\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5187 - accuracy: 0.9020 - val_loss: 0.2608 - val_accuracy: 0.9033\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4471 - accuracy: 0.9034 - val_loss: 0.3491 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5440 - accuracy: 0.8841 - val_loss: 0.2541 - val_accuracy: 0.9133\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.5730 - accuracy: 0.8823 - val_loss: 0.3169 - val_accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5030 - accuracy: 0.9000 - val_loss: 0.2776 - val_accuracy: 0.9017\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.5148 - accuracy: 0.9000 - val_loss: 0.3965 - val_accuracy: 0.8250\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 902us/step - loss: 0.5402 - accuracy: 0.8803 - val_loss: 0.2321 - val_accuracy: 0.9183\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.5341 - accuracy: 0.8895 - val_loss: 0.3422 - val_accuracy: 0.8583\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.5284 - accuracy: 0.9028 - val_loss: 0.2699 - val_accuracy: 0.9117\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5615 - accuracy: 0.8966 - val_loss: 0.2952 - val_accuracy: 0.8967\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5018 - accuracy: 0.8924 - val_loss: 0.3119 - val_accuracy: 0.8717\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.5054 - accuracy: 0.8987 - val_loss: 0.2705 - val_accuracy: 0.8867\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.4580 - accuracy: 0.9052 - val_loss: 0.3177 - val_accuracy: 0.8833\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.90 - 0s 949us/step - loss: 0.4309 - accuracy: 0.9064 - val_loss: 0.3461 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5129 - accuracy: 0.8873 - val_loss: 0.2744 - val_accuracy: 0.9067\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.4953 - accuracy: 0.9007 - val_loss: 0.2913 - val_accuracy: 0.8900\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.4160 - accuracy: 0.9250 - val_loss: 0.3012 - val_accuracy: 0.8800\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.4413 - accuracy: 0.9098 - val_loss: 0.2569 - val_accuracy: 0.9067\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.5059 - accuracy: 0.9053 - val_loss: 0.2463 - val_accuracy: 0.9200\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.4717 - accuracy: 0.9048 - val_loss: 0.3309 - val_accuracy: 0.8600\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.4729 - accuracy: 0.9047 - val_loss: 0.3108 - val_accuracy: 0.8717\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4874 - accuracy: 0.9074 - val_loss: 0.3283 - val_accuracy: 0.8817\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.4592 - accuracy: 0.9058 - val_loss: 0.2835 - val_accuracy: 0.8950\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.4612 - accuracy: 0.9040 - val_loss: 0.2779 - val_accuracy: 0.8900\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5059 - accuracy: 0.8940 - val_loss: 0.2290 - val_accuracy: 0.9200\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.3955 - accuracy: 0.9292 - val_loss: 0.4105 - val_accuracy: 0.8167\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.4109 - accuracy: 0.9148 - val_loss: 0.2744 - val_accuracy: 0.9017\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.4739 - accuracy: 0.8901 - val_loss: 0.2596 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4090 - accuracy: 0.9265 - val_loss: 0.2939 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5187 - accuracy: 0.8908 - val_loss: 0.2664 - val_accuracy: 0.9083\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.3733 - accuracy: 0.9260 - val_loss: 0.2297 - val_accuracy: 0.9250\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.3911 - accuracy: 0.9158 - val_loss: 0.2528 - val_accuracy: 0.9250\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.4291 - accuracy: 0.9145 - val_loss: 0.2706 - val_accuracy: 0.8933\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.3915 - accuracy: 0.9156 - val_loss: 0.3027 - val_accuracy: 0.8700\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.4439 - accuracy: 0.8993 - val_loss: 0.3121 - val_accuracy: 0.8900\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.4489 - accuracy: 0.9051 - val_loss: 0.3536 - val_accuracy: 0.8567\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.9117 - val_loss: 0.2881 - val_accuracy: 0.8850\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4112 - accuracy: 0.9193 - val_loss: 0.3227 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.3360 - accuracy: 0.9211 - val_loss: 0.3807 - val_accuracy: 0.8583\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.3679 - accuracy: 0.9198 - val_loss: 0.3283 - val_accuracy: 0.8733\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.9238 - val_loss: 0.2540 - val_accuracy: 0.9100\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.9184 - val_loss: 0.2585 - val_accuracy: 0.9150\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4449 - accuracy: 0.9010 - val_loss: 0.3105 - val_accuracy: 0.8783\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.4471 - accuracy: 0.9167 - val_loss: 0.2675 - val_accuracy: 0.9050\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.4040 - accuracy: 0.9171 - val_loss: 0.2911 - val_accuracy: 0.9000\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1634 - accuracy: 0.6260 - val_loss: 0.4992 - val_accuracy: 0.7767\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.9226 - accuracy: 0.7705 - val_loss: 0.4065 - val_accuracy: 0.8233\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.7647 - accuracy: 0.8027 - val_loss: 0.5069 - val_accuracy: 0.7650\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.7741 - accuracy: 0.8063 - val_loss: 0.4554 - val_accuracy: 0.7967\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.8164 - accuracy: 0.8069 - val_loss: 0.4396 - val_accuracy: 0.8200\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8672 - accuracy: 0.7996 - val_loss: 0.3905 - val_accuracy: 0.8433\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.7856 - accuracy: 0.8264 - val_loss: 0.4251 - val_accuracy: 0.8183\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.7611 - accuracy: 0.8229 - val_loss: 0.3494 - val_accuracy: 0.8700\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.6857 - accuracy: 0.8496 - val_loss: 0.3485 - val_accuracy: 0.8783\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.7167 - accuracy: 0.8656 - val_loss: 0.4481 - val_accuracy: 0.8200\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.7030 - accuracy: 0.8344 - val_loss: 0.5377 - val_accuracy: 0.7733\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.7013 - accuracy: 0.8424 - val_loss: 0.3871 - val_accuracy: 0.8567\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.8578 - val_loss: 0.3923 - val_accuracy: 0.8517\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6756 - accuracy: 0.8561 - val_loss: 0.3398 - val_accuracy: 0.8800\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.7000 - accuracy: 0.8567 - val_loss: 0.3742 - val_accuracy: 0.8433\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.6741 - accuracy: 0.8707 - val_loss: 0.3149 - val_accuracy: 0.8850\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5957 - accuracy: 0.8822 - val_loss: 0.3714 - val_accuracy: 0.8767\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.8628 - val_loss: 0.2974 - val_accuracy: 0.9017\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.6043 - accuracy: 0.8913 - val_loss: 0.3415 - val_accuracy: 0.8750\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6247 - accuracy: 0.8826 - val_loss: 0.3439 - val_accuracy: 0.8850\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.6488 - accuracy: 0.8633 - val_loss: 0.3155 - val_accuracy: 0.8933\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6162 - accuracy: 0.8902 - val_loss: 0.4046 - val_accuracy: 0.8583\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.6266 - accuracy: 0.8759 - val_loss: 0.3399 - val_accuracy: 0.8783\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.6006 - accuracy: 0.8851 - val_loss: 0.3403 - val_accuracy: 0.8733\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.6479 - accuracy: 0.8683 - val_loss: 0.3569 - val_accuracy: 0.8650\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.6264 - accuracy: 0.8755 - val_loss: 0.2946 - val_accuracy: 0.9033\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.6771 - accuracy: 0.8595 - val_loss: 0.3130 - val_accuracy: 0.8983\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.6172 - accuracy: 0.8899 - val_loss: 0.3197 - val_accuracy: 0.8900\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.5516 - accuracy: 0.8958 - val_loss: 0.3988 - val_accuracy: 0.8433\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.6275 - accuracy: 0.8745 - val_loss: 0.3370 - val_accuracy: 0.8817\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.5828 - accuracy: 0.8788 - val_loss: 0.3584 - val_accuracy: 0.8917\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.5716 - accuracy: 0.8941 - val_loss: 0.3134 - val_accuracy: 0.9050\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.5849 - accuracy: 0.8875 - val_loss: 0.3161 - val_accuracy: 0.9017\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5923 - accuracy: 0.8759 - val_loss: 0.3344 - val_accuracy: 0.8983\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.5877 - accuracy: 0.8946 - val_loss: 0.3640 - val_accuracy: 0.8633\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.6011 - accuracy: 0.8748 - val_loss: 0.3570 - val_accuracy: 0.8583\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5774 - accuracy: 0.8904 - val_loss: 0.2885 - val_accuracy: 0.8950\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 748us/step - loss: 0.5812 - accuracy: 0.8919 - val_loss: 0.3187 - val_accuracy: 0.8933\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.5901 - accuracy: 0.8935 - val_loss: 0.4387 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 725us/step - loss: 0.5397 - accuracy: 0.9020 - val_loss: 0.2959 - val_accuracy: 0.9033\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.5185 - accuracy: 0.9045 - val_loss: 0.3438 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.4733 - accuracy: 0.9001 - val_loss: 0.3634 - val_accuracy: 0.8617\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5680 - accuracy: 0.8974 - val_loss: 0.3080 - val_accuracy: 0.8817\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.4973 - accuracy: 0.9045 - val_loss: 0.3478 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.5081 - accuracy: 0.8939 - val_loss: 0.3666 - val_accuracy: 0.8700\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5509 - accuracy: 0.9040 - val_loss: 0.2968 - val_accuracy: 0.8950\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.5568 - accuracy: 0.9076 - val_loss: 0.3867 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 985us/step - loss: 0.5036 - accuracy: 0.8975 - val_loss: 0.2848 - val_accuracy: 0.9033\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5895 - accuracy: 0.8967 - val_loss: 0.2925 - val_accuracy: 0.8950\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.4746 - accuracy: 0.9054 - val_loss: 0.3271 - val_accuracy: 0.8917\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.5133 - accuracy: 0.8934 - val_loss: 0.3937 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.89 - 0s 809us/step - loss: 0.5601 - accuracy: 0.8992 - val_loss: 0.2966 - val_accuracy: 0.8933\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.5055 - accuracy: 0.9053 - val_loss: 0.3256 - val_accuracy: 0.8833\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5492 - accuracy: 0.8896 - val_loss: 0.3090 - val_accuracy: 0.8883\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5271 - accuracy: 0.8925 - val_loss: 0.2791 - val_accuracy: 0.9017\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5175 - accuracy: 0.9149 - val_loss: 0.3631 - val_accuracy: 0.8633\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.4621 - accuracy: 0.9151 - val_loss: 0.3834 - val_accuracy: 0.8417\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.5131 - accuracy: 0.8901 - val_loss: 0.3299 - val_accuracy: 0.8800\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.4682 - accuracy: 0.9096 - val_loss: 0.3732 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5179 - accuracy: 0.8973 - val_loss: 0.3022 - val_accuracy: 0.8967\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.4731 - accuracy: 0.9116 - val_loss: 0.4356 - val_accuracy: 0.8000\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.5199 - accuracy: 0.8935 - val_loss: 0.3093 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5370 - accuracy: 0.8993 - val_loss: 0.2970 - val_accuracy: 0.8950\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.3930 - accuracy: 0.9215 - val_loss: 0.3266 - val_accuracy: 0.8733\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.5171 - accuracy: 0.8999 - val_loss: 0.3565 - val_accuracy: 0.8567\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.4590 - accuracy: 0.8992 - val_loss: 0.3357 - val_accuracy: 0.8850\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5553 - accuracy: 0.8901 - val_loss: 0.3153 - val_accuracy: 0.8833\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.3914 - accuracy: 0.9233 - val_loss: 0.4114 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5331 - accuracy: 0.8785 - val_loss: 0.2935 - val_accuracy: 0.8900\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.4238 - accuracy: 0.9251 - val_loss: 0.3677 - val_accuracy: 0.8483\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.4956 - accuracy: 0.8894 - val_loss: 0.3096 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.4806 - accuracy: 0.8970 - val_loss: 0.2815 - val_accuracy: 0.9083\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5303 - accuracy: 0.9090 - val_loss: 0.2993 - val_accuracy: 0.8800\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.4818 - accuracy: 0.8998 - val_loss: 0.2735 - val_accuracy: 0.9050\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.5776 - accuracy: 0.9006 - val_loss: 0.2566 - val_accuracy: 0.9217\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4300 - accuracy: 0.9187 - val_loss: 0.2672 - val_accuracy: 0.9033\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.9273 - val_loss: 0.2613 - val_accuracy: 0.9083\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.4369 - accuracy: 0.9096 - val_loss: 0.3480 - val_accuracy: 0.8633\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.4938 - accuracy: 0.9025 - val_loss: 0.3037 - val_accuracy: 0.8883\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4409 - accuracy: 0.9157 - val_loss: 0.2644 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.4597 - accuracy: 0.9051 - val_loss: 0.2603 - val_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4787 - accuracy: 0.9027 - val_loss: 0.2567 - val_accuracy: 0.9200\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.4742 - accuracy: 0.9128 - val_loss: 0.3336 - val_accuracy: 0.8517\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.4666 - accuracy: 0.9002 - val_loss: 0.2880 - val_accuracy: 0.8850\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.4628 - accuracy: 0.9095 - val_loss: 0.3528 - val_accuracy: 0.8583\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.4634 - accuracy: 0.9118 - val_loss: 0.2880 - val_accuracy: 0.8900\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.4418 - accuracy: 0.9165 - val_loss: 0.2658 - val_accuracy: 0.9050\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.4244 - accuracy: 0.9131 - val_loss: 0.2743 - val_accuracy: 0.8933\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.4356 - accuracy: 0.9049 - val_loss: 0.2672 - val_accuracy: 0.9067\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.4294 - accuracy: 0.9160 - val_loss: 0.3308 - val_accuracy: 0.8617\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.4040 - accuracy: 0.9229 - val_loss: 0.3124 - val_accuracy: 0.8800\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.4016 - accuracy: 0.9075 - val_loss: 0.3370 - val_accuracy: 0.8633\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.4387 - accuracy: 0.9118 - val_loss: 0.2906 - val_accuracy: 0.8833\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.4464 - accuracy: 0.9219 - val_loss: 0.2959 - val_accuracy: 0.8883\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.4207 - accuracy: 0.9214 - val_loss: 0.2867 - val_accuracy: 0.8950\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2191 - accuracy: 0.6266 - val_loss: 0.5305 - val_accuracy: 0.7233\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.8848 - accuracy: 0.7516 - val_loss: 0.4905 - val_accuracy: 0.7850\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7946 - accuracy: 0.7904 - val_loss: 0.4503 - val_accuracy: 0.7983\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.7727 - accuracy: 0.8047 - val_loss: 0.3703 - val_accuracy: 0.8350\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8167 - accuracy: 0.8211 - val_loss: 0.3935 - val_accuracy: 0.8433\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.7445 - accuracy: 0.8305 - val_loss: 0.4444 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6949 - accuracy: 0.8415 - val_loss: 0.4115 - val_accuracy: 0.8450\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6755 - accuracy: 0.8424 - val_loss: 0.4040 - val_accuracy: 0.8550\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6795 - accuracy: 0.8532 - val_loss: 0.3759 - val_accuracy: 0.8583\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7409 - accuracy: 0.8302 - val_loss: 0.3990 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6677 - accuracy: 0.8487 - val_loss: 0.3418 - val_accuracy: 0.8700\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.6627 - accuracy: 0.8657 - val_loss: 0.2844 - val_accuracy: 0.8917\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 975us/step - loss: 0.7045 - accuracy: 0.8513 - val_loss: 0.3170 - val_accuracy: 0.8833\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.6579 - accuracy: 0.8630 - val_loss: 0.2816 - val_accuracy: 0.8917\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6344 - accuracy: 0.8697 - val_loss: 0.3499 - val_accuracy: 0.8867\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.6285 - accuracy: 0.8714 - val_loss: 0.4264 - val_accuracy: 0.8017\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6338 - accuracy: 0.8665 - val_loss: 0.3301 - val_accuracy: 0.8817\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.6457 - accuracy: 0.8693 - val_loss: 0.2963 - val_accuracy: 0.8733\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.6711 - accuracy: 0.8605 - val_loss: 0.3219 - val_accuracy: 0.8783\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.6534 - accuracy: 0.8585 - val_loss: 0.5025 - val_accuracy: 0.7767\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.6809 - accuracy: 0.8414 - val_loss: 0.3205 - val_accuracy: 0.8833\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5416 - accuracy: 0.8853 - val_loss: 0.3425 - val_accuracy: 0.8767\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.6204 - accuracy: 0.8699 - val_loss: 0.2546 - val_accuracy: 0.9333\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5738 - accuracy: 0.8927 - val_loss: 0.3047 - val_accuracy: 0.8950\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.6685 - accuracy: 0.8784 - val_loss: 0.3071 - val_accuracy: 0.8933\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.6054 - accuracy: 0.8759 - val_loss: 0.3002 - val_accuracy: 0.8883\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5599 - accuracy: 0.8903 - val_loss: 0.3044 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5199 - accuracy: 0.8996 - val_loss: 0.2901 - val_accuracy: 0.9050\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.6269 - accuracy: 0.8757 - val_loss: 0.3070 - val_accuracy: 0.8883\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5469 - accuracy: 0.8821 - val_loss: 0.2919 - val_accuracy: 0.8917\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.5920 - accuracy: 0.8929 - val_loss: 0.3034 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.5672 - accuracy: 0.8886 - val_loss: 0.2905 - val_accuracy: 0.9017\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5454 - accuracy: 0.8907 - val_loss: 0.2627 - val_accuracy: 0.9100\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.5614 - accuracy: 0.8953 - val_loss: 0.3059 - val_accuracy: 0.9100\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5565 - accuracy: 0.9028 - val_loss: 0.2877 - val_accuracy: 0.8967\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5434 - accuracy: 0.8976 - val_loss: 0.2954 - val_accuracy: 0.9083\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5703 - accuracy: 0.8835 - val_loss: 0.3313 - val_accuracy: 0.8967\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5213 - accuracy: 0.9000 - val_loss: 0.3327 - val_accuracy: 0.8817\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5851 - accuracy: 0.8884 - val_loss: 0.2913 - val_accuracy: 0.9200\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.4720 - accuracy: 0.9134 - val_loss: 0.3357 - val_accuracy: 0.8767\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5530 - accuracy: 0.8866 - val_loss: 0.3134 - val_accuracy: 0.9017\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.4495 - accuracy: 0.9088 - val_loss: 0.2965 - val_accuracy: 0.9067\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.4988 - accuracy: 0.9056 - val_loss: 0.3097 - val_accuracy: 0.8933\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1853 - accuracy: 0.5906 - val_loss: 0.3982 - val_accuracy: 0.8267\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.8651 - accuracy: 0.7685 - val_loss: 0.3864 - val_accuracy: 0.8450\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.7924 - accuracy: 0.8099 - val_loss: 0.3252 - val_accuracy: 0.8717\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.6966 - accuracy: 0.8382 - val_loss: 0.3800 - val_accuracy: 0.8550\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.7655 - accuracy: 0.8136 - val_loss: 0.3219 - val_accuracy: 0.8867\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.7259 - accuracy: 0.8339 - val_loss: 0.4161 - val_accuracy: 0.8433\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.7552 - accuracy: 0.8341 - val_loss: 0.3859 - val_accuracy: 0.8700\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.6837 - accuracy: 0.8392 - val_loss: 0.4109 - val_accuracy: 0.8267\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.7514 - accuracy: 0.8130 - val_loss: 0.3412 - val_accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.8489 - val_loss: 0.3064 - val_accuracy: 0.8733\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.8716 - val_loss: 0.4049 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6665 - accuracy: 0.8543 - val_loss: 0.3693 - val_accuracy: 0.8583\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.6831 - accuracy: 0.8505 - val_loss: 0.4405 - val_accuracy: 0.8317\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.6423 - accuracy: 0.8608 - val_loss: 0.3721 - val_accuracy: 0.8650\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.6426 - accuracy: 0.8550 - val_loss: 0.3943 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5930 - accuracy: 0.8642 - val_loss: 0.3558 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.6585 - accuracy: 0.8592 - val_loss: 0.3478 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5837 - accuracy: 0.8714 - val_loss: 0.3412 - val_accuracy: 0.8717\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 778us/step - loss: 0.6538 - accuracy: 0.8627 - val_loss: 0.3328 - val_accuracy: 0.8883\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.5890 - accuracy: 0.8735 - val_loss: 0.3684 - val_accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.6115 - accuracy: 0.8833 - val_loss: 0.3129 - val_accuracy: 0.8967\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6103 - accuracy: 0.8806 - val_loss: 0.4027 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5798 - accuracy: 0.8812 - val_loss: 0.4336 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5753 - accuracy: 0.8762 - val_loss: 0.2733 - val_accuracy: 0.9217\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.6243 - accuracy: 0.8873 - val_loss: 0.2799 - val_accuracy: 0.8967\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5654 - accuracy: 0.8853 - val_loss: 0.3065 - val_accuracy: 0.8967\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.6001 - accuracy: 0.8782 - val_loss: 0.2722 - val_accuracy: 0.9183\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5399 - accuracy: 0.8977 - val_loss: 0.3760 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.5928 - accuracy: 0.8806 - val_loss: 0.3679 - val_accuracy: 0.8817\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6126 - accuracy: 0.8741 - val_loss: 0.3551 - val_accuracy: 0.8817\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5488 - accuracy: 0.8691 - val_loss: 0.3240 - val_accuracy: 0.8917\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6154 - accuracy: 0.8760 - val_loss: 0.3923 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5163 - accuracy: 0.8983 - val_loss: 0.2752 - val_accuracy: 0.9100\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5661 - accuracy: 0.8989 - val_loss: 0.3031 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.4925 - accuracy: 0.8993 - val_loss: 0.2887 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.5679 - accuracy: 0.9009 - val_loss: 0.3721 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5332 - accuracy: 0.8965 - val_loss: 0.4051 - val_accuracy: 0.8517\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5691 - accuracy: 0.8828 - val_loss: 0.2601 - val_accuracy: 0.9083\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.5595 - accuracy: 0.8816 - val_loss: 0.3138 - val_accuracy: 0.8933\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.4828 - accuracy: 0.9096 - val_loss: 0.3851 - val_accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.5225 - accuracy: 0.8968 - val_loss: 0.2596 - val_accuracy: 0.9183\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.4798 - accuracy: 0.9024 - val_loss: 0.3155 - val_accuracy: 0.8883\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.5449 - accuracy: 0.9014 - val_loss: 0.2886 - val_accuracy: 0.9100\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.4836 - accuracy: 0.9029 - val_loss: 0.3244 - val_accuracy: 0.8767\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.4958 - accuracy: 0.8947 - val_loss: 0.3030 - val_accuracy: 0.8817\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.4904 - accuracy: 0.9064 - val_loss: 0.3442 - val_accuracy: 0.8850\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.4911 - accuracy: 0.8893 - val_loss: 0.2720 - val_accuracy: 0.9067\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5069 - accuracy: 0.8992 - val_loss: 0.2972 - val_accuracy: 0.8900\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.4548 - accuracy: 0.9099 - val_loss: 0.2525 - val_accuracy: 0.9100\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5173 - accuracy: 0.9058 - val_loss: 0.2913 - val_accuracy: 0.8883\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.4898 - accuracy: 0.9053 - val_loss: 0.3704 - val_accuracy: 0.8367\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.4971 - accuracy: 0.8943 - val_loss: 0.3362 - val_accuracy: 0.8800\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.4262 - accuracy: 0.9109 - val_loss: 0.3272 - val_accuracy: 0.8717\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4690 - accuracy: 0.9047 - val_loss: 0.3208 - val_accuracy: 0.8833\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.3895 - accuracy: 0.9185 - val_loss: 0.2893 - val_accuracy: 0.8967\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.5128 - accuracy: 0.8899 - val_loss: 0.2373 - val_accuracy: 0.9067\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4108 - accuracy: 0.9114 - val_loss: 0.2626 - val_accuracy: 0.9033\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.4594 - accuracy: 0.8969 - val_loss: 0.2751 - val_accuracy: 0.8967\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.4653 - accuracy: 0.9111 - val_loss: 0.3058 - val_accuracy: 0.8783\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4325 - accuracy: 0.9086 - val_loss: 0.2893 - val_accuracy: 0.8950\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.4367 - accuracy: 0.9110 - val_loss: 0.2771 - val_accuracy: 0.9033\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.4541 - accuracy: 0.9066 - val_loss: 0.2861 - val_accuracy: 0.8883\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.3941 - accuracy: 0.9129 - val_loss: 0.2722 - val_accuracy: 0.8933\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 755us/step - loss: 0.4134 - accuracy: 0.9078 - val_loss: 0.3196 - val_accuracy: 0.8683\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.4480 - accuracy: 0.8937 - val_loss: 0.3539 - val_accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.4381 - accuracy: 0.9219 - val_loss: 0.3584 - val_accuracy: 0.8550\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.8881 - val_loss: 0.2695 - val_accuracy: 0.9033\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4237 - accuracy: 0.9146 - val_loss: 0.3167 - val_accuracy: 0.8850\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4960 - accuracy: 0.8954 - val_loss: 0.3055 - val_accuracy: 0.8817\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5117 - accuracy: 0.8815 - val_loss: 0.2414 - val_accuracy: 0.9050\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 746us/step - loss: 0.4674 - accuracy: 0.9117 - val_loss: 0.3188 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 748us/step - loss: 0.4116 - accuracy: 0.9108 - val_loss: 0.2337 - val_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.4588 - accuracy: 0.9163 - val_loss: 0.2909 - val_accuracy: 0.8950\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4401 - accuracy: 0.9107 - val_loss: 0.3606 - val_accuracy: 0.8633\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.5443 - accuracy: 0.8928 - val_loss: 0.2995 - val_accuracy: 0.8867\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.4029 - accuracy: 0.9132 - val_loss: 0.2549 - val_accuracy: 0.9100\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.4056 - accuracy: 0.9064 - val_loss: 0.2997 - val_accuracy: 0.8867\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.3985 - accuracy: 0.9155 - val_loss: 0.3405 - val_accuracy: 0.8700\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4585 - accuracy: 0.9071 - val_loss: 0.2484 - val_accuracy: 0.9050\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 735us/step - loss: 0.4687 - accuracy: 0.9154 - val_loss: 0.2967 - val_accuracy: 0.8950\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.4133 - accuracy: 0.9133 - val_loss: 0.3560 - val_accuracy: 0.8567\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4905 - accuracy: 0.8901 - val_loss: 0.3382 - val_accuracy: 0.8850\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 743us/step - loss: 0.4242 - accuracy: 0.9143 - val_loss: 0.3060 - val_accuracy: 0.8867\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 744us/step - loss: 0.3800 - accuracy: 0.9189 - val_loss: 0.3273 - val_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.3809 - accuracy: 0.9186 - val_loss: 0.2467 - val_accuracy: 0.9117\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 763us/step - loss: 0.3873 - accuracy: 0.9259 - val_loss: 0.3213 - val_accuracy: 0.8717\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.3911 - accuracy: 0.9169 - val_loss: 0.3550 - val_accuracy: 0.8750\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4325 - accuracy: 0.9062 - val_loss: 0.3109 - val_accuracy: 0.8833\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.4563 - accuracy: 0.9025 - val_loss: 0.3238 - val_accuracy: 0.8683\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.4038 - accuracy: 0.9091 - val_loss: 0.3148 - val_accuracy: 0.8817\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.3708 - accuracy: 0.9165 - val_loss: 0.2909 - val_accuracy: 0.8983\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.4504 - accuracy: 0.9162 - val_loss: 0.2884 - val_accuracy: 0.9050\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2349 - accuracy: 0.6063 - val_loss: 0.5129 - val_accuracy: 0.7517\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 751us/step - loss: 0.9422 - accuracy: 0.7339 - val_loss: 0.4322 - val_accuracy: 0.8083\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.8583 - accuracy: 0.7958 - val_loss: 0.3754 - val_accuracy: 0.8617\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.7919 - accuracy: 0.8085 - val_loss: 0.4627 - val_accuracy: 0.8083\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.7814 - accuracy: 0.8016 - val_loss: 0.3666 - val_accuracy: 0.8467\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.7775 - accuracy: 0.8193 - val_loss: 0.4338 - val_accuracy: 0.8150\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.7506 - accuracy: 0.8238 - val_loss: 0.3839 - val_accuracy: 0.8283\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 760us/step - loss: 0.7003 - accuracy: 0.8430 - val_loss: 0.3837 - val_accuracy: 0.8367\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 740us/step - loss: 0.6900 - accuracy: 0.8388 - val_loss: 0.3413 - val_accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.8047 - accuracy: 0.8512 - val_loss: 0.3232 - val_accuracy: 0.8833\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.7921 - accuracy: 0.8326 - val_loss: 0.3402 - val_accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.6867 - accuracy: 0.8611 - val_loss: 0.2923 - val_accuracy: 0.8933\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.7152 - accuracy: 0.8564 - val_loss: 0.3423 - val_accuracy: 0.8833\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.6948 - accuracy: 0.8622 - val_loss: 0.3601 - val_accuracy: 0.8700\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 765us/step - loss: 0.6315 - accuracy: 0.8604 - val_loss: 0.3417 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.7104 - accuracy: 0.8668 - val_loss: 0.3759 - val_accuracy: 0.8400\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 747us/step - loss: 0.6172 - accuracy: 0.8843 - val_loss: 0.3435 - val_accuracy: 0.8800\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.7252 - accuracy: 0.8586 - val_loss: 0.3369 - val_accuracy: 0.8783\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5895 - accuracy: 0.8891 - val_loss: 0.3736 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.6992 - accuracy: 0.8529 - val_loss: 0.2497 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.5656 - accuracy: 0.8914 - val_loss: 0.3351 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 759us/step - loss: 0.5818 - accuracy: 0.8762 - val_loss: 0.3315 - val_accuracy: 0.8933\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.6026 - accuracy: 0.8946 - val_loss: 0.3204 - val_accuracy: 0.8900\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 752us/step - loss: 0.6041 - accuracy: 0.8716 - val_loss: 0.3294 - val_accuracy: 0.8867\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.5812 - accuracy: 0.8913 - val_loss: 0.3106 - val_accuracy: 0.8850\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.6281 - accuracy: 0.8827 - val_loss: 0.3172 - val_accuracy: 0.8933\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.6321 - accuracy: 0.8850 - val_loss: 0.2956 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.5644 - accuracy: 0.8892 - val_loss: 0.3311 - val_accuracy: 0.8817\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.5121 - accuracy: 0.8937 - val_loss: 0.2944 - val_accuracy: 0.9033\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.8797 - val_loss: 0.2739 - val_accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.5248 - accuracy: 0.9066 - val_loss: 0.2680 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.4798 - accuracy: 0.9055 - val_loss: 0.2706 - val_accuracy: 0.9133\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5080 - accuracy: 0.8986 - val_loss: 0.3287 - val_accuracy: 0.8717\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4566 - accuracy: 0.9053 - val_loss: 0.3876 - val_accuracy: 0.8517\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5714 - accuracy: 0.8861 - val_loss: 0.3535 - val_accuracy: 0.8683\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5307 - accuracy: 0.8871 - val_loss: 0.3295 - val_accuracy: 0.8850\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.5200 - accuracy: 0.9007 - val_loss: 0.3817 - val_accuracy: 0.8650\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6110 - accuracy: 0.8835 - val_loss: 0.3253 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.4738 - accuracy: 0.9048 - val_loss: 0.3877 - val_accuracy: 0.8733\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.5271 - accuracy: 0.8890 - val_loss: 0.2853 - val_accuracy: 0.8967\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2199 - accuracy: 0.6114 - val_loss: 0.6969 - val_accuracy: 0.6483\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 1.0113 - accuracy: 0.7089 - val_loss: 0.6005 - val_accuracy: 0.7133\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.7992 - accuracy: 0.7841 - val_loss: 0.4283 - val_accuracy: 0.8300\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.7552 - accuracy: 0.8146 - val_loss: 0.3839 - val_accuracy: 0.8433\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.7516 - accuracy: 0.8276 - val_loss: 0.4145 - val_accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 748us/step - loss: 0.7665 - accuracy: 0.8234 - val_loss: 0.3133 - val_accuracy: 0.8617\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.6735 - accuracy: 0.8474 - val_loss: 0.5168 - val_accuracy: 0.7717\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 753us/step - loss: 0.7741 - accuracy: 0.8195 - val_loss: 0.3078 - val_accuracy: 0.8950\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.7319 - accuracy: 0.8598 - val_loss: 0.3204 - val_accuracy: 0.8883\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 788us/step - loss: 0.7551 - accuracy: 0.8536 - val_loss: 0.3008 - val_accuracy: 0.8883\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.6712 - accuracy: 0.8456 - val_loss: 0.3490 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.7036 - accuracy: 0.8374 - val_loss: 0.3627 - val_accuracy: 0.8617\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.6590 - accuracy: 0.8631 - val_loss: 0.3292 - val_accuracy: 0.8800\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.6787 - accuracy: 0.8687 - val_loss: 0.2830 - val_accuracy: 0.8933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.6511 - accuracy: 0.8823 - val_loss: 0.5023 - val_accuracy: 0.8133\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6535 - accuracy: 0.8500 - val_loss: 0.3066 - val_accuracy: 0.8883\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6422 - accuracy: 0.8797 - val_loss: 0.3929 - val_accuracy: 0.8550\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.6282 - accuracy: 0.8636 - val_loss: 0.3949 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6829 - accuracy: 0.8627 - val_loss: 0.3697 - val_accuracy: 0.8600\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5936 - accuracy: 0.8835 - val_loss: 0.2881 - val_accuracy: 0.8983\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.6183 - accuracy: 0.8725 - val_loss: 0.3612 - val_accuracy: 0.8767\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.6273 - accuracy: 0.8795 - val_loss: 0.3278 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6236 - accuracy: 0.8833 - val_loss: 0.3468 - val_accuracy: 0.8683\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.5758 - accuracy: 0.8965 - val_loss: 0.4472 - val_accuracy: 0.8417\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 940us/step - loss: 0.6199 - accuracy: 0.8804 - val_loss: 0.3162 - val_accuracy: 0.9050\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.6442 - accuracy: 0.8818 - val_loss: 0.3302 - val_accuracy: 0.8883\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.5635 - accuracy: 0.8921 - val_loss: 0.3323 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6143 - accuracy: 0.8990 - val_loss: 0.2488 - val_accuracy: 0.9217\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5776 - accuracy: 0.8965 - val_loss: 0.3447 - val_accuracy: 0.8833\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 776us/step - loss: 0.6785 - accuracy: 0.8745 - val_loss: 0.2840 - val_accuracy: 0.9033\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.5927 - accuracy: 0.8915 - val_loss: 0.3379 - val_accuracy: 0.8850\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.6312 - accuracy: 0.8864 - val_loss: 0.3213 - val_accuracy: 0.8833\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5613 - accuracy: 0.8976 - val_loss: 0.2611 - val_accuracy: 0.9117\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5689 - accuracy: 0.8989 - val_loss: 0.3357 - val_accuracy: 0.8817\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.5939 - accuracy: 0.8953 - val_loss: 0.2630 - val_accuracy: 0.9133\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.5866 - accuracy: 0.9035 - val_loss: 0.3257 - val_accuracy: 0.8933\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5615 - accuracy: 0.8995 - val_loss: 0.2434 - val_accuracy: 0.9233\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.5812 - accuracy: 0.8974 - val_loss: 0.3164 - val_accuracy: 0.8950\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5579 - accuracy: 0.9033 - val_loss: 0.2379 - val_accuracy: 0.9367\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.4540 - accuracy: 0.9233 - val_loss: 0.2723 - val_accuracy: 0.9267\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.5476 - accuracy: 0.8976 - val_loss: 0.2717 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.9005 - val_loss: 0.3999 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.5628 - accuracy: 0.8891 - val_loss: 0.3014 - val_accuracy: 0.8900\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.9027 - val_loss: 0.2558 - val_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.4635 - accuracy: 0.9137 - val_loss: 0.2732 - val_accuracy: 0.9167\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.5472 - accuracy: 0.9046 - val_loss: 0.2807 - val_accuracy: 0.9033\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.4550 - accuracy: 0.9180 - val_loss: 0.2911 - val_accuracy: 0.9067\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 768us/step - loss: 0.4566 - accuracy: 0.9122 - val_loss: 0.3430 - val_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5405 - accuracy: 0.8985 - val_loss: 0.2413 - val_accuracy: 0.9217\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.4441 - accuracy: 0.9244 - val_loss: 0.2812 - val_accuracy: 0.9117\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4811 - accuracy: 0.9247 - val_loss: 0.3414 - val_accuracy: 0.8883\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.5281 - accuracy: 0.8913 - val_loss: 0.3005 - val_accuracy: 0.8983\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 783us/step - loss: 0.5209 - accuracy: 0.8935 - val_loss: 0.2601 - val_accuracy: 0.9133\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.4676 - accuracy: 0.9086 - val_loss: 0.2746 - val_accuracy: 0.9267\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 760us/step - loss: 0.5045 - accuracy: 0.9157 - val_loss: 0.2594 - val_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.5599 - accuracy: 0.8847 - val_loss: 0.2355 - val_accuracy: 0.9367\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.5834 - accuracy: 0.8955 - val_loss: 0.2118 - val_accuracy: 0.9467\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 900us/step - loss: 0.4450 - accuracy: 0.9240 - val_loss: 0.2514 - val_accuracy: 0.9183\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 750us/step - loss: 0.4424 - accuracy: 0.9128 - val_loss: 0.2773 - val_accuracy: 0.9083\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.4512 - accuracy: 0.9234 - val_loss: 0.3265 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.4764 - accuracy: 0.9023 - val_loss: 0.2710 - val_accuracy: 0.9183\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.4202 - accuracy: 0.9224 - val_loss: 0.2369 - val_accuracy: 0.9200\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.4323 - accuracy: 0.9134 - val_loss: 0.2336 - val_accuracy: 0.9217\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.5363 - accuracy: 0.8973 - val_loss: 0.2206 - val_accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.5176 - accuracy: 0.9116 - val_loss: 0.3443 - val_accuracy: 0.8817\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5489 - accuracy: 0.8918 - val_loss: 0.2483 - val_accuracy: 0.9133\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.4275 - accuracy: 0.9224 - val_loss: 0.2694 - val_accuracy: 0.9200\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.9186 - val_loss: 0.3247 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.5094 - accuracy: 0.9081 - val_loss: 0.2514 - val_accuracy: 0.9250\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.4453 - accuracy: 0.9182 - val_loss: 0.3656 - val_accuracy: 0.8567\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.4349 - accuracy: 0.9088 - val_loss: 0.3206 - val_accuracy: 0.8817\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.4286 - accuracy: 0.9200 - val_loss: 0.2093 - val_accuracy: 0.9400\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.4410 - accuracy: 0.9142 - val_loss: 0.2975 - val_accuracy: 0.9083\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.3832 - accuracy: 0.9176 - val_loss: 0.2133 - val_accuracy: 0.9267\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.89 - 0s 814us/step - loss: 0.4877 - accuracy: 0.8924 - val_loss: 0.2050 - val_accuracy: 0.9350\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.4366 - accuracy: 0.9249 - val_loss: 0.2238 - val_accuracy: 0.9283\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.4414 - accuracy: 0.9257 - val_loss: 0.2579 - val_accuracy: 0.9133\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.4889 - accuracy: 0.9082 - val_loss: 0.2823 - val_accuracy: 0.9033\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 985us/step - loss: 0.4217 - accuracy: 0.9153 - val_loss: 0.2860 - val_accuracy: 0.8950\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.3853 - accuracy: 0.9291 - val_loss: 0.2405 - val_accuracy: 0.9133\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5064 - accuracy: 0.9102 - val_loss: 0.2699 - val_accuracy: 0.8850\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.3668 - accuracy: 0.9288 - val_loss: 0.3577 - val_accuracy: 0.8533\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.3976 - accuracy: 0.9229 - val_loss: 0.2653 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.4257 - accuracy: 0.9220 - val_loss: 0.2918 - val_accuracy: 0.8833\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.3575 - accuracy: 0.9348 - val_loss: 0.2699 - val_accuracy: 0.9033\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.4733 - accuracy: 0.9065 - val_loss: 0.2397 - val_accuracy: 0.9150\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.3918 - accuracy: 0.9282 - val_loss: 0.2586 - val_accuracy: 0.9100\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.3223 - accuracy: 0.9436 - val_loss: 0.3065 - val_accuracy: 0.8867\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4139 - accuracy: 0.9277 - val_loss: 0.2249 - val_accuracy: 0.9183\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.3731 - accuracy: 0.9286 - val_loss: 0.3141 - val_accuracy: 0.8950\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4805 - accuracy: 0.8991 - val_loss: 0.2801 - val_accuracy: 0.8850\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.3493 - accuracy: 0.9329 - val_loss: 0.2910 - val_accuracy: 0.8850\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.4136 - accuracy: 0.9218 - val_loss: 0.2573 - val_accuracy: 0.9083\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4242 - accuracy: 0.9274 - val_loss: 0.2508 - val_accuracy: 0.9117\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.4349 - accuracy: 0.9137 - val_loss: 0.2662 - val_accuracy: 0.8967\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2066 - accuracy: 0.6167 - val_loss: 0.5471 - val_accuracy: 0.7250\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.8350 - accuracy: 0.7659 - val_loss: 0.4322 - val_accuracy: 0.8017\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7873 - accuracy: 0.8205 - val_loss: 0.4137 - val_accuracy: 0.8317\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.7860 - accuracy: 0.8166 - val_loss: 0.3672 - val_accuracy: 0.8517\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.6736 - accuracy: 0.8338 - val_loss: 0.3431 - val_accuracy: 0.8650\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.7370 - accuracy: 0.8468 - val_loss: 0.4084 - val_accuracy: 0.8383\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6346 - accuracy: 0.8408 - val_loss: 0.3355 - val_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7867 - accuracy: 0.8315 - val_loss: 0.3003 - val_accuracy: 0.8900\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.6833 - accuracy: 0.8592 - val_loss: 0.3957 - val_accuracy: 0.8450\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.6805 - accuracy: 0.8464 - val_loss: 0.2820 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.8604 - val_loss: 0.3964 - val_accuracy: 0.8467\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.8315 - accuracy: 0.8314 - val_loss: 0.3040 - val_accuracy: 0.8917\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7325 - accuracy: 0.8465 - val_loss: 0.2864 - val_accuracy: 0.9050\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.6540 - accuracy: 0.8646 - val_loss: 0.2922 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.6491 - accuracy: 0.8677 - val_loss: 0.3679 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.6093 - accuracy: 0.8746 - val_loss: 0.3673 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6417 - accuracy: 0.8733 - val_loss: 0.4534 - val_accuracy: 0.8267\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6628 - accuracy: 0.8544 - val_loss: 0.3306 - val_accuracy: 0.8817\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.6193 - accuracy: 0.8647 - val_loss: 0.3185 - val_accuracy: 0.8950\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6642 - accuracy: 0.8769 - val_loss: 0.3345 - val_accuracy: 0.8850\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.6750 - accuracy: 0.8618 - val_loss: 0.2789 - val_accuracy: 0.9100\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.6195 - accuracy: 0.8888 - val_loss: 0.3958 - val_accuracy: 0.8450\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.6130 - accuracy: 0.8803 - val_loss: 0.3333 - val_accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5803 - accuracy: 0.8916 - val_loss: 0.3462 - val_accuracy: 0.8767\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6244 - accuracy: 0.8671 - val_loss: 0.3555 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5931 - accuracy: 0.8878 - val_loss: 0.2649 - val_accuracy: 0.9017\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5733 - accuracy: 0.9033 - val_loss: 0.3158 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6079 - accuracy: 0.8870 - val_loss: 0.2796 - val_accuracy: 0.9050\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6287 - accuracy: 0.8904 - val_loss: 0.2440 - val_accuracy: 0.9267\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5789 - accuracy: 0.8997 - val_loss: 0.3076 - val_accuracy: 0.9033\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5662 - accuracy: 0.8880 - val_loss: 0.3008 - val_accuracy: 0.8917\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.5382 - accuracy: 0.9040 - val_loss: 0.3042 - val_accuracy: 0.8950\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.4882 - accuracy: 0.8974 - val_loss: 0.3305 - val_accuracy: 0.8933\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.6438 - accuracy: 0.8690 - val_loss: 0.2730 - val_accuracy: 0.9117\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.4807 - accuracy: 0.9037 - val_loss: 0.2731 - val_accuracy: 0.9033\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 757us/step - loss: 0.5636 - accuracy: 0.8907 - val_loss: 0.2901 - val_accuracy: 0.9133\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5066 - accuracy: 0.9011 - val_loss: 0.3241 - val_accuracy: 0.8850\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5011 - accuracy: 0.8843 - val_loss: 0.3941 - val_accuracy: 0.8450\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.5097 - accuracy: 0.9021 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.5400 - accuracy: 0.8864 - val_loss: 0.1951 - val_accuracy: 0.9383\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.5150 - accuracy: 0.9049 - val_loss: 0.2743 - val_accuracy: 0.9017\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.4875 - accuracy: 0.9063 - val_loss: 0.2794 - val_accuracy: 0.8967\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 758us/step - loss: 0.5434 - accuracy: 0.9044 - val_loss: 0.3029 - val_accuracy: 0.9033\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6042 - accuracy: 0.8943 - val_loss: 0.3078 - val_accuracy: 0.8867\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 900us/step - loss: 0.5571 - accuracy: 0.8924 - val_loss: 0.2057 - val_accuracy: 0.9367\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5397 - accuracy: 0.9110 - val_loss: 0.2394 - val_accuracy: 0.9317\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.5349 - accuracy: 0.9096 - val_loss: 0.2763 - val_accuracy: 0.9033\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.4549 - accuracy: 0.9194 - val_loss: 0.2330 - val_accuracy: 0.9317\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5191 - accuracy: 0.9117 - val_loss: 0.2113 - val_accuracy: 0.9400\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5137 - accuracy: 0.9092 - val_loss: 0.2898 - val_accuracy: 0.8967\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.4885 - accuracy: 0.9071 - val_loss: 0.3000 - val_accuracy: 0.8817\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.9153 - val_loss: 0.3367 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4094 - accuracy: 0.9156 - val_loss: 0.2456 - val_accuracy: 0.9283\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.5172 - accuracy: 0.9044 - val_loss: 0.2834 - val_accuracy: 0.9017\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.4964 - accuracy: 0.8949 - val_loss: 0.2301 - val_accuracy: 0.9267\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.3836 - accuracy: 0.9277 - val_loss: 0.2910 - val_accuracy: 0.9050\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5037 - accuracy: 0.8957 - val_loss: 0.2680 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.5446 - accuracy: 0.8969 - val_loss: 0.2576 - val_accuracy: 0.9200\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.4340 - accuracy: 0.9166 - val_loss: 0.2057 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4066 - accuracy: 0.9271 - val_loss: 0.2572 - val_accuracy: 0.9117\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1782 - accuracy: 0.6344 - val_loss: 0.4417 - val_accuracy: 0.8300\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.9173 - accuracy: 0.7470 - val_loss: 0.4238 - val_accuracy: 0.8267\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.8035 - accuracy: 0.8054 - val_loss: 0.4176 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8307 - accuracy: 0.7984 - val_loss: 0.4310 - val_accuracy: 0.8217\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7478 - accuracy: 0.8128 - val_loss: 0.3464 - val_accuracy: 0.8633\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.7814 - accuracy: 0.8187 - val_loss: 0.3876 - val_accuracy: 0.8533\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7597 - accuracy: 0.8368 - val_loss: 0.4017 - val_accuracy: 0.8567\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 902us/step - loss: 0.7447 - accuracy: 0.8315 - val_loss: 0.3766 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6852 - accuracy: 0.8635 - val_loss: 0.3575 - val_accuracy: 0.8683\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.6728 - accuracy: 0.8380 - val_loss: 0.3839 - val_accuracy: 0.8583\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6825 - accuracy: 0.8585 - val_loss: 0.3318 - val_accuracy: 0.8867\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.6537 - accuracy: 0.8695 - val_loss: 0.3203 - val_accuracy: 0.8833\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6377 - accuracy: 0.8602 - val_loss: 0.3343 - val_accuracy: 0.8783\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.6655 - accuracy: 0.8606 - val_loss: 0.3409 - val_accuracy: 0.8833\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.6236 - accuracy: 0.8707 - val_loss: 0.4609 - val_accuracy: 0.8050\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6486 - accuracy: 0.8500 - val_loss: 0.3731 - val_accuracy: 0.8683\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5563 - accuracy: 0.8823 - val_loss: 0.4509 - val_accuracy: 0.8367\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 0.7058 - accuracy: 0.8618 - val_loss: 0.4285 - val_accuracy: 0.8367\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6543 - accuracy: 0.8734 - val_loss: 0.3582 - val_accuracy: 0.8733\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.6616 - accuracy: 0.8831 - val_loss: 0.3544 - val_accuracy: 0.8750\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5653 - accuracy: 0.8778 - val_loss: 0.3337 - val_accuracy: 0.8867\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6370 - accuracy: 0.9042 - val_loss: 0.3504 - val_accuracy: 0.8833\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5661 - accuracy: 0.8898 - val_loss: 0.3172 - val_accuracy: 0.8933\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.8942 - val_loss: 0.2562 - val_accuracy: 0.9150\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6377 - accuracy: 0.8733 - val_loss: 0.3051 - val_accuracy: 0.9083\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6044 - accuracy: 0.8822 - val_loss: 0.2548 - val_accuracy: 0.9250\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5614 - accuracy: 0.9010 - val_loss: 0.3197 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.6135 - accuracy: 0.8867 - val_loss: 0.3170 - val_accuracy: 0.8950\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.5057 - accuracy: 0.9086 - val_loss: 0.2660 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5485 - accuracy: 0.8939 - val_loss: 0.3494 - val_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5866 - accuracy: 0.8883 - val_loss: 0.3199 - val_accuracy: 0.8917\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.5912 - accuracy: 0.8981 - val_loss: 0.2912 - val_accuracy: 0.8983\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.5432 - accuracy: 0.8995 - val_loss: 0.2399 - val_accuracy: 0.9183\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.6051 - accuracy: 0.8816 - val_loss: 0.2574 - val_accuracy: 0.9050\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5118 - accuracy: 0.9155 - val_loss: 0.2646 - val_accuracy: 0.9200\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.4786 - accuracy: 0.9165 - val_loss: 0.2547 - val_accuracy: 0.9167\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.5314 - accuracy: 0.8907 - val_loss: 0.3075 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5356 - accuracy: 0.8902 - val_loss: 0.3257 - val_accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5478 - accuracy: 0.8876 - val_loss: 0.2077 - val_accuracy: 0.9283\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.5084 - accuracy: 0.9071 - val_loss: 0.3159 - val_accuracy: 0.8867\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.8953 - val_loss: 0.3274 - val_accuracy: 0.8950\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.5066 - accuracy: 0.8967 - val_loss: 0.2400 - val_accuracy: 0.9067\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6383 - accuracy: 0.8811 - val_loss: 0.2683 - val_accuracy: 0.9150\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5406 - accuracy: 0.9104 - val_loss: 0.2638 - val_accuracy: 0.9067\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.5099 - accuracy: 0.9115 - val_loss: 0.2934 - val_accuracy: 0.8983\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5026 - accuracy: 0.9008 - val_loss: 0.2776 - val_accuracy: 0.9083\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5039 - accuracy: 0.9123 - val_loss: 0.3480 - val_accuracy: 0.8700\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5493 - accuracy: 0.8938 - val_loss: 0.2983 - val_accuracy: 0.8900\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.5765 - accuracy: 0.8967 - val_loss: 0.3154 - val_accuracy: 0.8983\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 790us/step - loss: 0.4495 - accuracy: 0.9161 - val_loss: 0.3063 - val_accuracy: 0.8983\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.4706 - accuracy: 0.8924 - val_loss: 0.2649 - val_accuracy: 0.9100\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5371 - accuracy: 0.8948 - val_loss: 0.2381 - val_accuracy: 0.9183\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.5276 - accuracy: 0.9050 - val_loss: 0.2664 - val_accuracy: 0.9050\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5317 - accuracy: 0.9082 - val_loss: 0.2997 - val_accuracy: 0.9083\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.4799 - accuracy: 0.9049 - val_loss: 0.3153 - val_accuracy: 0.8950\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.5219 - accuracy: 0.9183 - val_loss: 0.2304 - val_accuracy: 0.9317\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5016 - accuracy: 0.9085 - val_loss: 0.2769 - val_accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5393 - accuracy: 0.8994 - val_loss: 0.2480 - val_accuracy: 0.9067\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.4478 - accuracy: 0.9131 - val_loss: 0.3282 - val_accuracy: 0.8783\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2067 - accuracy: 0.6065 - val_loss: 0.6232 - val_accuracy: 0.6600\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.9562 - accuracy: 0.7169 - val_loss: 0.4715 - val_accuracy: 0.7733\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.9167 - accuracy: 0.7630 - val_loss: 0.4690 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.8548 - accuracy: 0.7986 - val_loss: 0.4321 - val_accuracy: 0.8183\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.7976 - accuracy: 0.8143 - val_loss: 0.4115 - val_accuracy: 0.8283\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7682 - accuracy: 0.8173 - val_loss: 0.3978 - val_accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7498 - accuracy: 0.8252 - val_loss: 0.3453 - val_accuracy: 0.8800\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.7806 - accuracy: 0.8319 - val_loss: 0.3811 - val_accuracy: 0.8550\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.6793 - accuracy: 0.8473 - val_loss: 0.3342 - val_accuracy: 0.8733\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.6472 - accuracy: 0.8560 - val_loss: 0.3804 - val_accuracy: 0.8467\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7470 - accuracy: 0.8327 - val_loss: 0.3370 - val_accuracy: 0.8833\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.7640 - accuracy: 0.8329 - val_loss: 0.3184 - val_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6418 - accuracy: 0.8787 - val_loss: 0.3192 - val_accuracy: 0.8800\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.7582 - accuracy: 0.8571 - val_loss: 0.3403 - val_accuracy: 0.8900\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5700 - accuracy: 0.8833 - val_loss: 0.4545 - val_accuracy: 0.8200\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6327 - accuracy: 0.8598 - val_loss: 0.2898 - val_accuracy: 0.8883\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.6734 - accuracy: 0.8707 - val_loss: 0.3225 - val_accuracy: 0.8817\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.6658 - accuracy: 0.8511 - val_loss: 0.3378 - val_accuracy: 0.8783\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.6474 - accuracy: 0.8784 - val_loss: 0.3969 - val_accuracy: 0.8617\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.6376 - accuracy: 0.8647 - val_loss: 0.3081 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5543 - accuracy: 0.8905 - val_loss: 0.4050 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.6336 - accuracy: 0.8701 - val_loss: 0.2736 - val_accuracy: 0.9100\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6627 - accuracy: 0.8778 - val_loss: 0.2698 - val_accuracy: 0.9017\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.6989 - accuracy: 0.8742 - val_loss: 0.2354 - val_accuracy: 0.9217\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5738 - accuracy: 0.8956 - val_loss: 0.3547 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6011 - accuracy: 0.8781 - val_loss: 0.3275 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.5707 - accuracy: 0.8891 - val_loss: 0.2602 - val_accuracy: 0.9133\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5965 - accuracy: 0.8903 - val_loss: 0.4508 - val_accuracy: 0.8267\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6557 - accuracy: 0.8577 - val_loss: 0.3649 - val_accuracy: 0.8783\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5247 - accuracy: 0.9002 - val_loss: 0.2864 - val_accuracy: 0.8950\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.6812 - accuracy: 0.8737 - val_loss: 0.3009 - val_accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5339 - accuracy: 0.8975 - val_loss: 0.3227 - val_accuracy: 0.8867\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.8721 - val_loss: 0.4557 - val_accuracy: 0.8183\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5432 - accuracy: 0.8904 - val_loss: 0.2839 - val_accuracy: 0.9117\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 900us/step - loss: 0.5861 - accuracy: 0.8846 - val_loss: 0.2825 - val_accuracy: 0.9033\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5542 - accuracy: 0.8929 - val_loss: 0.3999 - val_accuracy: 0.8383\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6515 - accuracy: 0.8664 - val_loss: 0.3449 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5304 - accuracy: 0.8838 - val_loss: 0.2619 - val_accuracy: 0.9117\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.5991 - accuracy: 0.8862 - val_loss: 0.3313 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5570 - accuracy: 0.8851 - val_loss: 0.2737 - val_accuracy: 0.9083\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.6320 - accuracy: 0.8915 - val_loss: 0.3077 - val_accuracy: 0.8917\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5581 - accuracy: 0.8932 - val_loss: 0.2974 - val_accuracy: 0.8900\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.5671 - accuracy: 0.8909 - val_loss: 0.2700 - val_accuracy: 0.9300\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.5237 - accuracy: 0.9094 - val_loss: 0.2545 - val_accuracy: 0.9033\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2536 - accuracy: 0.5963 - val_loss: 0.5664 - val_accuracy: 0.7350\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9142 - accuracy: 0.7493 - val_loss: 0.4551 - val_accuracy: 0.7833\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.8132 - accuracy: 0.7823 - val_loss: 0.3934 - val_accuracy: 0.8533\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.8445 - accuracy: 0.7939 - val_loss: 0.4902 - val_accuracy: 0.7750\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.7434 - accuracy: 0.8269 - val_loss: 0.4834 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.7819 - accuracy: 0.8153 - val_loss: 0.3441 - val_accuracy: 0.8583\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.7766 - accuracy: 0.8285 - val_loss: 0.4112 - val_accuracy: 0.8367\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.7525 - accuracy: 0.8212 - val_loss: 0.3666 - val_accuracy: 0.8450\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7535 - accuracy: 0.8219 - val_loss: 0.3509 - val_accuracy: 0.8700\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7511 - accuracy: 0.8240 - val_loss: 0.3778 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.6936 - accuracy: 0.8410 - val_loss: 0.3856 - val_accuracy: 0.8583\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.7066 - accuracy: 0.8495 - val_loss: 0.2948 - val_accuracy: 0.8833\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.6825 - accuracy: 0.8496 - val_loss: 0.2613 - val_accuracy: 0.9033\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.6470 - accuracy: 0.8607 - val_loss: 0.3434 - val_accuracy: 0.8783\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.6930 - accuracy: 0.8571 - val_loss: 0.3559 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 762us/step - loss: 0.6791 - accuracy: 0.8368 - val_loss: 0.2885 - val_accuracy: 0.8917\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.7797 - accuracy: 0.8251 - val_loss: 0.3159 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6958 - accuracy: 0.8474 - val_loss: 0.3567 - val_accuracy: 0.8633\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6548 - accuracy: 0.8648 - val_loss: 0.3433 - val_accuracy: 0.8483\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6869 - accuracy: 0.8478 - val_loss: 0.2544 - val_accuracy: 0.9067\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5659 - accuracy: 0.8858 - val_loss: 0.3828 - val_accuracy: 0.8517\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.5774 - accuracy: 0.8769 - val_loss: 0.4134 - val_accuracy: 0.8217\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5992 - accuracy: 0.8679 - val_loss: 0.3948 - val_accuracy: 0.8467\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.5903 - accuracy: 0.8791 - val_loss: 0.2728 - val_accuracy: 0.8983\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.6312 - accuracy: 0.8829 - val_loss: 0.2984 - val_accuracy: 0.9100\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 902us/step - loss: 0.6375 - accuracy: 0.8808 - val_loss: 0.4059 - val_accuracy: 0.8367\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.8606 - val_loss: 0.2789 - val_accuracy: 0.8950\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.5436 - accuracy: 0.8909 - val_loss: 0.3234 - val_accuracy: 0.8900\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.5918 - accuracy: 0.8710 - val_loss: 0.2852 - val_accuracy: 0.8983\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6563 - accuracy: 0.8885 - val_loss: 0.4485 - val_accuracy: 0.8017\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.6162 - accuracy: 0.8651 - val_loss: 0.2712 - val_accuracy: 0.9133\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.6271 - accuracy: 0.8777 - val_loss: 0.2738 - val_accuracy: 0.9017\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5523 - accuracy: 0.8916 - val_loss: 0.2866 - val_accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 890us/step - loss: 0.5540 - accuracy: 0.8881 - val_loss: 0.2016 - val_accuracy: 0.9350\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.5903 - accuracy: 0.8879 - val_loss: 0.2947 - val_accuracy: 0.9100\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5265 - accuracy: 0.8923 - val_loss: 0.2282 - val_accuracy: 0.9233\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5989 - accuracy: 0.8855 - val_loss: 0.2909 - val_accuracy: 0.8983\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5333 - accuracy: 0.8897 - val_loss: 0.3330 - val_accuracy: 0.8983\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.8990 - val_loss: 0.3579 - val_accuracy: 0.8700\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.8961 - val_loss: 0.3004 - val_accuracy: 0.8767\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.5899 - accuracy: 0.8901 - val_loss: 0.2475 - val_accuracy: 0.9267\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5691 - accuracy: 0.8978 - val_loss: 0.2954 - val_accuracy: 0.9067\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.5029 - accuracy: 0.9073 - val_loss: 0.3322 - val_accuracy: 0.8800\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5377 - accuracy: 0.8903 - val_loss: 0.3064 - val_accuracy: 0.8883\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5315 - accuracy: 0.9028 - val_loss: 0.3320 - val_accuracy: 0.9033\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.5393 - accuracy: 0.8884 - val_loss: 0.3377 - val_accuracy: 0.8883\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4889 - accuracy: 0.9133 - val_loss: 0.2283 - val_accuracy: 0.9267\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.4788 - accuracy: 0.9175 - val_loss: 0.3214 - val_accuracy: 0.8717\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5328 - accuracy: 0.8988 - val_loss: 0.2346 - val_accuracy: 0.9300\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.5116 - accuracy: 0.8983 - val_loss: 0.2973 - val_accuracy: 0.8917\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5311 - accuracy: 0.9094 - val_loss: 0.2921 - val_accuracy: 0.9117\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.4673 - accuracy: 0.9075 - val_loss: 0.3129 - val_accuracy: 0.8950\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.5308 - accuracy: 0.8871 - val_loss: 0.2466 - val_accuracy: 0.9233\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5292 - accuracy: 0.9040 - val_loss: 0.2693 - val_accuracy: 0.9100\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2347 - accuracy: 0.5900 - val_loss: 0.5046 - val_accuracy: 0.7667\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.8272 - accuracy: 0.7783 - val_loss: 0.5023 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.7834 - accuracy: 0.7920 - val_loss: 0.5142 - val_accuracy: 0.7467\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.7805 - accuracy: 0.7889 - val_loss: 0.4314 - val_accuracy: 0.8167\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7846 - accuracy: 0.8096 - val_loss: 0.4120 - val_accuracy: 0.8367\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.7687 - accuracy: 0.8225 - val_loss: 0.3702 - val_accuracy: 0.8483\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.7642 - accuracy: 0.8311 - val_loss: 0.4503 - val_accuracy: 0.8217\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6632 - accuracy: 0.8476 - val_loss: 0.3777 - val_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7319 - accuracy: 0.8423 - val_loss: 0.3004 - val_accuracy: 0.8850\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.7068 - accuracy: 0.8582 - val_loss: 0.2902 - val_accuracy: 0.8833\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6788 - accuracy: 0.8670 - val_loss: 0.3311 - val_accuracy: 0.8867\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.7126 - accuracy: 0.8522 - val_loss: 0.2720 - val_accuracy: 0.8917\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.6485 - accuracy: 0.8725 - val_loss: 0.3510 - val_accuracy: 0.8783\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.6260 - accuracy: 0.8681 - val_loss: 0.3256 - val_accuracy: 0.8933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6278 - accuracy: 0.8708 - val_loss: 0.3768 - val_accuracy: 0.8567\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.7733 - accuracy: 0.8437 - val_loss: 0.2882 - val_accuracy: 0.8983\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6290 - accuracy: 0.8817 - val_loss: 0.3170 - val_accuracy: 0.8967\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.5976 - accuracy: 0.8692 - val_loss: 0.3210 - val_accuracy: 0.8833\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5960 - accuracy: 0.8818 - val_loss: 0.2605 - val_accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.6192 - accuracy: 0.8928 - val_loss: 0.4035 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 0.6478 - accuracy: 0.8709 - val_loss: 0.2852 - val_accuracy: 0.9017\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 984us/step - loss: 0.6047 - accuracy: 0.8930 - val_loss: 0.3697 - val_accuracy: 0.8517\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.5443 - accuracy: 0.8916 - val_loss: 0.3536 - val_accuracy: 0.8867\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5759 - accuracy: 0.8956 - val_loss: 0.3581 - val_accuracy: 0.8850\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5928 - accuracy: 0.8867 - val_loss: 0.3281 - val_accuracy: 0.9050\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.6132 - accuracy: 0.8833 - val_loss: 0.2852 - val_accuracy: 0.9067\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.5747 - accuracy: 0.8924 - val_loss: 0.3611 - val_accuracy: 0.8733\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5837 - accuracy: 0.8876 - val_loss: 0.3486 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.5857 - accuracy: 0.8873 - val_loss: 0.3677 - val_accuracy: 0.8717\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5887 - accuracy: 0.8799 - val_loss: 0.2538 - val_accuracy: 0.9283\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5630 - accuracy: 0.8989 - val_loss: 0.3274 - val_accuracy: 0.8867\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5917 - accuracy: 0.8905 - val_loss: 0.3464 - val_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.5706 - accuracy: 0.8856 - val_loss: 0.3097 - val_accuracy: 0.9133\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5873 - accuracy: 0.8860 - val_loss: 0.2980 - val_accuracy: 0.9150\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.6093 - accuracy: 0.8888 - val_loss: 0.3452 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.5946 - accuracy: 0.8859 - val_loss: 0.2371 - val_accuracy: 0.9267\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5308 - accuracy: 0.9055 - val_loss: 0.4064 - val_accuracy: 0.8517\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.5956 - accuracy: 0.8879 - val_loss: 0.3157 - val_accuracy: 0.8850\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.5650 - accuracy: 0.8907 - val_loss: 0.3220 - val_accuracy: 0.8900\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5298 - accuracy: 0.8906 - val_loss: 0.3459 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.5479 - accuracy: 0.8981 - val_loss: 0.2220 - val_accuracy: 0.9233\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.4995 - accuracy: 0.9124 - val_loss: 0.3170 - val_accuracy: 0.9033\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5461 - accuracy: 0.9082 - val_loss: 0.2795 - val_accuracy: 0.9033\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.4454 - accuracy: 0.9149 - val_loss: 0.3622 - val_accuracy: 0.8767\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6349 - accuracy: 0.8811 - val_loss: 0.2136 - val_accuracy: 0.9350\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5228 - accuracy: 0.9083 - val_loss: 0.2613 - val_accuracy: 0.9100\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.5581 - accuracy: 0.8998 - val_loss: 0.2381 - val_accuracy: 0.9317\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.4500 - accuracy: 0.9255 - val_loss: 0.2935 - val_accuracy: 0.8967\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.4751 - accuracy: 0.9193 - val_loss: 0.2986 - val_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5168 - accuracy: 0.9021 - val_loss: 0.3089 - val_accuracy: 0.8883\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.8886 - val_loss: 0.2636 - val_accuracy: 0.9050\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5231 - accuracy: 0.9093 - val_loss: 0.2525 - val_accuracy: 0.9217\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.5731 - accuracy: 0.9022 - val_loss: 0.3049 - val_accuracy: 0.8983\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5630 - accuracy: 0.9002 - val_loss: 0.2413 - val_accuracy: 0.9183\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.5529 - accuracy: 0.8982 - val_loss: 0.3226 - val_accuracy: 0.8783\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.4833 - accuracy: 0.9077 - val_loss: 0.3144 - val_accuracy: 0.8983\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.5002 - accuracy: 0.9076 - val_loss: 0.2488 - val_accuracy: 0.9217\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 792us/step - loss: 0.5398 - accuracy: 0.9081 - val_loss: 0.2536 - val_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.4748 - accuracy: 0.9222 - val_loss: 0.2513 - val_accuracy: 0.9217\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.4536 - accuracy: 0.9164 - val_loss: 0.2563 - val_accuracy: 0.9283\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4990 - accuracy: 0.9010 - val_loss: 0.2259 - val_accuracy: 0.9250\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.5344 - accuracy: 0.9056 - val_loss: 0.2775 - val_accuracy: 0.9083\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4925 - accuracy: 0.8985 - val_loss: 0.3267 - val_accuracy: 0.8850\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5038 - accuracy: 0.8942 - val_loss: 0.2932 - val_accuracy: 0.9033\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.4367 - accuracy: 0.9186 - val_loss: 0.2951 - val_accuracy: 0.8933\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2183 - accuracy: 0.6050 - val_loss: 0.5705 - val_accuracy: 0.7017\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.9359 - accuracy: 0.7211 - val_loss: 0.5028 - val_accuracy: 0.7783\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 766us/step - loss: 0.8340 - accuracy: 0.7897 - val_loss: 0.3932 - val_accuracy: 0.8367\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.8029 - accuracy: 0.8220 - val_loss: 0.4107 - val_accuracy: 0.8367\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.8047 - accuracy: 0.8083 - val_loss: 0.3850 - val_accuracy: 0.8283\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.7504 - accuracy: 0.8222 - val_loss: 0.3670 - val_accuracy: 0.8550\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.7415 - accuracy: 0.8296 - val_loss: 0.3608 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.7608 - accuracy: 0.8293 - val_loss: 0.3066 - val_accuracy: 0.8850\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.7817 - accuracy: 0.8273 - val_loss: 0.3602 - val_accuracy: 0.8567\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.7322 - accuracy: 0.8500 - val_loss: 0.3673 - val_accuracy: 0.8683\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.7106 - accuracy: 0.8496 - val_loss: 0.4029 - val_accuracy: 0.8683\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6824 - accuracy: 0.8560 - val_loss: 0.3291 - val_accuracy: 0.8950\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.6794 - accuracy: 0.8677 - val_loss: 0.3218 - val_accuracy: 0.8983\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6263 - accuracy: 0.8821 - val_loss: 0.3524 - val_accuracy: 0.8817\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 800us/step - loss: 0.6367 - accuracy: 0.8833 - val_loss: 0.3271 - val_accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5948 - accuracy: 0.8804 - val_loss: 0.3218 - val_accuracy: 0.8983\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.6373 - accuracy: 0.8795 - val_loss: 0.3397 - val_accuracy: 0.8850\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6116 - accuracy: 0.8761 - val_loss: 0.3208 - val_accuracy: 0.8950\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.7329 - accuracy: 0.8480 - val_loss: 0.2722 - val_accuracy: 0.9100\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.7005 - accuracy: 0.8752 - val_loss: 0.3723 - val_accuracy: 0.8917\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.5900 - accuracy: 0.8907 - val_loss: 0.4356 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.6399 - accuracy: 0.8735 - val_loss: 0.3139 - val_accuracy: 0.8833\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.5563 - accuracy: 0.8910 - val_loss: 0.3569 - val_accuracy: 0.8733\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6190 - accuracy: 0.8834 - val_loss: 0.2641 - val_accuracy: 0.9083\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5564 - accuracy: 0.8779 - val_loss: 0.2827 - val_accuracy: 0.9083\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.5576 - accuracy: 0.8913 - val_loss: 0.3647 - val_accuracy: 0.8700\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.5702 - accuracy: 0.8927 - val_loss: 0.2684 - val_accuracy: 0.9133\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5530 - accuracy: 0.9073 - val_loss: 0.3104 - val_accuracy: 0.9067\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.6052 - accuracy: 0.8836 - val_loss: 0.3384 - val_accuracy: 0.8983\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.6156 - accuracy: 0.8793 - val_loss: 0.3090 - val_accuracy: 0.8967\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.5457 - accuracy: 0.8931 - val_loss: 0.2953 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.5914 - accuracy: 0.8817 - val_loss: 0.2904 - val_accuracy: 0.9050\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5410 - accuracy: 0.8910 - val_loss: 0.3055 - val_accuracy: 0.8917\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 770us/step - loss: 0.5469 - accuracy: 0.8843 - val_loss: 0.4384 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.6383 - accuracy: 0.8586 - val_loss: 0.2474 - val_accuracy: 0.9283\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.5470 - accuracy: 0.9044 - val_loss: 0.2840 - val_accuracy: 0.9100\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5518 - accuracy: 0.8866 - val_loss: 0.2990 - val_accuracy: 0.9050\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.5381 - accuracy: 0.9008 - val_loss: 0.2721 - val_accuracy: 0.9150\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5763 - accuracy: 0.8694 - val_loss: 0.3342 - val_accuracy: 0.8867\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.5603 - accuracy: 0.88 - 0s 806us/step - loss: 0.5634 - accuracy: 0.8822 - val_loss: 0.3363 - val_accuracy: 0.8733\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5400 - accuracy: 0.8868 - val_loss: 0.2752 - val_accuracy: 0.9117\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.4966 - accuracy: 0.9057 - val_loss: 0.2697 - val_accuracy: 0.9050\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5229 - accuracy: 0.8954 - val_loss: 0.2831 - val_accuracy: 0.9017\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5235 - accuracy: 0.8879 - val_loss: 0.3694 - val_accuracy: 0.8567\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5640 - accuracy: 0.8886 - val_loss: 0.3411 - val_accuracy: 0.8733\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4574 - accuracy: 0.9049 - val_loss: 0.2626 - val_accuracy: 0.9050\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.4671 - accuracy: 0.9043 - val_loss: 0.2873 - val_accuracy: 0.8917\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.4489 - accuracy: 0.9128 - val_loss: 0.4541 - val_accuracy: 0.8017\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5084 - accuracy: 0.8837 - val_loss: 0.2655 - val_accuracy: 0.8917\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.4410 - accuracy: 0.8976 - val_loss: 0.2844 - val_accuracy: 0.9000\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.5330 - accuracy: 0.8983 - val_loss: 0.3072 - val_accuracy: 0.8867\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.4827 - accuracy: 0.9087 - val_loss: 0.3619 - val_accuracy: 0.8500\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5161 - accuracy: 0.8843 - val_loss: 0.3214 - val_accuracy: 0.8817\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5648 - accuracy: 0.8775 - val_loss: 0.2745 - val_accuracy: 0.8883\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5902 - accuracy: 0.8910 - val_loss: 0.3769 - val_accuracy: 0.8500\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1490 - accuracy: 0.6363 - val_loss: 0.5733 - val_accuracy: 0.7367\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.9334 - accuracy: 0.7348 - val_loss: 0.4281 - val_accuracy: 0.8167\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.8827 - accuracy: 0.7850 - val_loss: 0.4498 - val_accuracy: 0.8100\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.8897 - accuracy: 0.7759 - val_loss: 0.4789 - val_accuracy: 0.7933\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.7723 - accuracy: 0.8163 - val_loss: 0.5139 - val_accuracy: 0.7817\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.7723 - accuracy: 0.8115 - val_loss: 0.3762 - val_accuracy: 0.8533\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.8198 - accuracy: 0.8081 - val_loss: 0.4527 - val_accuracy: 0.8050\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.6855 - accuracy: 0.8521 - val_loss: 0.4028 - val_accuracy: 0.8433\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6956 - accuracy: 0.8472 - val_loss: 0.3280 - val_accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 761us/step - loss: 0.7170 - accuracy: 0.8583 - val_loss: 0.3047 - val_accuracy: 0.8833\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.6773 - accuracy: 0.8559 - val_loss: 0.3420 - val_accuracy: 0.8817\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6770 - accuracy: 0.8599 - val_loss: 0.3436 - val_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.7000 - accuracy: 0.8565 - val_loss: 0.3525 - val_accuracy: 0.8800\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6869 - accuracy: 0.8608 - val_loss: 0.4020 - val_accuracy: 0.8383\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.6555 - accuracy: 0.8674 - val_loss: 0.3098 - val_accuracy: 0.9033\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.6529 - accuracy: 0.8762 - val_loss: 0.4049 - val_accuracy: 0.8433\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6182 - accuracy: 0.8688 - val_loss: 0.3645 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6294 - accuracy: 0.8694 - val_loss: 0.3279 - val_accuracy: 0.8867\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6738 - accuracy: 0.8676 - val_loss: 0.3573 - val_accuracy: 0.8750\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.5851 - accuracy: 0.8922 - val_loss: 0.3183 - val_accuracy: 0.9067\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5945 - accuracy: 0.8924 - val_loss: 0.2814 - val_accuracy: 0.9100\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.6135 - accuracy: 0.8898 - val_loss: 0.3462 - val_accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6221 - accuracy: 0.8785 - val_loss: 0.2821 - val_accuracy: 0.9083\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.6158 - accuracy: 0.8925 - val_loss: 0.3303 - val_accuracy: 0.8867\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.6789 - accuracy: 0.8815 - val_loss: 0.2926 - val_accuracy: 0.9133\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6346 - accuracy: 0.8701 - val_loss: 0.2683 - val_accuracy: 0.9017\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5522 - accuracy: 0.8977 - val_loss: 0.3260 - val_accuracy: 0.8800\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 795us/step - loss: 0.5874 - accuracy: 0.8851 - val_loss: 0.3572 - val_accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.6085 - accuracy: 0.8754 - val_loss: 0.2974 - val_accuracy: 0.9050\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 787us/step - loss: 0.5607 - accuracy: 0.9018 - val_loss: 0.3354 - val_accuracy: 0.8850\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6277 - accuracy: 0.8755 - val_loss: 0.2979 - val_accuracy: 0.8983\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5952 - accuracy: 0.8920 - val_loss: 0.3657 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.6311 - accuracy: 0.8714 - val_loss: 0.3190 - val_accuracy: 0.8967\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.5207 - accuracy: 0.8948 - val_loss: 0.2837 - val_accuracy: 0.8900\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 764us/step - loss: 0.6249 - accuracy: 0.8769 - val_loss: 0.2779 - val_accuracy: 0.9083\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5433 - accuracy: 0.8979 - val_loss: 0.3042 - val_accuracy: 0.8967\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5749 - accuracy: 0.8872 - val_loss: 0.3584 - val_accuracy: 0.8783\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5584 - accuracy: 0.8927 - val_loss: 0.3451 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5572 - accuracy: 0.8963 - val_loss: 0.2831 - val_accuracy: 0.9017\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6070 - accuracy: 0.8850 - val_loss: 0.2702 - val_accuracy: 0.9183\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5353 - accuracy: 0.9007 - val_loss: 0.3401 - val_accuracy: 0.8817\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5788 - accuracy: 0.8917 - val_loss: 0.3520 - val_accuracy: 0.8917\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5364 - accuracy: 0.8965 - val_loss: 0.2995 - val_accuracy: 0.8917\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5459 - accuracy: 0.9050 - val_loss: 0.2891 - val_accuracy: 0.9133\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.9061 - val_loss: 0.3144 - val_accuracy: 0.8950\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.5604 - accuracy: 0.9067 - val_loss: 0.3787 - val_accuracy: 0.8600\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2446 - accuracy: 0.5858 - val_loss: 0.5597 - val_accuracy: 0.7083\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 1.0045 - accuracy: 0.7006 - val_loss: 0.4491 - val_accuracy: 0.8017\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.8630 - accuracy: 0.7930 - val_loss: 0.4290 - val_accuracy: 0.8317\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.7715 - accuracy: 0.8174 - val_loss: 0.5207 - val_accuracy: 0.7483\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.8052 - accuracy: 0.7998 - val_loss: 0.3610 - val_accuracy: 0.8500\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.7987 - accuracy: 0.8089 - val_loss: 0.3388 - val_accuracy: 0.8733\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.7646 - accuracy: 0.8375 - val_loss: 0.4811 - val_accuracy: 0.7700\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7493 - accuracy: 0.8173 - val_loss: 0.3488 - val_accuracy: 0.8467\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.7109 - accuracy: 0.8298 - val_loss: 0.3429 - val_accuracy: 0.8700\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.6543 - accuracy: 0.8489 - val_loss: 0.3755 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.7131 - accuracy: 0.8534 - val_loss: 0.3088 - val_accuracy: 0.8983\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.6849 - accuracy: 0.8508 - val_loss: 0.3585 - val_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7197 - accuracy: 0.8438 - val_loss: 0.4187 - val_accuracy: 0.8400\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.6361 - accuracy: 0.8591 - val_loss: 0.3093 - val_accuracy: 0.8883\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.6864 - accuracy: 0.8573 - val_loss: 0.3092 - val_accuracy: 0.8783\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6656 - accuracy: 0.8579 - val_loss: 0.3053 - val_accuracy: 0.8767\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6332 - accuracy: 0.8722 - val_loss: 0.3341 - val_accuracy: 0.8833\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6856 - accuracy: 0.8648 - val_loss: 0.3108 - val_accuracy: 0.8967\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.6672 - accuracy: 0.8666 - val_loss: 0.3181 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.6512 - accuracy: 0.8663 - val_loss: 0.3241 - val_accuracy: 0.8867\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6173 - accuracy: 0.8827 - val_loss: 0.3261 - val_accuracy: 0.8933\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 993us/step - loss: 0.5742 - accuracy: 0.8891 - val_loss: 0.3437 - val_accuracy: 0.8867\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.8748 - val_loss: 0.2838 - val_accuracy: 0.8950\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.6569 - accuracy: 0.8728 - val_loss: 0.3756 - val_accuracy: 0.8550\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6304 - accuracy: 0.8705 - val_loss: 0.3530 - val_accuracy: 0.8650\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.6205 - accuracy: 0.8784 - val_loss: 0.4366 - val_accuracy: 0.8150\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6728 - accuracy: 0.8532 - val_loss: 0.3085 - val_accuracy: 0.9083\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.5577 - accuracy: 0.9009 - val_loss: 0.2937 - val_accuracy: 0.8950\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5107 - accuracy: 0.8976 - val_loss: 0.3142 - val_accuracy: 0.8933\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.5284 - accuracy: 0.8951 - val_loss: 0.3005 - val_accuracy: 0.8850\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.5581 - accuracy: 0.8883 - val_loss: 0.3432 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.6469 - accuracy: 0.8704 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5756 - accuracy: 0.9031 - val_loss: 0.2819 - val_accuracy: 0.9067\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5470 - accuracy: 0.8998 - val_loss: 0.3955 - val_accuracy: 0.8350\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.5635 - accuracy: 0.8881 - val_loss: 0.2444 - val_accuracy: 0.9217\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5290 - accuracy: 0.8948 - val_loss: 0.2730 - val_accuracy: 0.9200\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.4912 - accuracy: 0.9066 - val_loss: 0.4277 - val_accuracy: 0.8100\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 797us/step - loss: 0.5621 - accuracy: 0.8819 - val_loss: 0.2988 - val_accuracy: 0.8850\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5398 - accuracy: 0.8950 - val_loss: 0.2755 - val_accuracy: 0.9167\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5167 - accuracy: 0.8959 - val_loss: 0.2725 - val_accuracy: 0.9117\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.4698 - accuracy: 0.9081 - val_loss: 0.3163 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5622 - accuracy: 0.8962 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.4852 - accuracy: 0.9206 - val_loss: 0.3229 - val_accuracy: 0.8850\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5062 - accuracy: 0.8929 - val_loss: 0.2269 - val_accuracy: 0.9300\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5621 - accuracy: 0.8969 - val_loss: 0.2814 - val_accuracy: 0.9017\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4550 - accuracy: 0.9146 - val_loss: 0.2526 - val_accuracy: 0.9200\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.5280 - accuracy: 0.8925 - val_loss: 0.2961 - val_accuracy: 0.9183\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5077 - accuracy: 0.9062 - val_loss: 0.2617 - val_accuracy: 0.9183\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.4820 - accuracy: 0.9067 - val_loss: 0.2794 - val_accuracy: 0.9017\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.4674 - accuracy: 0.9133 - val_loss: 0.4161 - val_accuracy: 0.8267\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.4817 - accuracy: 0.8912 - val_loss: 0.2469 - val_accuracy: 0.9200\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.4707 - accuracy: 0.9135 - val_loss: 0.2776 - val_accuracy: 0.9017\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.4751 - accuracy: 0.8958 - val_loss: 0.3266 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.4850 - accuracy: 0.9008 - val_loss: 0.2562 - val_accuracy: 0.9183\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.4441 - accuracy: 0.9045 - val_loss: 0.2433 - val_accuracy: 0.9183\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.4870 - accuracy: 0.9037 - val_loss: 0.3654 - val_accuracy: 0.8717\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.4913 - accuracy: 0.9018 - val_loss: 0.2982 - val_accuracy: 0.8950\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.4467 - accuracy: 0.9127 - val_loss: 0.2827 - val_accuracy: 0.9100\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.9158 - val_loss: 0.3071 - val_accuracy: 0.8850\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.4817 - accuracy: 0.8991 - val_loss: 0.2303 - val_accuracy: 0.9300\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 982us/step - loss: 0.5248 - accuracy: 0.9054 - val_loss: 0.3030 - val_accuracy: 0.9017\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.4437 - accuracy: 0.9160 - val_loss: 0.3429 - val_accuracy: 0.8883\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1981 - accuracy: 0.6264 - val_loss: 0.4151 - val_accuracy: 0.8083\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8697 - accuracy: 0.7688 - val_loss: 0.4292 - val_accuracy: 0.8217\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 767us/step - loss: 0.8578 - accuracy: 0.7755 - val_loss: 0.3927 - val_accuracy: 0.8450\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.7939 - accuracy: 0.8188 - val_loss: 0.3620 - val_accuracy: 0.8633\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.7570 - accuracy: 0.8205 - val_loss: 0.3761 - val_accuracy: 0.8650\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.6732 - accuracy: 0.8441 - val_loss: 0.4713 - val_accuracy: 0.8150\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.7192 - accuracy: 0.8257 - val_loss: 0.3501 - val_accuracy: 0.8783\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7789 - accuracy: 0.8428 - val_loss: 0.3405 - val_accuracy: 0.8617\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.7465 - accuracy: 0.8384 - val_loss: 0.3548 - val_accuracy: 0.8683\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.8670 - val_loss: 0.3426 - val_accuracy: 0.8767\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.6716 - accuracy: 0.8588 - val_loss: 0.2650 - val_accuracy: 0.9083\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.6902 - accuracy: 0.8626 - val_loss: 0.2911 - val_accuracy: 0.8950\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.6362 - accuracy: 0.8722 - val_loss: 0.3031 - val_accuracy: 0.8833\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.7235 - accuracy: 0.8621 - val_loss: 0.3356 - val_accuracy: 0.8917\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.6642 - accuracy: 0.8790 - val_loss: 0.2562 - val_accuracy: 0.9133\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7119 - accuracy: 0.8740 - val_loss: 0.2912 - val_accuracy: 0.8917\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.6210 - accuracy: 0.8731 - val_loss: 0.2707 - val_accuracy: 0.9100\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.6291 - accuracy: 0.8871 - val_loss: 0.3533 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.6218 - accuracy: 0.8791 - val_loss: 0.2908 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.6367 - accuracy: 0.8703 - val_loss: 0.3096 - val_accuracy: 0.9033\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.6363 - accuracy: 0.8719 - val_loss: 0.2435 - val_accuracy: 0.9183\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6065 - accuracy: 0.8895 - val_loss: 0.2784 - val_accuracy: 0.9100\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.5812 - accuracy: 0.8906 - val_loss: 0.2304 - val_accuracy: 0.9117\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5567 - accuracy: 0.8948 - val_loss: 0.2837 - val_accuracy: 0.8983\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6065 - accuracy: 0.8784 - val_loss: 0.2923 - val_accuracy: 0.8967\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.6321 - accuracy: 0.8848 - val_loss: 0.3095 - val_accuracy: 0.8967\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6141 - accuracy: 0.8810 - val_loss: 0.3024 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6332 - accuracy: 0.8770 - val_loss: 0.2095 - val_accuracy: 0.9333\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5609 - accuracy: 0.9090 - val_loss: 0.3103 - val_accuracy: 0.8833\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.6017 - accuracy: 0.8929 - val_loss: 0.4375 - val_accuracy: 0.8300\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.5918 - accuracy: 0.8782 - val_loss: 0.2525 - val_accuracy: 0.9200\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6096 - accuracy: 0.8743 - val_loss: 0.2405 - val_accuracy: 0.9233\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5259 - accuracy: 0.9000 - val_loss: 0.3212 - val_accuracy: 0.8967\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.5058 - accuracy: 0.8990 - val_loss: 0.3059 - val_accuracy: 0.8883\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5572 - accuracy: 0.8897 - val_loss: 0.2544 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 781us/step - loss: 0.4806 - accuracy: 0.9149 - val_loss: 0.3962 - val_accuracy: 0.8350\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.5183 - accuracy: 0.8925 - val_loss: 0.2789 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5815 - accuracy: 0.8886 - val_loss: 0.2066 - val_accuracy: 0.9400\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5345 - accuracy: 0.9067 - val_loss: 0.3226 - val_accuracy: 0.8717\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5412 - accuracy: 0.8977 - val_loss: 0.2557 - val_accuracy: 0.9150\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.5205 - accuracy: 0.8948 - val_loss: 0.2432 - val_accuracy: 0.9200\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.4809 - accuracy: 0.9182 - val_loss: 0.2083 - val_accuracy: 0.9450\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.4996 - accuracy: 0.9203 - val_loss: 0.1789 - val_accuracy: 0.9600\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.4793 - accuracy: 0.9187 - val_loss: 0.2465 - val_accuracy: 0.9150\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.5151 - accuracy: 0.9020 - val_loss: 0.2856 - val_accuracy: 0.8917\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.6131 - accuracy: 0.8782 - val_loss: 0.2266 - val_accuracy: 0.9300\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4740 - accuracy: 0.9117 - val_loss: 0.2720 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4580 - accuracy: 0.9051 - val_loss: 0.2467 - val_accuracy: 0.9200\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5266 - accuracy: 0.9015 - val_loss: 0.2594 - val_accuracy: 0.8917\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.5588 - accuracy: 0.8989 - val_loss: 0.2777 - val_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.9144 - val_loss: 0.2395 - val_accuracy: 0.9300\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 996us/step - loss: 0.5300 - accuracy: 0.9085 - val_loss: 0.2620 - val_accuracy: 0.9117\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.4862 - accuracy: 0.9127 - val_loss: 0.2468 - val_accuracy: 0.9150\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5092 - accuracy: 0.9024 - val_loss: 0.2572 - val_accuracy: 0.9083\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4254 - accuracy: 0.9207 - val_loss: 0.2436 - val_accuracy: 0.9300\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.4347 - accuracy: 0.9147 - val_loss: 0.2319 - val_accuracy: 0.9283\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.3837 - accuracy: 0.9184 - val_loss: 0.3024 - val_accuracy: 0.8883\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.4744 - accuracy: 0.9040 - val_loss: 0.2943 - val_accuracy: 0.8850\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.9049 - val_loss: 0.2032 - val_accuracy: 0.9367\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 966us/step - loss: 0.4284 - accuracy: 0.9250 - val_loss: 0.2908 - val_accuracy: 0.8933\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.9091 - val_loss: 0.2927 - val_accuracy: 0.8983\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.4934 - accuracy: 0.9021 - val_loss: 0.3624 - val_accuracy: 0.8417\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8985 - val_loss: 0.2621 - val_accuracy: 0.9083\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2875 - accuracy: 0.5701 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8781 - accuracy: 0.7614 - val_loss: 0.4934 - val_accuracy: 0.7800\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.7737 - accuracy: 0.8125 - val_loss: 0.4737 - val_accuracy: 0.8033\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.7660 - accuracy: 0.8034 - val_loss: 0.4365 - val_accuracy: 0.8317\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7360 - accuracy: 0.8266 - val_loss: 0.4141 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.7649 - accuracy: 0.8181 - val_loss: 0.3174 - val_accuracy: 0.8700\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.7804 - accuracy: 0.8293 - val_loss: 0.3123 - val_accuracy: 0.8783\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.6677 - accuracy: 0.8542 - val_loss: 0.3698 - val_accuracy: 0.8583\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6912 - accuracy: 0.8404 - val_loss: 0.4003 - val_accuracy: 0.8533\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.8215 - val_loss: 0.3365 - val_accuracy: 0.8633\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7244 - accuracy: 0.8479 - val_loss: 0.3574 - val_accuracy: 0.8617\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.7278 - accuracy: 0.8410 - val_loss: 0.3933 - val_accuracy: 0.8300\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.6929 - accuracy: 0.8595 - val_loss: 0.3859 - val_accuracy: 0.8417\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.8476 - val_loss: 0.3588 - val_accuracy: 0.8633\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6584 - accuracy: 0.8575 - val_loss: 0.3604 - val_accuracy: 0.8650\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.7446 - accuracy: 0.8341 - val_loss: 0.2631 - val_accuracy: 0.9017\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.6679 - accuracy: 0.8726 - val_loss: 0.4495 - val_accuracy: 0.8133\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.6480 - accuracy: 0.8686 - val_loss: 0.3163 - val_accuracy: 0.8883\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.5689 - accuracy: 0.8850 - val_loss: 0.3167 - val_accuracy: 0.8783\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6361 - accuracy: 0.8656 - val_loss: 0.3900 - val_accuracy: 0.8350\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5907 - accuracy: 0.8676 - val_loss: 0.3663 - val_accuracy: 0.8633\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.6570 - accuracy: 0.8678 - val_loss: 0.3660 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.6572 - accuracy: 0.8624 - val_loss: 0.2692 - val_accuracy: 0.9150\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6066 - accuracy: 0.8750 - val_loss: 0.2989 - val_accuracy: 0.9017\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.6155 - accuracy: 0.8869 - val_loss: 0.2977 - val_accuracy: 0.8917\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5561 - accuracy: 0.8885 - val_loss: 0.3116 - val_accuracy: 0.8967\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.8826 - val_loss: 0.4120 - val_accuracy: 0.8383\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6012 - accuracy: 0.8630 - val_loss: 0.3473 - val_accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.5651 - accuracy: 0.8813 - val_loss: 0.3440 - val_accuracy: 0.8700\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.6261 - accuracy: 0.8670 - val_loss: 0.2816 - val_accuracy: 0.9067\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.6084 - accuracy: 0.8811 - val_loss: 0.2381 - val_accuracy: 0.9233\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5912 - accuracy: 0.8936 - val_loss: 0.2852 - val_accuracy: 0.9100\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 779us/step - loss: 0.5734 - accuracy: 0.8929 - val_loss: 0.3934 - val_accuracy: 0.8450\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5691 - accuracy: 0.8883 - val_loss: 0.3235 - val_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 785us/step - loss: 0.6005 - accuracy: 0.8956 - val_loss: 0.3412 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.5175 - accuracy: 0.8845 - val_loss: 0.3319 - val_accuracy: 0.8783\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 771us/step - loss: 0.5554 - accuracy: 0.9017 - val_loss: 0.3548 - val_accuracy: 0.8650\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5949 - accuracy: 0.8711 - val_loss: 0.2671 - val_accuracy: 0.9050\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.5478 - accuracy: 0.8818 - val_loss: 0.3454 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.6230 - accuracy: 0.8768 - val_loss: 0.2341 - val_accuracy: 0.9167\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5589 - accuracy: 0.8990 - val_loss: 0.2517 - val_accuracy: 0.9033\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.5366 - accuracy: 0.8993 - val_loss: 0.2906 - val_accuracy: 0.8967\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.4685 - accuracy: 0.9024 - val_loss: 0.2343 - val_accuracy: 0.9167\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 774us/step - loss: 0.4821 - accuracy: 0.9115 - val_loss: 0.3819 - val_accuracy: 0.8583\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6245 - accuracy: 0.8806 - val_loss: 0.2720 - val_accuracy: 0.9017\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.5291 - accuracy: 0.8884 - val_loss: 0.2711 - val_accuracy: 0.9050\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.4767 - accuracy: 0.9084 - val_loss: 0.2964 - val_accuracy: 0.8850\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 769us/step - loss: 0.5105 - accuracy: 0.8949 - val_loss: 0.2829 - val_accuracy: 0.8817\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.5211 - accuracy: 0.8945 - val_loss: 0.2511 - val_accuracy: 0.9017\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.4537 - accuracy: 0.9079 - val_loss: 0.2432 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.9139 - val_loss: 0.2748 - val_accuracy: 0.9050\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.9116 - val_loss: 0.2806 - val_accuracy: 0.8933\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.9003 - val_loss: 0.2417 - val_accuracy: 0.9217\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.4641 - accuracy: 0.8992 - val_loss: 0.2680 - val_accuracy: 0.9017\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4289 - accuracy: 0.9206 - val_loss: 0.3290 - val_accuracy: 0.8700\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.9119 - val_loss: 0.2824 - val_accuracy: 0.9033\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 969us/step - loss: 0.4524 - accuracy: 0.9137 - val_loss: 0.2816 - val_accuracy: 0.8950\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.4499 - accuracy: 0.9055 - val_loss: 0.2301 - val_accuracy: 0.9050\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.8910 - val_loss: 0.2296 - val_accuracy: 0.9200\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.9112 - val_loss: 0.3014 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.9113 - val_loss: 0.3022 - val_accuracy: 0.8800\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.9103 - val_loss: 0.3493 - val_accuracy: 0.8700\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.4598 - accuracy: 0.9000 - val_loss: 0.2456 - val_accuracy: 0.9017\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.5319 - accuracy: 0.9087 - val_loss: 0.2508 - val_accuracy: 0.9083\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5106 - accuracy: 0.8946 - val_loss: 0.2972 - val_accuracy: 0.8783\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8906 - val_loss: 0.2214 - val_accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.9139 - val_loss: 0.2857 - val_accuracy: 0.8833\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.4928 - accuracy: 0.9053 - val_loss: 0.3410 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.4724 - accuracy: 0.8957 - val_loss: 0.3966 - val_accuracy: 0.8367\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.4506 - accuracy: 0.8988 - val_loss: 0.3308 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4651 - accuracy: 0.9120 - val_loss: 0.3284 - val_accuracy: 0.8783\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5702 - accuracy: 0.8960 - val_loss: 0.2396 - val_accuracy: 0.9083\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.9240 - val_loss: 0.3268 - val_accuracy: 0.8800\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.9139 - val_loss: 0.2300 - val_accuracy: 0.9150\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 975us/step - loss: 0.4013 - accuracy: 0.9233 - val_loss: 0.2617 - val_accuracy: 0.8967\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.4315 - accuracy: 0.9145 - val_loss: 0.3030 - val_accuracy: 0.8783\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.4694 - accuracy: 0.9122 - val_loss: 0.2464 - val_accuracy: 0.9083\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.9255 - val_loss: 0.2552 - val_accuracy: 0.8967\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.3928 - accuracy: 0.9199 - val_loss: 0.5055 - val_accuracy: 0.8033\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 964us/step - loss: 0.4923 - accuracy: 0.8773 - val_loss: 0.3034 - val_accuracy: 0.8733\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.4019 - accuracy: 0.9111 - val_loss: 0.3281 - val_accuracy: 0.8600\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.3952 - accuracy: 0.9190 - val_loss: 0.2320 - val_accuracy: 0.9150\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.3859 - accuracy: 0.9287 - val_loss: 0.3858 - val_accuracy: 0.8500\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.4078 - accuracy: 0.9123 - val_loss: 0.3366 - val_accuracy: 0.8567\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.4117 - accuracy: 0.9147 - val_loss: 0.2809 - val_accuracy: 0.8950\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.9317 - val_loss: 0.3091 - val_accuracy: 0.8733\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2569 - accuracy: 0.6055 - val_loss: 0.4896 - val_accuracy: 0.7750\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.9252 - accuracy: 0.7517 - val_loss: 0.4155 - val_accuracy: 0.8367\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.9019 - accuracy: 0.7628 - val_loss: 0.3972 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.8190 - accuracy: 0.8083 - val_loss: 0.3899 - val_accuracy: 0.8400\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.7379 - accuracy: 0.8365 - val_loss: 0.3459 - val_accuracy: 0.8550\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.7231 - accuracy: 0.8361 - val_loss: 0.4046 - val_accuracy: 0.8467\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7199 - accuracy: 0.8389 - val_loss: 0.3600 - val_accuracy: 0.8683\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.7193 - accuracy: 0.8398 - val_loss: 0.3854 - val_accuracy: 0.8617\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6169 - accuracy: 0.8763 - val_loss: 0.3659 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.8707 - val_loss: 0.2994 - val_accuracy: 0.8900\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 0.6726 - accuracy: 0.8700 - val_loss: 0.3565 - val_accuracy: 0.8783\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.7113 - accuracy: 0.8634 - val_loss: 0.2627 - val_accuracy: 0.9117\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 978us/step - loss: 0.6225 - accuracy: 0.8897 - val_loss: 0.3139 - val_accuracy: 0.8950\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.6584 - accuracy: 0.8707 - val_loss: 0.3680 - val_accuracy: 0.8717\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 802us/step - loss: 0.6554 - accuracy: 0.8735 - val_loss: 0.3364 - val_accuracy: 0.8683\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6246 - accuracy: 0.8696 - val_loss: 0.3090 - val_accuracy: 0.9067\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.6428 - accuracy: 0.8842 - val_loss: 0.3511 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.8722 - val_loss: 0.3095 - val_accuracy: 0.8850\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.7014 - accuracy: 0.8643 - val_loss: 0.2792 - val_accuracy: 0.8983\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.6872 - accuracy: 0.8634 - val_loss: 0.2893 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.6216 - accuracy: 0.8896 - val_loss: 0.3374 - val_accuracy: 0.8900\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.5789 - accuracy: 0.8834 - val_loss: 0.2874 - val_accuracy: 0.8950\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5575 - accuracy: 0.8892 - val_loss: 0.3004 - val_accuracy: 0.8983\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.5370 - accuracy: 0.8935 - val_loss: 0.3518 - val_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.5354 - accuracy: 0.9039 - val_loss: 0.3896 - val_accuracy: 0.8633\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5614 - accuracy: 0.8885 - val_loss: 0.3866 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5352 - accuracy: 0.8966 - val_loss: 0.3475 - val_accuracy: 0.8850\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.5583 - accuracy: 0.8837 - val_loss: 0.2631 - val_accuracy: 0.9200\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5347 - accuracy: 0.9052 - val_loss: 0.3201 - val_accuracy: 0.8950\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4895 - accuracy: 0.9137 - val_loss: 0.2456 - val_accuracy: 0.9117\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 992us/step - loss: 0.5335 - accuracy: 0.9107 - val_loss: 0.2838 - val_accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.5172 - accuracy: 0.9044 - val_loss: 0.2532 - val_accuracy: 0.9250\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.5543 - accuracy: 0.8987 - val_loss: 0.3083 - val_accuracy: 0.8933\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.6310 - accuracy: 0.8896 - val_loss: 0.3350 - val_accuracy: 0.8817\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.4786 - accuracy: 0.9137 - val_loss: 0.3075 - val_accuracy: 0.9083\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.5968 - accuracy: 0.8896 - val_loss: 0.2316 - val_accuracy: 0.9217\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5269 - accuracy: 0.9143 - val_loss: 0.2510 - val_accuracy: 0.9350\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5106 - accuracy: 0.9041 - val_loss: 0.2803 - val_accuracy: 0.9133\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.5427 - accuracy: 0.8939 - val_loss: 0.2525 - val_accuracy: 0.9050\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5595 - accuracy: 0.8926 - val_loss: 0.3382 - val_accuracy: 0.8767\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 982us/step - loss: 0.5169 - accuracy: 0.9086 - val_loss: 0.2549 - val_accuracy: 0.9217\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5373 - accuracy: 0.9088 - val_loss: 0.2646 - val_accuracy: 0.9100\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5268 - accuracy: 0.8987 - val_loss: 0.3500 - val_accuracy: 0.8967\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.5492 - accuracy: 0.8912 - val_loss: 0.2766 - val_accuracy: 0.9200\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 940us/step - loss: 0.5263 - accuracy: 0.9005 - val_loss: 0.3724 - val_accuracy: 0.8567\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.5305 - accuracy: 0.8957 - val_loss: 0.3634 - val_accuracy: 0.8800\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.4994 - accuracy: 0.9079 - val_loss: 0.2831 - val_accuracy: 0.9083\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.9066 - val_loss: 0.2671 - val_accuracy: 0.9250\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.9096 - val_loss: 0.3010 - val_accuracy: 0.8900\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 966us/step - loss: 0.4182 - accuracy: 0.9187 - val_loss: 0.3281 - val_accuracy: 0.8733\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.4582 - accuracy: 0.9175 - val_loss: 0.3306 - val_accuracy: 0.8700\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 981us/step - loss: 0.4465 - accuracy: 0.9126 - val_loss: 0.2622 - val_accuracy: 0.9200\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.5386 - accuracy: 0.9192 - val_loss: 0.2922 - val_accuracy: 0.9233\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.4948 - accuracy: 0.9097 - val_loss: 0.2377 - val_accuracy: 0.9200\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5239 - accuracy: 0.9157 - val_loss: 0.3114 - val_accuracy: 0.8950\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.4787 - accuracy: 0.9192 - val_loss: 0.2778 - val_accuracy: 0.9233\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2332 - accuracy: 0.5804 - val_loss: 0.6229 - val_accuracy: 0.6750\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.8442 - accuracy: 0.7547 - val_loss: 0.5120 - val_accuracy: 0.7750\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8767 - accuracy: 0.7725 - val_loss: 0.5212 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.8008 - accuracy: 0.7904 - val_loss: 0.3988 - val_accuracy: 0.8433\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.8120 - accuracy: 0.8025 - val_loss: 0.3894 - val_accuracy: 0.8450\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.7677 - accuracy: 0.8233 - val_loss: 0.3874 - val_accuracy: 0.8417\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7143 - accuracy: 0.8341 - val_loss: 0.3429 - val_accuracy: 0.8733\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6651 - accuracy: 0.8527 - val_loss: 0.4198 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7167 - accuracy: 0.8216 - val_loss: 0.3800 - val_accuracy: 0.8417\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.6728 - accuracy: 0.8517 - val_loss: 0.3281 - val_accuracy: 0.8717\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7042 - accuracy: 0.8407 - val_loss: 0.3562 - val_accuracy: 0.8633\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6820 - accuracy: 0.8631 - val_loss: 0.3047 - val_accuracy: 0.9033\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.7095 - accuracy: 0.8551 - val_loss: 0.3849 - val_accuracy: 0.8533\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7104 - accuracy: 0.8716 - val_loss: 0.3287 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6719 - accuracy: 0.8608 - val_loss: 0.2563 - val_accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.7134 - accuracy: 0.8563 - val_loss: 0.2922 - val_accuracy: 0.8933\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.6195 - accuracy: 0.8730 - val_loss: 0.3357 - val_accuracy: 0.8850\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6195 - accuracy: 0.8686 - val_loss: 0.3135 - val_accuracy: 0.8833\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6225 - accuracy: 0.8793 - val_loss: 0.3137 - val_accuracy: 0.8817\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6401 - accuracy: 0.8742 - val_loss: 0.3960 - val_accuracy: 0.8417\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6668 - accuracy: 0.8719 - val_loss: 0.3582 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6377 - accuracy: 0.8709 - val_loss: 0.4015 - val_accuracy: 0.8417\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6287 - accuracy: 0.8546 - val_loss: 0.3071 - val_accuracy: 0.8950\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5974 - accuracy: 0.8924 - val_loss: 0.3707 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.5766 - accuracy: 0.8919 - val_loss: 0.2744 - val_accuracy: 0.9100\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5562 - accuracy: 0.8891 - val_loss: 0.2559 - val_accuracy: 0.9267\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.6088 - accuracy: 0.8828 - val_loss: 0.2580 - val_accuracy: 0.9100\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5814 - accuracy: 0.8987 - val_loss: 0.4220 - val_accuracy: 0.8350\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.5333 - accuracy: 0.8784 - val_loss: 0.3747 - val_accuracy: 0.8467\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5697 - accuracy: 0.8937 - val_loss: 0.3036 - val_accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5976 - accuracy: 0.8847 - val_loss: 0.2688 - val_accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.5192 - accuracy: 0.8912 - val_loss: 0.3373 - val_accuracy: 0.8883\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5257 - accuracy: 0.8929 - val_loss: 0.2541 - val_accuracy: 0.9317\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5698 - accuracy: 0.8908 - val_loss: 0.3026 - val_accuracy: 0.8917\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.4634 - accuracy: 0.8982 - val_loss: 0.3362 - val_accuracy: 0.8633\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5572 - accuracy: 0.8892 - val_loss: 0.1936 - val_accuracy: 0.9400\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.9048 - val_loss: 0.2897 - val_accuracy: 0.8817\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5577 - accuracy: 0.8929 - val_loss: 0.2194 - val_accuracy: 0.9233\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.5327 - accuracy: 0.8888 - val_loss: 0.3364 - val_accuracy: 0.8783\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.4849 - accuracy: 0.8978 - val_loss: 0.2254 - val_accuracy: 0.9283\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.5020 - accuracy: 0.9089 - val_loss: 0.2916 - val_accuracy: 0.8983\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5294 - accuracy: 0.8979 - val_loss: 0.2764 - val_accuracy: 0.9117\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6142 - accuracy: 0.8903 - val_loss: 0.3235 - val_accuracy: 0.8983\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5170 - accuracy: 0.9020 - val_loss: 0.4471 - val_accuracy: 0.7783\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4789 - accuracy: 0.8964 - val_loss: 0.2810 - val_accuracy: 0.9083\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.4878 - accuracy: 0.9030 - val_loss: 0.2219 - val_accuracy: 0.9317\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5090 - accuracy: 0.8977 - val_loss: 0.3127 - val_accuracy: 0.8933\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5402 - accuracy: 0.8949 - val_loss: 0.2968 - val_accuracy: 0.9017\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.4801 - accuracy: 0.8934 - val_loss: 0.3644 - val_accuracy: 0.8817\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5096 - accuracy: 0.9129 - val_loss: 0.2483 - val_accuracy: 0.9150\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5068 - accuracy: 0.9009 - val_loss: 0.2599 - val_accuracy: 0.9283\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.4974 - accuracy: 0.9002 - val_loss: 0.3876 - val_accuracy: 0.8600\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.4694 - accuracy: 0.9071 - val_loss: 0.3328 - val_accuracy: 0.8700\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8936 - val_loss: 0.2678 - val_accuracy: 0.8883\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.4658 - accuracy: 0.8962 - val_loss: 0.3069 - val_accuracy: 0.8917\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4996 - accuracy: 0.9057 - val_loss: 0.2550 - val_accuracy: 0.9233\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1884 - accuracy: 0.6286 - val_loss: 0.4879 - val_accuracy: 0.7533\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.8519 - accuracy: 0.7679 - val_loss: 0.4421 - val_accuracy: 0.8183\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8593 - accuracy: 0.7850 - val_loss: 0.3797 - val_accuracy: 0.8517\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7409 - accuracy: 0.8335 - val_loss: 0.4322 - val_accuracy: 0.8250\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7567 - accuracy: 0.8242 - val_loss: 0.4498 - val_accuracy: 0.8167\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7499 - accuracy: 0.8200 - val_loss: 0.3473 - val_accuracy: 0.8817\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7209 - accuracy: 0.8447 - val_loss: 0.3780 - val_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.6578 - accuracy: 0.8603 - val_loss: 0.3785 - val_accuracy: 0.8717\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6990 - accuracy: 0.8570 - val_loss: 0.3470 - val_accuracy: 0.8700\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7621 - accuracy: 0.8474 - val_loss: 0.3763 - val_accuracy: 0.8583\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6415 - accuracy: 0.8791 - val_loss: 0.3090 - val_accuracy: 0.8967\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6809 - accuracy: 0.8698 - val_loss: 0.3863 - val_accuracy: 0.8617\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6050 - accuracy: 0.8818 - val_loss: 0.3719 - val_accuracy: 0.8717\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6343 - accuracy: 0.8734 - val_loss: 0.3640 - val_accuracy: 0.8600\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 985us/step - loss: 0.6369 - accuracy: 0.8850 - val_loss: 0.3865 - val_accuracy: 0.8650\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6340 - accuracy: 0.8796 - val_loss: 0.3791 - val_accuracy: 0.8567\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.6804 - accuracy: 0.8688 - val_loss: 0.2921 - val_accuracy: 0.9050\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.8835 - val_loss: 0.3856 - val_accuracy: 0.8783\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.8840 - val_loss: 0.3105 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5802 - accuracy: 0.8956 - val_loss: 0.2943 - val_accuracy: 0.9133\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5593 - accuracy: 0.8989 - val_loss: 0.3054 - val_accuracy: 0.9150\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5922 - accuracy: 0.8903 - val_loss: 0.2890 - val_accuracy: 0.9083\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5635 - accuracy: 0.8997 - val_loss: 0.2561 - val_accuracy: 0.9300\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.9050 - val_loss: 0.3234 - val_accuracy: 0.8917\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5832 - accuracy: 0.8985 - val_loss: 0.2692 - val_accuracy: 0.9233\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6096 - accuracy: 0.8910 - val_loss: 0.2586 - val_accuracy: 0.9200\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5383 - accuracy: 0.9055 - val_loss: 0.3306 - val_accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6232 - accuracy: 0.8868 - val_loss: 0.3124 - val_accuracy: 0.8950\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5465 - accuracy: 0.8941 - val_loss: 0.2315 - val_accuracy: 0.9317\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5469 - accuracy: 0.9104 - val_loss: 0.3241 - val_accuracy: 0.8933\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.5762 - accuracy: 0.8918 - val_loss: 0.2794 - val_accuracy: 0.9133\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.5746 - accuracy: 0.8979 - val_loss: 0.2997 - val_accuracy: 0.8983\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.5331 - accuracy: 0.8965 - val_loss: 0.3062 - val_accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.9017 - val_loss: 0.2791 - val_accuracy: 0.9100\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6400 - accuracy: 0.8836 - val_loss: 0.2572 - val_accuracy: 0.9250\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6143 - accuracy: 0.8839 - val_loss: 0.2844 - val_accuracy: 0.9117\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.5427 - accuracy: 0.9056 - val_loss: 0.2683 - val_accuracy: 0.9083\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.4922 - accuracy: 0.9121 - val_loss: 0.2673 - val_accuracy: 0.9067\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.9053 - val_loss: 0.2979 - val_accuracy: 0.8983\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.8901 - val_loss: 0.2391 - val_accuracy: 0.9233\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.9143 - val_loss: 0.2552 - val_accuracy: 0.9200\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.4795 - accuracy: 0.9207 - val_loss: 0.2672 - val_accuracy: 0.9200\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.8996 - val_loss: 0.2860 - val_accuracy: 0.9033\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.5966 - accuracy: 0.8907 - val_loss: 0.2661 - val_accuracy: 0.9317\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.5000 - accuracy: 0.8957 - val_loss: 0.3355 - val_accuracy: 0.8850\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5671 - accuracy: 0.9065 - val_loss: 0.2713 - val_accuracy: 0.9217\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.4969 - accuracy: 0.9149 - val_loss: 0.3061 - val_accuracy: 0.8983\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.5714 - accuracy: 0.8914 - val_loss: 0.2401 - val_accuracy: 0.9283\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.4673 - accuracy: 0.9188 - val_loss: 0.2576 - val_accuracy: 0.9183\n",
      "8\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3290 - accuracy: 0.5439 - val_loss: 0.5767 - val_accuracy: 0.7050\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.9616 - accuracy: 0.7404 - val_loss: 0.5114 - val_accuracy: 0.7717\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.8958 - accuracy: 0.7624 - val_loss: 0.4828 - val_accuracy: 0.7800\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.7911 - val_loss: 0.4252 - val_accuracy: 0.8200\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7917 - accuracy: 0.8136 - val_loss: 0.4249 - val_accuracy: 0.8133\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.8108 - accuracy: 0.8157 - val_loss: 0.3794 - val_accuracy: 0.8433\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7896 - accuracy: 0.8077 - val_loss: 0.3725 - val_accuracy: 0.8533\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.7711 - accuracy: 0.8142 - val_loss: 0.4095 - val_accuracy: 0.8450\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7740 - accuracy: 0.8224 - val_loss: 0.3355 - val_accuracy: 0.8783\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7458 - accuracy: 0.8348 - val_loss: 0.3272 - val_accuracy: 0.8817\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.7759 - accuracy: 0.8421 - val_loss: 0.3918 - val_accuracy: 0.8450\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 995us/step - loss: 0.6749 - accuracy: 0.8592 - val_loss: 0.4158 - val_accuracy: 0.8467\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.7494 - accuracy: 0.8359 - val_loss: 0.3218 - val_accuracy: 0.8933\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.6939 - accuracy: 0.8575 - val_loss: 0.3976 - val_accuracy: 0.8517\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7456 - accuracy: 0.8364 - val_loss: 0.4574 - val_accuracy: 0.8233\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.7055 - accuracy: 0.8417 - val_loss: 0.3631 - val_accuracy: 0.8617\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.6816 - accuracy: 0.8639 - val_loss: 0.3926 - val_accuracy: 0.8533\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.7070 - accuracy: 0.8543 - val_loss: 0.4265 - val_accuracy: 0.8350\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.7600 - accuracy: 0.8427 - val_loss: 0.3122 - val_accuracy: 0.8967\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 799us/step - loss: 0.7352 - accuracy: 0.8488 - val_loss: 0.4634 - val_accuracy: 0.8200\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.7170 - accuracy: 0.8533 - val_loss: 0.3982 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6104 - accuracy: 0.8756 - val_loss: 0.3940 - val_accuracy: 0.8583\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.7224 - accuracy: 0.8604 - val_loss: 0.3279 - val_accuracy: 0.8900\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6205 - accuracy: 0.8865 - val_loss: 0.4167 - val_accuracy: 0.8483\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.87 - 0s 844us/step - loss: 0.6247 - accuracy: 0.8754 - val_loss: 0.3274 - val_accuracy: 0.8850\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6119 - accuracy: 0.8783 - val_loss: 0.2988 - val_accuracy: 0.8950\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6623 - accuracy: 0.8718 - val_loss: 0.3180 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5874 - accuracy: 0.8831 - val_loss: 0.2816 - val_accuracy: 0.9050\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.6977 - accuracy: 0.8668 - val_loss: 0.3771 - val_accuracy: 0.8650\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6187 - accuracy: 0.8615 - val_loss: 0.3862 - val_accuracy: 0.8500\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 0.6867 - accuracy: 0.8657 - val_loss: 0.3559 - val_accuracy: 0.8733\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 782us/step - loss: 0.6421 - accuracy: 0.8703 - val_loss: 0.3744 - val_accuracy: 0.8533\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.6128 - accuracy: 0.8704 - val_loss: 0.3569 - val_accuracy: 0.8800\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.5997 - accuracy: 0.8791 - val_loss: 0.3278 - val_accuracy: 0.8700\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7326 - accuracy: 0.8481 - val_loss: 0.3097 - val_accuracy: 0.9017\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.7189 - accuracy: 0.8685 - val_loss: 0.3173 - val_accuracy: 0.8917\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6196 - accuracy: 0.8810 - val_loss: 0.2918 - val_accuracy: 0.9083\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5823 - accuracy: 0.8900 - val_loss: 0.3204 - val_accuracy: 0.9017\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.5593 - accuracy: 0.8894 - val_loss: 0.3131 - val_accuracy: 0.8917\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6276 - accuracy: 0.8908 - val_loss: 0.3161 - val_accuracy: 0.8867\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.6294 - accuracy: 0.8760 - val_loss: 0.4610 - val_accuracy: 0.8050\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.5666 - accuracy: 0.8825 - val_loss: 0.3784 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.5320 - accuracy: 0.8951 - val_loss: 0.3273 - val_accuracy: 0.8850\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.8951 - val_loss: 0.3341 - val_accuracy: 0.8833\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.8914 - val_loss: 0.3056 - val_accuracy: 0.8967\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.5097 - accuracy: 0.9093 - val_loss: 0.3584 - val_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.5380 - accuracy: 0.8928 - val_loss: 0.3567 - val_accuracy: 0.8717\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5363 - accuracy: 0.8964 - val_loss: 0.3596 - val_accuracy: 0.8550\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2632 - accuracy: 0.5489 - val_loss: 0.5764 - val_accuracy: 0.7117\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9760 - accuracy: 0.7354 - val_loss: 0.4855 - val_accuracy: 0.7767\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8220 - accuracy: 0.7829 - val_loss: 0.4830 - val_accuracy: 0.7983\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8396 - accuracy: 0.8012 - val_loss: 0.3663 - val_accuracy: 0.8700\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7883 - accuracy: 0.8119 - val_loss: 0.3593 - val_accuracy: 0.8567\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.8245 - val_loss: 0.4049 - val_accuracy: 0.8283\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.8278 - val_loss: 0.3864 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 996us/step - loss: 0.7735 - accuracy: 0.8350 - val_loss: 0.4314 - val_accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.8443 - val_loss: 0.3579 - val_accuracy: 0.8550\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.8502 - val_loss: 0.3752 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7480 - accuracy: 0.8416 - val_loss: 0.3904 - val_accuracy: 0.8600\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.8622 - val_loss: 0.3932 - val_accuracy: 0.8383\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7798 - accuracy: 0.8445 - val_loss: 0.3113 - val_accuracy: 0.8933\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.8749 - val_loss: 0.2589 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6244 - accuracy: 0.8798 - val_loss: 0.3609 - val_accuracy: 0.8900\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.8695 - val_loss: 0.3869 - val_accuracy: 0.8583\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.8683 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.8726 - val_loss: 0.3450 - val_accuracy: 0.8883\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.7082 - accuracy: 0.8619 - val_loss: 0.3841 - val_accuracy: 0.8633\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6892 - accuracy: 0.8752 - val_loss: 0.3894 - val_accuracy: 0.8567\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6723 - accuracy: 0.8517 - val_loss: 0.2639 - val_accuracy: 0.9167\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6332 - accuracy: 0.8754 - val_loss: 0.3616 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6016 - accuracy: 0.8948 - val_loss: 0.3933 - val_accuracy: 0.8567\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6602 - accuracy: 0.8819 - val_loss: 0.3787 - val_accuracy: 0.8650\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6668 - accuracy: 0.8774 - val_loss: 0.3142 - val_accuracy: 0.8767\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.6753 - accuracy: 0.8818 - val_loss: 0.3851 - val_accuracy: 0.8883\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.6225 - accuracy: 0.8883 - val_loss: 0.3524 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6295 - accuracy: 0.8845 - val_loss: 0.3781 - val_accuracy: 0.8817\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5878 - accuracy: 0.8863 - val_loss: 0.2811 - val_accuracy: 0.8983\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.6558 - accuracy: 0.8717 - val_loss: 0.3717 - val_accuracy: 0.8717\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.6178 - accuracy: 0.8858 - val_loss: 0.2992 - val_accuracy: 0.9150\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.5738 - accuracy: 0.9090 - val_loss: 0.3316 - val_accuracy: 0.8900\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.6560 - accuracy: 0.8845 - val_loss: 0.3071 - val_accuracy: 0.8983\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5795 - accuracy: 0.8974 - val_loss: 0.3693 - val_accuracy: 0.8550\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2465 - accuracy: 0.5992 - val_loss: 0.5692 - val_accuracy: 0.7150\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9890 - accuracy: 0.7091 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9367 - accuracy: 0.7535 - val_loss: 0.4445 - val_accuracy: 0.8100\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8986 - accuracy: 0.7716 - val_loss: 0.4240 - val_accuracy: 0.8017\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.8411 - accuracy: 0.8112 - val_loss: 0.3746 - val_accuracy: 0.8767\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.8061 - accuracy: 0.8053 - val_loss: 0.3454 - val_accuracy: 0.8650\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7463 - accuracy: 0.8434 - val_loss: 0.3678 - val_accuracy: 0.8633\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8027 - accuracy: 0.8248 - val_loss: 0.3170 - val_accuracy: 0.8967\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.7827 - accuracy: 0.8388 - val_loss: 0.3536 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7118 - accuracy: 0.8488 - val_loss: 0.3611 - val_accuracy: 0.8767\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.7352 - accuracy: 0.8481 - val_loss: 0.3710 - val_accuracy: 0.8517\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.7523 - accuracy: 0.8418 - val_loss: 0.3806 - val_accuracy: 0.8600\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.7132 - accuracy: 0.8469 - val_loss: 0.4675 - val_accuracy: 0.8017\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.7193 - accuracy: 0.8416 - val_loss: 0.3324 - val_accuracy: 0.8867\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.6412 - accuracy: 0.8741 - val_loss: 0.4008 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.6870 - accuracy: 0.8582 - val_loss: 0.4319 - val_accuracy: 0.8300\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6555 - accuracy: 0.8517 - val_loss: 0.3754 - val_accuracy: 0.8433\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.7071 - accuracy: 0.8513 - val_loss: 0.3767 - val_accuracy: 0.8583\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.6292 - accuracy: 0.8752 - val_loss: 0.4461 - val_accuracy: 0.8317\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 809us/step - loss: 0.6713 - accuracy: 0.8409 - val_loss: 0.3537 - val_accuracy: 0.8833\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6359 - accuracy: 0.8665 - val_loss: 0.4075 - val_accuracy: 0.8183\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7131 - accuracy: 0.8377 - val_loss: 0.3173 - val_accuracy: 0.8783\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.8567 - val_loss: 0.2829 - val_accuracy: 0.9100\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.8751 - val_loss: 0.3830 - val_accuracy: 0.8550\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.8437 - val_loss: 0.3652 - val_accuracy: 0.8533\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.8918 - val_loss: 0.3453 - val_accuracy: 0.8683\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7128 - accuracy: 0.8463 - val_loss: 0.3548 - val_accuracy: 0.8783\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.8746 - val_loss: 0.3031 - val_accuracy: 0.8867\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.8790 - val_loss: 0.2471 - val_accuracy: 0.9150\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.5875 - accuracy: 0.8923 - val_loss: 0.2930 - val_accuracy: 0.8983\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.6850 - accuracy: 0.8553 - val_loss: 0.3152 - val_accuracy: 0.8833\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6338 - accuracy: 0.8665 - val_loss: 0.3182 - val_accuracy: 0.8800\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6790 - accuracy: 0.8791 - val_loss: 0.3103 - val_accuracy: 0.8867\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.5811 - accuracy: 0.8732 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.5883 - accuracy: 0.8736 - val_loss: 0.2633 - val_accuracy: 0.9017\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.5812 - accuracy: 0.8883 - val_loss: 0.3889 - val_accuracy: 0.8283\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.5011 - accuracy: 0.8941 - val_loss: 0.3721 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5486 - accuracy: 0.8895 - val_loss: 0.2955 - val_accuracy: 0.8967\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.8804 - val_loss: 0.2962 - val_accuracy: 0.8867\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.8684 - val_loss: 0.2553 - val_accuracy: 0.9200\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.8818 - val_loss: 0.3204 - val_accuracy: 0.8633\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.8856 - val_loss: 0.3059 - val_accuracy: 0.8833\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.8831 - val_loss: 0.2210 - val_accuracy: 0.9300\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5125 - accuracy: 0.9024 - val_loss: 0.3535 - val_accuracy: 0.8367\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.8786 - val_loss: 0.3101 - val_accuracy: 0.8967\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5829 - accuracy: 0.8904 - val_loss: 0.3105 - val_accuracy: 0.8900\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5523 - accuracy: 0.8892 - val_loss: 0.2808 - val_accuracy: 0.9017\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8966 - val_loss: 0.3038 - val_accuracy: 0.8833\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.8956 - val_loss: 0.2913 - val_accuracy: 0.8950\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5683 - accuracy: 0.8813 - val_loss: 0.3198 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.9026 - val_loss: 0.2824 - val_accuracy: 0.8900\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.8866 - val_loss: 0.2658 - val_accuracy: 0.9033\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.9139 - val_loss: 0.3268 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.8807 - val_loss: 0.3357 - val_accuracy: 0.8650\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.9196 - val_loss: 0.2565 - val_accuracy: 0.9250\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.8939 - val_loss: 0.2867 - val_accuracy: 0.9217\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.5324 - accuracy: 0.8999 - val_loss: 0.2783 - val_accuracy: 0.9083\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.8918 - val_loss: 0.3334 - val_accuracy: 0.8867\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.9185 - val_loss: 0.3405 - val_accuracy: 0.8583\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.9061 - val_loss: 0.2228 - val_accuracy: 0.9317\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.9047 - val_loss: 0.2889 - val_accuracy: 0.8933\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.5333 - accuracy: 0.8951 - val_loss: 0.2506 - val_accuracy: 0.9100\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5116 - accuracy: 0.9033 - val_loss: 0.2302 - val_accuracy: 0.9333\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3025 - accuracy: 0.5801 - val_loss: 0.5161 - val_accuracy: 0.7733\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.9686 - accuracy: 0.7307 - val_loss: 0.4103 - val_accuracy: 0.8367\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8640 - accuracy: 0.8036 - val_loss: 0.5205 - val_accuracy: 0.7700\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9165 - accuracy: 0.7718 - val_loss: 0.3676 - val_accuracy: 0.8583\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8786 - accuracy: 0.7979 - val_loss: 0.3819 - val_accuracy: 0.8550\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.8168 - accuracy: 0.8068 - val_loss: 0.3810 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7930 - accuracy: 0.8178 - val_loss: 0.3518 - val_accuracy: 0.8700\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7720 - accuracy: 0.8243 - val_loss: 0.3723 - val_accuracy: 0.8633\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7947 - accuracy: 0.8255 - val_loss: 0.3081 - val_accuracy: 0.9067\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7600 - accuracy: 0.8325 - val_loss: 0.3455 - val_accuracy: 0.8717\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8264 - accuracy: 0.8313 - val_loss: 0.3532 - val_accuracy: 0.8767\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.7144 - accuracy: 0.8568 - val_loss: 0.3799 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.8588 - val_loss: 0.3664 - val_accuracy: 0.8583\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.8425 - val_loss: 0.3445 - val_accuracy: 0.8783\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.8654 - val_loss: 0.4536 - val_accuracy: 0.8283\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.8355 - val_loss: 0.3777 - val_accuracy: 0.8650\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.8487 - val_loss: 0.2769 - val_accuracy: 0.9200\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.8648 - val_loss: 0.2999 - val_accuracy: 0.8833\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.8474 - val_loss: 0.2310 - val_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7715 - accuracy: 0.8695 - val_loss: 0.2690 - val_accuracy: 0.9200\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.8766 - val_loss: 0.3486 - val_accuracy: 0.8883\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.8700 - val_loss: 0.2990 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.8716 - val_loss: 0.3508 - val_accuracy: 0.8717\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6080 - accuracy: 0.8580 - val_loss: 0.2836 - val_accuracy: 0.8933\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.8804 - val_loss: 0.3961 - val_accuracy: 0.8583\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.8654 - val_loss: 0.3765 - val_accuracy: 0.8417\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.8620 - val_loss: 0.2917 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.8754 - val_loss: 0.3334 - val_accuracy: 0.8833\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.8791 - val_loss: 0.2700 - val_accuracy: 0.9133\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.8706 - val_loss: 0.2636 - val_accuracy: 0.9083\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.8906 - val_loss: 0.3082 - val_accuracy: 0.9017\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.8599 - val_loss: 0.2954 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.8761 - val_loss: 0.2662 - val_accuracy: 0.9017\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.8895 - val_loss: 0.3064 - val_accuracy: 0.8867\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5968 - accuracy: 0.8789 - val_loss: 0.3086 - val_accuracy: 0.8983\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.8802 - val_loss: 0.4140 - val_accuracy: 0.8367\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.6263 - accuracy: 0.8800 - val_loss: 0.3473 - val_accuracy: 0.8733\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.8738 - val_loss: 0.2346 - val_accuracy: 0.9117\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.8688 - val_loss: 0.2415 - val_accuracy: 0.9167\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1308 - accuracy: 0.6698 - val_loss: 0.5009 - val_accuracy: 0.7633\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.9066 - accuracy: 0.7699 - val_loss: 0.5263 - val_accuracy: 0.7650\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9119 - accuracy: 0.7505 - val_loss: 0.3921 - val_accuracy: 0.8450\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7906 - accuracy: 0.8109 - val_loss: 0.4268 - val_accuracy: 0.8367\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.8354 - accuracy: 0.8094 - val_loss: 0.4632 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8031 - accuracy: 0.8159 - val_loss: 0.3668 - val_accuracy: 0.8650\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.8065 - accuracy: 0.8228 - val_loss: 0.3666 - val_accuracy: 0.8617\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.8291 - accuracy: 0.8211 - val_loss: 0.4850 - val_accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.7319 - accuracy: 0.8447 - val_loss: 0.4734 - val_accuracy: 0.7900\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.7450 - accuracy: 0.8290 - val_loss: 0.3603 - val_accuracy: 0.8450\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.6793 - accuracy: 0.8444 - val_loss: 0.3967 - val_accuracy: 0.8483\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8222 - accuracy: 0.8172 - val_loss: 0.4235 - val_accuracy: 0.8483\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.7312 - accuracy: 0.8395 - val_loss: 0.4129 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.8402 - val_loss: 0.4159 - val_accuracy: 0.8367\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6694 - accuracy: 0.8489 - val_loss: 0.3768 - val_accuracy: 0.8483\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.8501 - val_loss: 0.2965 - val_accuracy: 0.8950\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6598 - accuracy: 0.8785 - val_loss: 0.3715 - val_accuracy: 0.8583\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7114 - accuracy: 0.8590 - val_loss: 0.3436 - val_accuracy: 0.8683\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.8595 - val_loss: 0.3396 - val_accuracy: 0.8800\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 805us/step - loss: 0.6688 - accuracy: 0.8715 - val_loss: 0.3083 - val_accuracy: 0.8950\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5906 - accuracy: 0.8755 - val_loss: 0.3050 - val_accuracy: 0.8900\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.6571 - accuracy: 0.8575 - val_loss: 0.3143 - val_accuracy: 0.8867\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.8749 - val_loss: 0.3863 - val_accuracy: 0.8483\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.6457 - accuracy: 0.8494 - val_loss: 0.3240 - val_accuracy: 0.8767\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.8385 - val_loss: 0.3077 - val_accuracy: 0.8950\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6709 - accuracy: 0.8686 - val_loss: 0.2977 - val_accuracy: 0.8950\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.6002 - accuracy: 0.8657 - val_loss: 0.3351 - val_accuracy: 0.8783\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.7091 - accuracy: 0.8545 - val_loss: 0.2939 - val_accuracy: 0.8933\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6670 - accuracy: 0.8573 - val_loss: 0.2878 - val_accuracy: 0.8883\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.6555 - accuracy: 0.8841 - val_loss: 0.2927 - val_accuracy: 0.8983\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5875 - accuracy: 0.8870 - val_loss: 0.2604 - val_accuracy: 0.9100\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.5374 - accuracy: 0.8852 - val_loss: 0.2834 - val_accuracy: 0.8817\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5597 - accuracy: 0.8818 - val_loss: 0.2737 - val_accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.5441 - accuracy: 0.8797 - val_loss: 0.3909 - val_accuracy: 0.8300\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.6910 - accuracy: 0.8614 - val_loss: 0.2697 - val_accuracy: 0.9017\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5469 - accuracy: 0.8911 - val_loss: 0.3664 - val_accuracy: 0.8400\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5016 - accuracy: 0.8931 - val_loss: 0.2980 - val_accuracy: 0.8883\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5589 - accuracy: 0.8909 - val_loss: 0.2604 - val_accuracy: 0.9083\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5185 - accuracy: 0.8919 - val_loss: 0.2649 - val_accuracy: 0.9050\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5734 - accuracy: 0.8985 - val_loss: 0.3021 - val_accuracy: 0.8850\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.8768 - val_loss: 0.2821 - val_accuracy: 0.8967\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6073 - accuracy: 0.8837 - val_loss: 0.2723 - val_accuracy: 0.9017\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.4902 - accuracy: 0.9052 - val_loss: 0.3141 - val_accuracy: 0.8700\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.4618 - accuracy: 0.8962 - val_loss: 0.2513 - val_accuracy: 0.9017\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.9012 - val_loss: 0.3614 - val_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.8723 - val_loss: 0.2251 - val_accuracy: 0.9233\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.4794 - accuracy: 0.9042 - val_loss: 0.3162 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5979 - accuracy: 0.8799 - val_loss: 0.2506 - val_accuracy: 0.9033\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.8914 - val_loss: 0.4036 - val_accuracy: 0.8050\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.5414 - accuracy: 0.8604 - val_loss: 0.2276 - val_accuracy: 0.9133\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.9135 - val_loss: 0.3339 - val_accuracy: 0.8533\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.4499 - accuracy: 0.9090 - val_loss: 0.4052 - val_accuracy: 0.8250\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.5212 - accuracy: 0.8755 - val_loss: 0.2468 - val_accuracy: 0.9083\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.4745 - accuracy: 0.9071 - val_loss: 0.3253 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.8907 - val_loss: 0.2288 - val_accuracy: 0.9117\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.9144 - val_loss: 0.3815 - val_accuracy: 0.8450\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 998us/step - loss: 0.4941 - accuracy: 0.8772 - val_loss: 0.3090 - val_accuracy: 0.8867\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.4679 - accuracy: 0.8961 - val_loss: 0.2477 - val_accuracy: 0.9017\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.5855 - accuracy: 0.8870 - val_loss: 0.2738 - val_accuracy: 0.8950\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.9190 - val_loss: 0.2686 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.5220 - accuracy: 0.8995 - val_loss: 0.2767 - val_accuracy: 0.8950\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.4266 - accuracy: 0.9140 - val_loss: 0.2833 - val_accuracy: 0.8867\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5086 - accuracy: 0.8998 - val_loss: 0.2489 - val_accuracy: 0.9017\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.4909 - accuracy: 0.9125 - val_loss: 0.2913 - val_accuracy: 0.8933\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.9066 - val_loss: 0.3180 - val_accuracy: 0.8783\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.4882 - accuracy: 0.8949 - val_loss: 0.2683 - val_accuracy: 0.9067\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2680 - accuracy: 0.5840 - val_loss: 0.5031 - val_accuracy: 0.7600\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9429 - accuracy: 0.7547 - val_loss: 0.5052 - val_accuracy: 0.7933\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8509 - accuracy: 0.7801 - val_loss: 0.4964 - val_accuracy: 0.7800\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.9025 - accuracy: 0.7783 - val_loss: 0.3915 - val_accuracy: 0.8317\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 982us/step - loss: 0.7765 - accuracy: 0.8056 - val_loss: 0.4101 - val_accuracy: 0.8500\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8365 - accuracy: 0.8161 - val_loss: 0.4069 - val_accuracy: 0.8150\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.8282 - val_loss: 0.3762 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.7079 - accuracy: 0.8342 - val_loss: 0.3561 - val_accuracy: 0.8517\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.7622 - accuracy: 0.8367 - val_loss: 0.3761 - val_accuracy: 0.8550\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.6653 - accuracy: 0.8439 - val_loss: 0.4532 - val_accuracy: 0.8183\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8132 - accuracy: 0.8159 - val_loss: 0.4003 - val_accuracy: 0.8567\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.7406 - accuracy: 0.8449 - val_loss: 0.3645 - val_accuracy: 0.8517\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.7298 - accuracy: 0.8493 - val_loss: 0.3307 - val_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6764 - accuracy: 0.8663 - val_loss: 0.3680 - val_accuracy: 0.8483\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.8494 - val_loss: 0.3377 - val_accuracy: 0.8650\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.7327 - accuracy: 0.8546 - val_loss: 0.3585 - val_accuracy: 0.8533\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 985us/step - loss: 0.8109 - accuracy: 0.8505 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6794 - accuracy: 0.8631 - val_loss: 0.3730 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.8545 - val_loss: 0.3352 - val_accuracy: 0.8867\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 993us/step - loss: 0.6261 - accuracy: 0.8769 - val_loss: 0.3553 - val_accuracy: 0.8717\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.7657 - accuracy: 0.8502 - val_loss: 0.2887 - val_accuracy: 0.9017\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.6791 - accuracy: 0.8664 - val_loss: 0.3217 - val_accuracy: 0.9017\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.7552 - accuracy: 0.8564 - val_loss: 0.2919 - val_accuracy: 0.8867\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.6560 - accuracy: 0.8710 - val_loss: 0.2979 - val_accuracy: 0.9083\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.6712 - accuracy: 0.8794 - val_loss: 0.2591 - val_accuracy: 0.9067\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.8933 - val_loss: 0.2734 - val_accuracy: 0.9083\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.8819 - val_loss: 0.3643 - val_accuracy: 0.8817\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.8768 - val_loss: 0.3065 - val_accuracy: 0.8883\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.8860 - val_loss: 0.3246 - val_accuracy: 0.8833\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.5953 - accuracy: 0.8890 - val_loss: 0.3092 - val_accuracy: 0.8967\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5759 - accuracy: 0.8772 - val_loss: 0.4056 - val_accuracy: 0.8283\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.8641 - val_loss: 0.3379 - val_accuracy: 0.8817\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.5963 - accuracy: 0.8778 - val_loss: 0.3390 - val_accuracy: 0.8817\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5793 - accuracy: 0.8877 - val_loss: 0.3258 - val_accuracy: 0.8933\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.5613 - accuracy: 0.8887 - val_loss: 0.2974 - val_accuracy: 0.8933\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.6416 - accuracy: 0.8735 - val_loss: 0.2659 - val_accuracy: 0.9067\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5460 - accuracy: 0.9061 - val_loss: 0.3440 - val_accuracy: 0.8917\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5701 - accuracy: 0.8785 - val_loss: 0.4243 - val_accuracy: 0.8117\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.8776 - val_loss: 0.2501 - val_accuracy: 0.9300\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.9083 - val_loss: 0.3616 - val_accuracy: 0.8700\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5956 - accuracy: 0.8813 - val_loss: 0.3006 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.8649 - val_loss: 0.3197 - val_accuracy: 0.8900\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.8822 - val_loss: 0.2788 - val_accuracy: 0.9167\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6155 - accuracy: 0.8860 - val_loss: 0.3253 - val_accuracy: 0.8717\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5664 - accuracy: 0.8981 - val_loss: 0.4106 - val_accuracy: 0.8267\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.8803 - val_loss: 0.3396 - val_accuracy: 0.8633\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 794us/step - loss: 0.4889 - accuracy: 0.8855 - val_loss: 0.2410 - val_accuracy: 0.9133\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5758 - accuracy: 0.9003 - val_loss: 0.2889 - val_accuracy: 0.8917\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 789us/step - loss: 0.4812 - accuracy: 0.9032 - val_loss: 0.2692 - val_accuracy: 0.9067\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 791us/step - loss: 0.5316 - accuracy: 0.9002 - val_loss: 0.2965 - val_accuracy: 0.8833\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5665 - accuracy: 0.8987 - val_loss: 0.2587 - val_accuracy: 0.9217\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5320 - accuracy: 0.9002 - val_loss: 0.3625 - val_accuracy: 0.8617\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.5402 - accuracy: 0.8947 - val_loss: 0.3599 - val_accuracy: 0.8467\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.5332 - accuracy: 0.8836 - val_loss: 0.3269 - val_accuracy: 0.8717\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.5016 - accuracy: 0.9089 - val_loss: 0.2927 - val_accuracy: 0.8817\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 775us/step - loss: 0.5026 - accuracy: 0.8886 - val_loss: 0.3221 - val_accuracy: 0.8933\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.5407 - accuracy: 0.8839 - val_loss: 0.3023 - val_accuracy: 0.8833\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.4853 - accuracy: 0.8942 - val_loss: 0.2981 - val_accuracy: 0.8900\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.6447 - accuracy: 0.8607 - val_loss: 0.2512 - val_accuracy: 0.9100\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.5720 - accuracy: 0.9027 - val_loss: 0.3338 - val_accuracy: 0.8633\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.5374 - accuracy: 0.8985 - val_loss: 0.2913 - val_accuracy: 0.8917\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.4912 - accuracy: 0.8951 - val_loss: 0.2438 - val_accuracy: 0.9117\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5131 - accuracy: 0.9072 - val_loss: 0.2536 - val_accuracy: 0.8950\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.4655 - accuracy: 0.9031 - val_loss: 0.3081 - val_accuracy: 0.8767\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.4629 - accuracy: 0.8992 - val_loss: 0.3093 - val_accuracy: 0.8633\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5392 - accuracy: 0.8939 - val_loss: 0.2648 - val_accuracy: 0.8933\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 814us/step - loss: 0.4915 - accuracy: 0.8979 - val_loss: 0.3266 - val_accuracy: 0.8717\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2166 - accuracy: 0.5968 - val_loss: 0.5210 - val_accuracy: 0.7517\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.9276 - accuracy: 0.7413 - val_loss: 0.4548 - val_accuracy: 0.7983\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.8458 - accuracy: 0.7987 - val_loss: 0.5128 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.8417 - accuracy: 0.7896 - val_loss: 0.4330 - val_accuracy: 0.8183\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.8219 - accuracy: 0.8028 - val_loss: 0.4176 - val_accuracy: 0.8367\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.8451 - accuracy: 0.7993 - val_loss: 0.4219 - val_accuracy: 0.8317\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.7043 - accuracy: 0.8340 - val_loss: 0.4746 - val_accuracy: 0.7933\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7795 - accuracy: 0.8141 - val_loss: 0.3324 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.7841 - accuracy: 0.8100 - val_loss: 0.3397 - val_accuracy: 0.8767\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.8251 - accuracy: 0.8203 - val_loss: 0.3949 - val_accuracy: 0.8167\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7922 - accuracy: 0.8295 - val_loss: 0.4663 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.7153 - accuracy: 0.8328 - val_loss: 0.3535 - val_accuracy: 0.8583\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7602 - accuracy: 0.8308 - val_loss: 0.3132 - val_accuracy: 0.8850\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.7170 - accuracy: 0.8480 - val_loss: 0.3278 - val_accuracy: 0.8800\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 808us/step - loss: 0.7103 - accuracy: 0.8605 - val_loss: 0.3089 - val_accuracy: 0.8917\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6943 - accuracy: 0.8631 - val_loss: 0.3373 - val_accuracy: 0.8733\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.7141 - accuracy: 0.8384 - val_loss: 0.4200 - val_accuracy: 0.8417\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.6838 - accuracy: 0.8491 - val_loss: 0.4635 - val_accuracy: 0.7817\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6886 - accuracy: 0.8470 - val_loss: 0.3811 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.7361 - accuracy: 0.8468 - val_loss: 0.4113 - val_accuracy: 0.8350\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6673 - accuracy: 0.8521 - val_loss: 0.3507 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6285 - accuracy: 0.8739 - val_loss: 0.3804 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.7267 - accuracy: 0.8510 - val_loss: 0.3588 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.8675 - val_loss: 0.2787 - val_accuracy: 0.9133\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6862 - accuracy: 0.8688 - val_loss: 0.3409 - val_accuracy: 0.8733\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.8641 - val_loss: 0.3523 - val_accuracy: 0.8700\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 993us/step - loss: 0.6512 - accuracy: 0.8619 - val_loss: 0.3505 - val_accuracy: 0.8683\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.6156 - accuracy: 0.8750 - val_loss: 0.2761 - val_accuracy: 0.9183\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6359 - accuracy: 0.8732 - val_loss: 0.2956 - val_accuracy: 0.8917\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.6107 - accuracy: 0.8809 - val_loss: 0.3210 - val_accuracy: 0.8933\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.6197 - accuracy: 0.8757 - val_loss: 0.3649 - val_accuracy: 0.8683\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6715 - accuracy: 0.8639 - val_loss: 0.4004 - val_accuracy: 0.8283\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.8611 - val_loss: 0.3077 - val_accuracy: 0.8967\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5990 - accuracy: 0.8805 - val_loss: 0.2943 - val_accuracy: 0.8967\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5587 - accuracy: 0.8943 - val_loss: 0.3237 - val_accuracy: 0.8967\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.5333 - accuracy: 0.8842 - val_loss: 0.3285 - val_accuracy: 0.8933\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.6568 - accuracy: 0.8677 - val_loss: 0.2743 - val_accuracy: 0.9017\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5081 - accuracy: 0.8979 - val_loss: 0.3274 - val_accuracy: 0.8883\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.8847 - val_loss: 0.3387 - val_accuracy: 0.8633\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6054 - accuracy: 0.8795 - val_loss: 0.3222 - val_accuracy: 0.8867\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.9018 - val_loss: 0.3829 - val_accuracy: 0.8117\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5430 - accuracy: 0.8848 - val_loss: 0.3972 - val_accuracy: 0.8200\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.8858 - val_loss: 0.3298 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.8927 - val_loss: 0.2999 - val_accuracy: 0.9117\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5843 - accuracy: 0.8734 - val_loss: 0.2515 - val_accuracy: 0.9267\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.9067 - val_loss: 0.2867 - val_accuracy: 0.8967\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.5260 - accuracy: 0.9113 - val_loss: 0.4040 - val_accuracy: 0.8067\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5394 - accuracy: 0.8958 - val_loss: 0.2927 - val_accuracy: 0.8933\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5889 - accuracy: 0.8819 - val_loss: 0.3623 - val_accuracy: 0.8483\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.5545 - accuracy: 0.8866 - val_loss: 0.3095 - val_accuracy: 0.8800\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5727 - accuracy: 0.8716 - val_loss: 0.2496 - val_accuracy: 0.9150\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.5099 - accuracy: 0.9085 - val_loss: 0.3649 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.4969 - accuracy: 0.8829 - val_loss: 0.2693 - val_accuracy: 0.9050\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5088 - accuracy: 0.8942 - val_loss: 0.3411 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.5289 - accuracy: 0.8869 - val_loss: 0.3542 - val_accuracy: 0.8450\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4805 - accuracy: 0.8938 - val_loss: 0.3121 - val_accuracy: 0.8850\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.5681 - accuracy: 0.8830 - val_loss: 0.2385 - val_accuracy: 0.9150\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.5492 - accuracy: 0.9029 - val_loss: 0.2688 - val_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.4245 - accuracy: 0.9093 - val_loss: 0.2439 - val_accuracy: 0.9117\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5276 - accuracy: 0.8850 - val_loss: 0.2985 - val_accuracy: 0.8850\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.5002 - accuracy: 0.8846 - val_loss: 0.3207 - val_accuracy: 0.8617\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.4977 - accuracy: 0.8935 - val_loss: 0.2267 - val_accuracy: 0.9300\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.8958 - val_loss: 0.3020 - val_accuracy: 0.8867\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4755 - accuracy: 0.8993 - val_loss: 0.3174 - val_accuracy: 0.8717\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.3824 - accuracy: 0.9222 - val_loss: 0.4183 - val_accuracy: 0.8150\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.4495 - accuracy: 0.9081 - val_loss: 0.2903 - val_accuracy: 0.8950\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.4520 - accuracy: 0.9008 - val_loss: 0.2505 - val_accuracy: 0.9017\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.4672 - accuracy: 0.9009 - val_loss: 0.3170 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.4394 - accuracy: 0.9090 - val_loss: 0.2755 - val_accuracy: 0.8967\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.4256 - accuracy: 0.9154 - val_loss: 0.3379 - val_accuracy: 0.8767\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.4643 - accuracy: 0.8955 - val_loss: 0.3158 - val_accuracy: 0.8867\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.4545 - accuracy: 0.9100 - val_loss: 0.2690 - val_accuracy: 0.9017\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.4184 - accuracy: 0.9145 - val_loss: 0.3053 - val_accuracy: 0.8950\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.4377 - accuracy: 0.9079 - val_loss: 0.2731 - val_accuracy: 0.8933\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.3842 - accuracy: 0.9295 - val_loss: 0.3640 - val_accuracy: 0.8500\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.4182 - accuracy: 0.9071 - val_loss: 0.2939 - val_accuracy: 0.8967\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.4142 - accuracy: 0.9271 - val_loss: 0.3014 - val_accuracy: 0.8917\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.5463 - accuracy: 0.9006 - val_loss: 0.3596 - val_accuracy: 0.8650\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.3766 - accuracy: 0.9169 - val_loss: 0.3519 - val_accuracy: 0.8700\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.5092 - accuracy: 0.8968 - val_loss: 0.2892 - val_accuracy: 0.8867\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.4043 - accuracy: 0.9170 - val_loss: 0.2442 - val_accuracy: 0.9100\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.3996 - accuracy: 0.9313 - val_loss: 0.2830 - val_accuracy: 0.9050\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2631 - accuracy: 0.5974 - val_loss: 0.5434 - val_accuracy: 0.7217\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.9691 - accuracy: 0.7218 - val_loss: 0.5325 - val_accuracy: 0.7733\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8716 - accuracy: 0.7842 - val_loss: 0.3880 - val_accuracy: 0.8483\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7996 - accuracy: 0.8068 - val_loss: 0.4668 - val_accuracy: 0.8167\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.7490 - accuracy: 0.8235 - val_loss: 0.3637 - val_accuracy: 0.8483\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.7769 - accuracy: 0.8165 - val_loss: 0.5015 - val_accuracy: 0.7867\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7565 - accuracy: 0.8335 - val_loss: 0.3274 - val_accuracy: 0.8717\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7733 - accuracy: 0.8302 - val_loss: 0.3711 - val_accuracy: 0.8633\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.7336 - accuracy: 0.8474 - val_loss: 0.4413 - val_accuracy: 0.8233\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.6844 - accuracy: 0.8467 - val_loss: 0.3097 - val_accuracy: 0.8833\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.7158 - accuracy: 0.8526 - val_loss: 0.3798 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.7000 - accuracy: 0.8522 - val_loss: 0.4277 - val_accuracy: 0.8367\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.7438 - accuracy: 0.8380 - val_loss: 0.3323 - val_accuracy: 0.8683\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.6622 - accuracy: 0.8651 - val_loss: 0.3403 - val_accuracy: 0.8617\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6931 - accuracy: 0.8676 - val_loss: 0.2715 - val_accuracy: 0.9083\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.7823 - accuracy: 0.8640 - val_loss: 0.3563 - val_accuracy: 0.8883\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.6438 - accuracy: 0.8878 - val_loss: 0.3413 - val_accuracy: 0.8633\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6164 - accuracy: 0.8726 - val_loss: 0.3359 - val_accuracy: 0.8800\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 978us/step - loss: 0.6559 - accuracy: 0.8619 - val_loss: 0.3514 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.6627 - accuracy: 0.8782 - val_loss: 0.3672 - val_accuracy: 0.8717\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.7452 - accuracy: 0.8465 - val_loss: 0.2722 - val_accuracy: 0.9050\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6185 - accuracy: 0.8858 - val_loss: 0.2904 - val_accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5870 - accuracy: 0.8779 - val_loss: 0.3692 - val_accuracy: 0.8700\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6723 - accuracy: 0.8705 - val_loss: 0.4006 - val_accuracy: 0.8533\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6091 - accuracy: 0.8755 - val_loss: 0.3426 - val_accuracy: 0.8700\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6164 - accuracy: 0.8763 - val_loss: 0.3613 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6337 - accuracy: 0.8755 - val_loss: 0.4157 - val_accuracy: 0.8467\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.5981 - accuracy: 0.8759 - val_loss: 0.4634 - val_accuracy: 0.7900\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.6514 - accuracy: 0.8684 - val_loss: 0.3083 - val_accuracy: 0.8833\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6864 - accuracy: 0.8691 - val_loss: 0.3233 - val_accuracy: 0.8817\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.6440 - accuracy: 0.8764 - val_loss: 0.3712 - val_accuracy: 0.8617\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.6091 - accuracy: 0.8823 - val_loss: 0.2252 - val_accuracy: 0.9200\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.6671 - accuracy: 0.8814 - val_loss: 0.2777 - val_accuracy: 0.9133\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.6458 - accuracy: 0.8818 - val_loss: 0.3121 - val_accuracy: 0.8967\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.5060 - accuracy: 0.8991 - val_loss: 0.4336 - val_accuracy: 0.8283\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.5999 - accuracy: 0.8615 - val_loss: 0.3426 - val_accuracy: 0.8883\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6270 - accuracy: 0.8820 - val_loss: 0.3126 - val_accuracy: 0.8800\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 987us/step - loss: 0.5664 - accuracy: 0.8706 - val_loss: 0.3766 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.5361 - accuracy: 0.8919 - val_loss: 0.2448 - val_accuracy: 0.9200\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 0.5699 - accuracy: 0.9051 - val_loss: 0.3340 - val_accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.5506 - accuracy: 0.8968 - val_loss: 0.4134 - val_accuracy: 0.8133\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5751 - accuracy: 0.8685 - val_loss: 0.2639 - val_accuracy: 0.9167\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.6073 - accuracy: 0.8805 - val_loss: 0.2945 - val_accuracy: 0.8983\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5350 - accuracy: 0.8921 - val_loss: 0.2858 - val_accuracy: 0.9033\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.5294 - accuracy: 0.8966 - val_loss: 0.2913 - val_accuracy: 0.8900\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.4825 - accuracy: 0.9018 - val_loss: 0.3225 - val_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.5098 - accuracy: 0.8956 - val_loss: 0.3713 - val_accuracy: 0.8450\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.5492 - accuracy: 0.8792 - val_loss: 0.3496 - val_accuracy: 0.8500\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.5079 - accuracy: 0.8920 - val_loss: 0.4146 - val_accuracy: 0.8167\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.8794 - val_loss: 0.3109 - val_accuracy: 0.8867\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6431 - accuracy: 0.8743 - val_loss: 0.2911 - val_accuracy: 0.8833\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.4759 - accuracy: 0.8979 - val_loss: 0.2577 - val_accuracy: 0.9133\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.2691 - accuracy: 0.5962 - val_loss: 0.5485 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.9506 - accuracy: 0.7295 - val_loss: 0.4289 - val_accuracy: 0.8267\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.9194 - accuracy: 0.7893 - val_loss: 0.3340 - val_accuracy: 0.8800\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7967 - accuracy: 0.8220 - val_loss: 0.4965 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 943us/step - loss: 0.7673 - accuracy: 0.8147 - val_loss: 0.3660 - val_accuracy: 0.8533\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.7671 - accuracy: 0.8269 - val_loss: 0.5600 - val_accuracy: 0.7417\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.7771 - accuracy: 0.8166 - val_loss: 0.4415 - val_accuracy: 0.8367\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.8154 - accuracy: 0.7988 - val_loss: 0.3204 - val_accuracy: 0.8850\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.7755 - accuracy: 0.8440 - val_loss: 0.3721 - val_accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.7297 - accuracy: 0.8382 - val_loss: 0.4239 - val_accuracy: 0.8350\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.8061 - accuracy: 0.8245 - val_loss: 0.4158 - val_accuracy: 0.8400\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.7118 - accuracy: 0.8529 - val_loss: 0.4361 - val_accuracy: 0.8367\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6793 - accuracy: 0.8594 - val_loss: 0.4487 - val_accuracy: 0.8317\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6840 - accuracy: 0.8436 - val_loss: 0.3565 - val_accuracy: 0.8883\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6957 - accuracy: 0.8511 - val_loss: 0.3996 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7184 - accuracy: 0.8499 - val_loss: 0.3606 - val_accuracy: 0.8783\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.6669 - accuracy: 0.8603 - val_loss: 0.3153 - val_accuracy: 0.8833\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.7397 - accuracy: 0.8589 - val_loss: 0.3916 - val_accuracy: 0.8600\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.7117 - accuracy: 0.8411 - val_loss: 0.3107 - val_accuracy: 0.8950\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7026 - accuracy: 0.8664 - val_loss: 0.2958 - val_accuracy: 0.9050\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.6650 - accuracy: 0.8825 - val_loss: 0.3736 - val_accuracy: 0.8717\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6689 - accuracy: 0.8783 - val_loss: 0.3778 - val_accuracy: 0.8683\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.6105 - accuracy: 0.8683 - val_loss: 0.2572 - val_accuracy: 0.9133\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 943us/step - loss: 0.6652 - accuracy: 0.8753 - val_loss: 0.3108 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.7066 - accuracy: 0.8698 - val_loss: 0.3517 - val_accuracy: 0.8783\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.6738 - accuracy: 0.8583 - val_loss: 0.3375 - val_accuracy: 0.8900\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.5951 - accuracy: 0.8907 - val_loss: 0.4258 - val_accuracy: 0.8467\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.7385 - accuracy: 0.8403 - val_loss: 0.3167 - val_accuracy: 0.9033\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.6408 - accuracy: 0.8789 - val_loss: 0.3146 - val_accuracy: 0.8917\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5959 - accuracy: 0.8803 - val_loss: 0.3734 - val_accuracy: 0.8717\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.6524 - accuracy: 0.8737 - val_loss: 0.3914 - val_accuracy: 0.8617\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.5721 - accuracy: 0.8863 - val_loss: 0.3966 - val_accuracy: 0.8300\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6508 - accuracy: 0.8597 - val_loss: 0.3154 - val_accuracy: 0.8883\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5992 - accuracy: 0.8882 - val_loss: 0.3408 - val_accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.5883 - accuracy: 0.8909 - val_loss: 0.3414 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5694 - accuracy: 0.8847 - val_loss: 0.3101 - val_accuracy: 0.9067\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5585 - accuracy: 0.8950 - val_loss: 0.3172 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6408 - accuracy: 0.8816 - val_loss: 0.3287 - val_accuracy: 0.8833\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.5705 - accuracy: 0.8820 - val_loss: 0.3434 - val_accuracy: 0.8883\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.5638 - accuracy: 0.8900 - val_loss: 0.3047 - val_accuracy: 0.8867\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5038 - accuracy: 0.9025 - val_loss: 0.3253 - val_accuracy: 0.8850\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.5360 - accuracy: 0.8971 - val_loss: 0.3110 - val_accuracy: 0.8950\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5386 - accuracy: 0.9005 - val_loss: 0.4155 - val_accuracy: 0.8000\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2648 - accuracy: 0.5909 - val_loss: 0.4574 - val_accuracy: 0.8117\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.9704 - accuracy: 0.7485 - val_loss: 0.4711 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8795 - accuracy: 0.7569 - val_loss: 0.4016 - val_accuracy: 0.8317\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.8893 - accuracy: 0.7939 - val_loss: 0.5248 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.8667 - accuracy: 0.7796 - val_loss: 0.3502 - val_accuracy: 0.8650\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.8326 - accuracy: 0.8218 - val_loss: 0.3773 - val_accuracy: 0.8433\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.7655 - accuracy: 0.8215 - val_loss: 0.4184 - val_accuracy: 0.8583\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.7454 - accuracy: 0.8478 - val_loss: 0.3650 - val_accuracy: 0.8650\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.7505 - accuracy: 0.8469 - val_loss: 0.3554 - val_accuracy: 0.8683\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.7520 - accuracy: 0.8365 - val_loss: 0.3099 - val_accuracy: 0.8900\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.7849 - accuracy: 0.8366 - val_loss: 0.3556 - val_accuracy: 0.8633\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7891 - accuracy: 0.8308 - val_loss: 0.3390 - val_accuracy: 0.8717\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6381 - accuracy: 0.8743 - val_loss: 0.3979 - val_accuracy: 0.8400\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7733 - accuracy: 0.8281 - val_loss: 0.3922 - val_accuracy: 0.8367\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.7229 - accuracy: 0.8607 - val_loss: 0.4157 - val_accuracy: 0.8267\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.6678 - accuracy: 0.8621 - val_loss: 0.2857 - val_accuracy: 0.8983\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.6428 - accuracy: 0.8687 - val_loss: 0.4214 - val_accuracy: 0.8317\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.6662 - accuracy: 0.8536 - val_loss: 0.3440 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.7215 - accuracy: 0.8608 - val_loss: 0.3304 - val_accuracy: 0.8817\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.8504 - val_loss: 0.2754 - val_accuracy: 0.9050\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6711 - accuracy: 0.8623 - val_loss: 0.4701 - val_accuracy: 0.8017\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6294 - accuracy: 0.8877 - val_loss: 0.2975 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6477 - accuracy: 0.8807 - val_loss: 0.3384 - val_accuracy: 0.8650\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6598 - accuracy: 0.8637 - val_loss: 0.3054 - val_accuracy: 0.8883\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.8962 - val_loss: 0.4584 - val_accuracy: 0.7867\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 890us/step - loss: 0.6848 - accuracy: 0.8471 - val_loss: 0.3802 - val_accuracy: 0.8517\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.5883 - accuracy: 0.8888 - val_loss: 0.2822 - val_accuracy: 0.9067\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6602 - accuracy: 0.8765 - val_loss: 0.4330 - val_accuracy: 0.8100\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.6275 - accuracy: 0.8665 - val_loss: 0.2718 - val_accuracy: 0.9050\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.5741 - accuracy: 0.9058 - val_loss: 0.3018 - val_accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5930 - accuracy: 0.8878 - val_loss: 0.3508 - val_accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.5653 - accuracy: 0.8877 - val_loss: 0.3246 - val_accuracy: 0.8733\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5344 - accuracy: 0.9014 - val_loss: 0.3326 - val_accuracy: 0.8833\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.4954 - accuracy: 0.9091 - val_loss: 0.3349 - val_accuracy: 0.8733\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5966 - accuracy: 0.8877 - val_loss: 0.4248 - val_accuracy: 0.8167\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6251 - accuracy: 0.8720 - val_loss: 0.2846 - val_accuracy: 0.8950\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6205 - accuracy: 0.8798 - val_loss: 0.2764 - val_accuracy: 0.9050\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.5859 - accuracy: 0.8802 - val_loss: 0.2890 - val_accuracy: 0.9033\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6097 - accuracy: 0.8987 - val_loss: 0.3202 - val_accuracy: 0.8867\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.5942 - accuracy: 0.8904 - val_loss: 0.3237 - val_accuracy: 0.8933\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.5560 - accuracy: 0.8950 - val_loss: 0.2780 - val_accuracy: 0.9017\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.8844 - val_loss: 0.3085 - val_accuracy: 0.8950\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.9006 - val_loss: 0.2696 - val_accuracy: 0.9067\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.5301 - accuracy: 0.8972 - val_loss: 0.3454 - val_accuracy: 0.8583\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.8862 - val_loss: 0.3265 - val_accuracy: 0.8850\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 978us/step - loss: 0.4822 - accuracy: 0.9112 - val_loss: 0.3201 - val_accuracy: 0.8817\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.8925 - val_loss: 0.2635 - val_accuracy: 0.9050\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.8865 - val_loss: 0.3265 - val_accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6140 - accuracy: 0.8788 - val_loss: 0.2319 - val_accuracy: 0.9217\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.9193 - val_loss: 0.2811 - val_accuracy: 0.9017\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5241 - accuracy: 0.8979 - val_loss: 0.3537 - val_accuracy: 0.8783\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5763 - accuracy: 0.8996 - val_loss: 0.3081 - val_accuracy: 0.8917\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.9161 - val_loss: 0.2605 - val_accuracy: 0.9167\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.5475 - accuracy: 0.8901 - val_loss: 0.2488 - val_accuracy: 0.9200\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.4646 - accuracy: 0.9080 - val_loss: 0.3427 - val_accuracy: 0.8700\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5016 - accuracy: 0.8961 - val_loss: 0.4186 - val_accuracy: 0.8167\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.8963 - val_loss: 0.3011 - val_accuracy: 0.8883\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.5033 - accuracy: 0.9036 - val_loss: 0.2472 - val_accuracy: 0.9250\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5086 - accuracy: 0.9170 - val_loss: 0.3091 - val_accuracy: 0.8983\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.4841 - accuracy: 0.9167 - val_loss: 0.2571 - val_accuracy: 0.9183\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5421 - accuracy: 0.8995 - val_loss: 0.2926 - val_accuracy: 0.8917\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.4755 - accuracy: 0.9012 - val_loss: 0.3470 - val_accuracy: 0.8717\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.4356 - accuracy: 0.9098 - val_loss: 0.3264 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.4520 - accuracy: 0.9097 - val_loss: 0.4536 - val_accuracy: 0.7967\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.6148 - accuracy: 0.8684 - val_loss: 0.3354 - val_accuracy: 0.8833\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.4700 - accuracy: 0.9029 - val_loss: 0.2841 - val_accuracy: 0.9017\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.4938 - accuracy: 0.9055 - val_loss: 0.3646 - val_accuracy: 0.8433\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.5706 - accuracy: 0.8882 - val_loss: 0.2863 - val_accuracy: 0.8950\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.5671 - accuracy: 0.8919 - val_loss: 0.2476 - val_accuracy: 0.9183\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1549 - accuracy: 0.6365 - val_loss: 0.4945 - val_accuracy: 0.7783\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.9335 - accuracy: 0.7683 - val_loss: 0.5228 - val_accuracy: 0.7683\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.9374 - accuracy: 0.7559 - val_loss: 0.5113 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.8124 - accuracy: 0.7977 - val_loss: 0.3939 - val_accuracy: 0.8533\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7644 - accuracy: 0.8455 - val_loss: 0.3835 - val_accuracy: 0.8550\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.8397 - val_loss: 0.3696 - val_accuracy: 0.8767\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.8176 - accuracy: 0.8156 - val_loss: 0.3441 - val_accuracy: 0.8700\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7847 - accuracy: 0.8411 - val_loss: 0.4091 - val_accuracy: 0.8517\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 890us/step - loss: 0.7504 - accuracy: 0.8421 - val_loss: 0.3825 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 890us/step - loss: 0.7376 - accuracy: 0.8323 - val_loss: 0.3042 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.7677 - accuracy: 0.8274 - val_loss: 0.3328 - val_accuracy: 0.8733\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 902us/step - loss: 0.6561 - accuracy: 0.8600 - val_loss: 0.3951 - val_accuracy: 0.8583\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 943us/step - loss: 0.6728 - accuracy: 0.8569 - val_loss: 0.4598 - val_accuracy: 0.7983\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7025 - accuracy: 0.8656 - val_loss: 0.3462 - val_accuracy: 0.8733\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7146 - accuracy: 0.8528 - val_loss: 0.3701 - val_accuracy: 0.8733\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.6517 - accuracy: 0.8724 - val_loss: 0.3982 - val_accuracy: 0.8683\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 992us/step - loss: 0.7051 - accuracy: 0.8607 - val_loss: 0.3708 - val_accuracy: 0.8850\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.8673 - val_loss: 0.3076 - val_accuracy: 0.8967\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.8473 - val_loss: 0.2560 - val_accuracy: 0.9050\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6253 - accuracy: 0.8833 - val_loss: 0.4163 - val_accuracy: 0.8533\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.8504 - val_loss: 0.3131 - val_accuracy: 0.8917\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.8665 - val_loss: 0.3580 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.8692 - val_loss: 0.3880 - val_accuracy: 0.8683\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 998us/step - loss: 0.6666 - accuracy: 0.8674 - val_loss: 0.2913 - val_accuracy: 0.8933\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5852 - accuracy: 0.8866 - val_loss: 0.3100 - val_accuracy: 0.8917\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 0.6086 - accuracy: 0.8797 - val_loss: 0.3156 - val_accuracy: 0.8850\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.8821 - val_loss: 0.2810 - val_accuracy: 0.9183\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.8771 - val_loss: 0.3494 - val_accuracy: 0.8733\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.5726 - accuracy: 0.8918 - val_loss: 0.3714 - val_accuracy: 0.8650\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5988 - accuracy: 0.8688 - val_loss: 0.2786 - val_accuracy: 0.9133\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5658 - accuracy: 0.8756 - val_loss: 0.3096 - val_accuracy: 0.8700\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.8927 - val_loss: 0.2966 - val_accuracy: 0.8883\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.5989 - accuracy: 0.8859 - val_loss: 0.3748 - val_accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 976us/step - loss: 0.5614 - accuracy: 0.8704 - val_loss: 0.2419 - val_accuracy: 0.9133\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.5038 - accuracy: 0.8984 - val_loss: 0.3272 - val_accuracy: 0.8917\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6042 - accuracy: 0.8727 - val_loss: 0.2980 - val_accuracy: 0.8983\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5789 - accuracy: 0.8793 - val_loss: 0.4776 - val_accuracy: 0.7750\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5329 - accuracy: 0.8805 - val_loss: 0.2924 - val_accuracy: 0.8933\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5629 - accuracy: 0.8880 - val_loss: 0.2677 - val_accuracy: 0.9100\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5508 - accuracy: 0.8942 - val_loss: 0.3298 - val_accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5542 - accuracy: 0.8937 - val_loss: 0.3067 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.5509 - accuracy: 0.8771 - val_loss: 0.2405 - val_accuracy: 0.9283\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.5016 - accuracy: 0.8974 - val_loss: 0.3671 - val_accuracy: 0.8717\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.4956 - accuracy: 0.9038 - val_loss: 0.2871 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5331 - accuracy: 0.9014 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.5249 - accuracy: 0.8734 - val_loss: 0.3678 - val_accuracy: 0.8533\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5527 - accuracy: 0.8932 - val_loss: 0.2482 - val_accuracy: 0.9200\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.9026 - val_loss: 0.3534 - val_accuracy: 0.8583\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.4625 - accuracy: 0.8949 - val_loss: 0.3465 - val_accuracy: 0.8600\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.5674 - accuracy: 0.8675 - val_loss: 0.2459 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.8929 - val_loss: 0.3025 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.8900 - val_loss: 0.2729 - val_accuracy: 0.8933\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 999us/step - loss: 0.5164 - accuracy: 0.8908 - val_loss: 0.2170 - val_accuracy: 0.9267\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.8954 - val_loss: 0.3310 - val_accuracy: 0.8783\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.4676 - accuracy: 0.8986 - val_loss: 0.3355 - val_accuracy: 0.8733\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8985 - val_loss: 0.2653 - val_accuracy: 0.9083\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5152 - accuracy: 0.9043 - val_loss: 0.3311 - val_accuracy: 0.8600\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.6827 - accuracy: 0.8632 - val_loss: 0.2919 - val_accuracy: 0.8900\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.5546 - accuracy: 0.8875 - val_loss: 0.2961 - val_accuracy: 0.8917\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.4902 - accuracy: 0.9014 - val_loss: 0.3009 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.4768 - accuracy: 0.9030 - val_loss: 0.3349 - val_accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.4920 - accuracy: 0.8979 - val_loss: 0.3077 - val_accuracy: 0.8783\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.4719 - accuracy: 0.8949 - val_loss: 0.2102 - val_accuracy: 0.9217\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4493 - accuracy: 0.9118 - val_loss: 0.2461 - val_accuracy: 0.9033\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.4239 - accuracy: 0.9202 - val_loss: 0.2384 - val_accuracy: 0.9083\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4457 - accuracy: 0.9149 - val_loss: 0.2184 - val_accuracy: 0.9267\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4149 - accuracy: 0.9264 - val_loss: 0.2426 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5848 - accuracy: 0.8989 - val_loss: 0.2005 - val_accuracy: 0.9317\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5592 - accuracy: 0.9054 - val_loss: 0.2018 - val_accuracy: 0.9317\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.4677 - accuracy: 0.9205 - val_loss: 0.2926 - val_accuracy: 0.8917\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.3732 - accuracy: 0.9235 - val_loss: 0.2339 - val_accuracy: 0.9150\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.4904 - accuracy: 0.8979 - val_loss: 0.2699 - val_accuracy: 0.8933\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4087 - accuracy: 0.9163 - val_loss: 0.2741 - val_accuracy: 0.9033\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.8845 - val_loss: 0.2295 - val_accuracy: 0.9217\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.4671 - accuracy: 0.9059 - val_loss: 0.3017 - val_accuracy: 0.8967\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.4789 - accuracy: 0.9061 - val_loss: 0.2638 - val_accuracy: 0.9050\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.3499 - accuracy: 0.9211 - val_loss: 0.2664 - val_accuracy: 0.8967\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.4385 - accuracy: 0.9098 - val_loss: 0.2513 - val_accuracy: 0.9083\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.4626 - accuracy: 0.8913 - val_loss: 0.2064 - val_accuracy: 0.9283\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.4346 - accuracy: 0.9117 - val_loss: 0.3171 - val_accuracy: 0.8867\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.4051 - accuracy: 0.9188 - val_loss: 0.3061 - val_accuracy: 0.8750\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4292 - accuracy: 0.9042 - val_loss: 0.2253 - val_accuracy: 0.9217\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5015 - accuracy: 0.9162 - val_loss: 0.1921 - val_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.3399 - accuracy: 0.9361 - val_loss: 0.2163 - val_accuracy: 0.9233\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.4378 - accuracy: 0.9236 - val_loss: 0.3090 - val_accuracy: 0.8850\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.4595 - accuracy: 0.9028 - val_loss: 0.2393 - val_accuracy: 0.9083\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.4338 - accuracy: 0.9124 - val_loss: 0.3206 - val_accuracy: 0.8750\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.4272 - accuracy: 0.9210 - val_loss: 0.3002 - val_accuracy: 0.8800\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.9175 - val_loss: 0.3105 - val_accuracy: 0.8767\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.4319 - accuracy: 0.9051 - val_loss: 0.2331 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.4549 - accuracy: 0.9149 - val_loss: 0.2662 - val_accuracy: 0.9050\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.4481 - accuracy: 0.9144 - val_loss: 0.3180 - val_accuracy: 0.8733\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.4719 - accuracy: 0.9024 - val_loss: 0.2650 - val_accuracy: 0.8933\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.3315 - accuracy: 0.9299 - val_loss: 0.2647 - val_accuracy: 0.9017\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.4671 - accuracy: 0.9098 - val_loss: 0.2430 - val_accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.4509 - accuracy: 0.9130 - val_loss: 0.3044 - val_accuracy: 0.8867\n",
      "Epoch 97/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.4538 - accuracy: 0.8971 - val_loss: 0.2923 - val_accuracy: 0.8933\n",
      "Epoch 98/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4005 - accuracy: 0.9243 - val_loss: 0.2178 - val_accuracy: 0.9233\n",
      "Epoch 99/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4389 - accuracy: 0.9114 - val_loss: 0.2479 - val_accuracy: 0.9067\n",
      "Epoch 100/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4207 - accuracy: 0.9191 - val_loss: 0.2490 - val_accuracy: 0.9150\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2921 - accuracy: 0.5739 - val_loss: 0.5100 - val_accuracy: 0.7617\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.9455 - accuracy: 0.7351 - val_loss: 0.5276 - val_accuracy: 0.7767\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.9208 - accuracy: 0.7622 - val_loss: 0.4140 - val_accuracy: 0.8300\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.8840 - accuracy: 0.7849 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.8338 - accuracy: 0.7836 - val_loss: 0.4333 - val_accuracy: 0.8233\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.8538 - accuracy: 0.8061 - val_loss: 0.5125 - val_accuracy: 0.7633\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.8537 - accuracy: 0.8025 - val_loss: 0.4910 - val_accuracy: 0.7767\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.7689 - accuracy: 0.8205 - val_loss: 0.4272 - val_accuracy: 0.8483\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.7922 - accuracy: 0.8306 - val_loss: 0.3904 - val_accuracy: 0.8450\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.7521 - accuracy: 0.8246 - val_loss: 0.3767 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7958 - accuracy: 0.8083 - val_loss: 0.4124 - val_accuracy: 0.8350\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7475 - accuracy: 0.8324 - val_loss: 0.3605 - val_accuracy: 0.8683\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.7399 - accuracy: 0.8388 - val_loss: 0.4117 - val_accuracy: 0.8400\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.7922 - accuracy: 0.8287 - val_loss: 0.4382 - val_accuracy: 0.8250\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6692 - accuracy: 0.8486 - val_loss: 0.3735 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.6925 - accuracy: 0.8515 - val_loss: 0.4238 - val_accuracy: 0.8300\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6846 - accuracy: 0.8397 - val_loss: 0.3337 - val_accuracy: 0.8817\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.7028 - accuracy: 0.8596 - val_loss: 0.3161 - val_accuracy: 0.8883\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6632 - accuracy: 0.8735 - val_loss: 0.2817 - val_accuracy: 0.9050\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6892 - accuracy: 0.8671 - val_loss: 0.3679 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.6485 - accuracy: 0.8709 - val_loss: 0.4058 - val_accuracy: 0.8467\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.6126 - accuracy: 0.8725 - val_loss: 0.3481 - val_accuracy: 0.8700\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6236 - accuracy: 0.8730 - val_loss: 0.3184 - val_accuracy: 0.8783\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.5800 - accuracy: 0.8891 - val_loss: 0.3224 - val_accuracy: 0.8867\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 979us/step - loss: 0.6163 - accuracy: 0.8826 - val_loss: 0.3927 - val_accuracy: 0.8383\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.6669 - accuracy: 0.8679 - val_loss: 0.2634 - val_accuracy: 0.8983\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.7757 - accuracy: 0.8679 - val_loss: 0.2519 - val_accuracy: 0.9100\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6108 - accuracy: 0.8935 - val_loss: 0.3352 - val_accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6746 - accuracy: 0.8605 - val_loss: 0.3404 - val_accuracy: 0.8700\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6485 - accuracy: 0.8736 - val_loss: 0.3112 - val_accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.6578 - accuracy: 0.8698 - val_loss: 0.3646 - val_accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.6458 - accuracy: 0.8660 - val_loss: 0.3058 - val_accuracy: 0.9017\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6216 - accuracy: 0.8804 - val_loss: 0.3127 - val_accuracy: 0.8833\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6337 - accuracy: 0.8795 - val_loss: 0.3822 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6312 - accuracy: 0.8774 - val_loss: 0.3222 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.6633 - accuracy: 0.8638 - val_loss: 0.2501 - val_accuracy: 0.9100\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.6475 - accuracy: 0.8769 - val_loss: 0.2816 - val_accuracy: 0.9017\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 780us/step - loss: 0.5299 - accuracy: 0.8947 - val_loss: 0.3498 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5555 - accuracy: 0.8752 - val_loss: 0.2932 - val_accuracy: 0.8817\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5425 - accuracy: 0.8934 - val_loss: 0.3038 - val_accuracy: 0.8917\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.6328 - accuracy: 0.8834 - val_loss: 0.2841 - val_accuracy: 0.9200\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5437 - accuracy: 0.8875 - val_loss: 0.3157 - val_accuracy: 0.8850\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5409 - accuracy: 0.9011 - val_loss: 0.4000 - val_accuracy: 0.8583\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5399 - accuracy: 0.8949 - val_loss: 0.3723 - val_accuracy: 0.8533\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.4940 - accuracy: 0.8941 - val_loss: 0.3758 - val_accuracy: 0.8617\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6570 - accuracy: 0.8749 - val_loss: 0.3122 - val_accuracy: 0.8983\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.5750 - accuracy: 0.8929 - val_loss: 0.2886 - val_accuracy: 0.9017\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5919 - accuracy: 0.8866 - val_loss: 0.2673 - val_accuracy: 0.9033\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5353 - accuracy: 0.8966 - val_loss: 0.2750 - val_accuracy: 0.9117\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.5373 - accuracy: 0.8862 - val_loss: 0.3204 - val_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6113 - accuracy: 0.8690 - val_loss: 0.2805 - val_accuracy: 0.8967\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5774 - accuracy: 0.8926 - val_loss: 0.2650 - val_accuracy: 0.9133\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5207 - accuracy: 0.9013 - val_loss: 0.2264 - val_accuracy: 0.9317\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.5615 - accuracy: 0.8937 - val_loss: 0.2886 - val_accuracy: 0.8933\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.5365 - accuracy: 0.9004 - val_loss: 0.4044 - val_accuracy: 0.8267\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5431 - accuracy: 0.8778 - val_loss: 0.2964 - val_accuracy: 0.9017\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5477 - accuracy: 0.8947 - val_loss: 0.3107 - val_accuracy: 0.8850\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 777us/step - loss: 0.4923 - accuracy: 0.9038 - val_loss: 0.2459 - val_accuracy: 0.9283\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.4954 - accuracy: 0.8958 - val_loss: 0.2381 - val_accuracy: 0.9350\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.4725 - accuracy: 0.9256 - val_loss: 0.3951 - val_accuracy: 0.8517\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.5328 - accuracy: 0.8993 - val_loss: 0.2877 - val_accuracy: 0.9017\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 830us/step - loss: 0.5102 - accuracy: 0.8938 - val_loss: 0.3766 - val_accuracy: 0.8233\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.5711 - accuracy: 0.8884 - val_loss: 0.3010 - val_accuracy: 0.8867\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5050 - accuracy: 0.8998 - val_loss: 0.3415 - val_accuracy: 0.8533\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5089 - accuracy: 0.9038 - val_loss: 0.3386 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.5159 - accuracy: 0.8837 - val_loss: 0.2707 - val_accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5136 - accuracy: 0.8976 - val_loss: 0.2687 - val_accuracy: 0.9083\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6025 - accuracy: 0.8936 - val_loss: 0.2625 - val_accuracy: 0.9117\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.5083 - accuracy: 0.8993 - val_loss: 0.3014 - val_accuracy: 0.8900\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 820us/step - loss: 0.4911 - accuracy: 0.9100 - val_loss: 0.5132 - val_accuracy: 0.8017\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.4684 - accuracy: 0.8960 - val_loss: 0.4352 - val_accuracy: 0.8233\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.6505 - accuracy: 0.8784 - val_loss: 0.3272 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.4679 - accuracy: 0.8998 - val_loss: 0.2530 - val_accuracy: 0.9050\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3020 - accuracy: 0.5599 - val_loss: 0.4763 - val_accuracy: 0.7717\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 811us/step - loss: 1.0148 - accuracy: 0.7438 - val_loss: 0.4415 - val_accuracy: 0.8150\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.8620 - accuracy: 0.7859 - val_loss: 0.5860 - val_accuracy: 0.7067\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.8854 - accuracy: 0.7731 - val_loss: 0.4038 - val_accuracy: 0.8450\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.8119 - accuracy: 0.8157 - val_loss: 0.4509 - val_accuracy: 0.8150\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7570 - accuracy: 0.8358 - val_loss: 0.4124 - val_accuracy: 0.8417\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.7751 - accuracy: 0.8360 - val_loss: 0.4137 - val_accuracy: 0.8350\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.7940 - accuracy: 0.8271 - val_loss: 0.3886 - val_accuracy: 0.8583\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 821us/step - loss: 0.7536 - accuracy: 0.8416 - val_loss: 0.4629 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7211 - accuracy: 0.8441 - val_loss: 0.4242 - val_accuracy: 0.8467\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.8099 - accuracy: 0.8163 - val_loss: 0.4661 - val_accuracy: 0.8017\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 840us/step - loss: 0.7432 - accuracy: 0.8354 - val_loss: 0.3498 - val_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.6704 - accuracy: 0.8715 - val_loss: 0.3967 - val_accuracy: 0.8633\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6782 - accuracy: 0.8705 - val_loss: 0.5376 - val_accuracy: 0.7750\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.7596 - accuracy: 0.8245 - val_loss: 0.3683 - val_accuracy: 0.8517\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 824us/step - loss: 0.6907 - accuracy: 0.8595 - val_loss: 0.4084 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.7246 - accuracy: 0.8387 - val_loss: 0.3587 - val_accuracy: 0.8550\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.7364 - accuracy: 0.8442 - val_loss: 0.3274 - val_accuracy: 0.8817\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.8756 - val_loss: 0.4380 - val_accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 803us/step - loss: 0.6212 - accuracy: 0.8778 - val_loss: 0.4781 - val_accuracy: 0.8017\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 810us/step - loss: 0.6598 - accuracy: 0.8542 - val_loss: 0.3864 - val_accuracy: 0.8533\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.6710 - accuracy: 0.8635 - val_loss: 0.2708 - val_accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6159 - accuracy: 0.8850 - val_loss: 0.3658 - val_accuracy: 0.8517\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5715 - accuracy: 0.8823 - val_loss: 0.4369 - val_accuracy: 0.8133\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.6809 - accuracy: 0.8509 - val_loss: 0.3327 - val_accuracy: 0.8900\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.7030 - accuracy: 0.8545 - val_loss: 0.3024 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6780 - accuracy: 0.8727 - val_loss: 0.3031 - val_accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5950 - accuracy: 0.8911 - val_loss: 0.3575 - val_accuracy: 0.8633\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.8659 - val_loss: 0.4237 - val_accuracy: 0.8167\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.6465 - accuracy: 0.8683 - val_loss: 0.2854 - val_accuracy: 0.9150\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.8841 - val_loss: 0.3106 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.8877 - val_loss: 0.3984 - val_accuracy: 0.8433\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.8495 - val_loss: 0.3841 - val_accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.8725 - val_loss: 0.3453 - val_accuracy: 0.8483\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.5063 - accuracy: 0.8997 - val_loss: 0.3282 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.6741 - accuracy: 0.8507 - val_loss: 0.2645 - val_accuracy: 0.9100\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.5477 - accuracy: 0.8921 - val_loss: 0.3409 - val_accuracy: 0.8633\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6356 - accuracy: 0.8552 - val_loss: 0.2598 - val_accuracy: 0.9083\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6030 - accuracy: 0.9067 - val_loss: 0.2751 - val_accuracy: 0.9117\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.6170 - accuracy: 0.8898 - val_loss: 0.3669 - val_accuracy: 0.8533\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.8821 - val_loss: 0.2214 - val_accuracy: 0.9317\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6051 - accuracy: 0.8892 - val_loss: 0.2902 - val_accuracy: 0.8867\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5546 - accuracy: 0.8862 - val_loss: 0.3710 - val_accuracy: 0.8400\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5586 - accuracy: 0.8846 - val_loss: 0.3615 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.5995 - accuracy: 0.8827 - val_loss: 0.2780 - val_accuracy: 0.9083\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.8959 - val_loss: 0.3156 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8955 - val_loss: 0.2965 - val_accuracy: 0.8867\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.8894 - val_loss: 0.2381 - val_accuracy: 0.9183\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5611 - accuracy: 0.8916 - val_loss: 0.2479 - val_accuracy: 0.9050\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 0.5615 - accuracy: 0.8817 - val_loss: 0.2407 - val_accuracy: 0.9200\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.5308 - accuracy: 0.9035 - val_loss: 0.3260 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5237 - accuracy: 0.8939 - val_loss: 0.3346 - val_accuracy: 0.8833\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.5529 - accuracy: 0.8800 - val_loss: 0.3073 - val_accuracy: 0.8867\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 833us/step - loss: 0.5190 - accuracy: 0.8931 - val_loss: 0.2332 - val_accuracy: 0.9183\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.9029 - val_loss: 0.2546 - val_accuracy: 0.9067\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.9077 - val_loss: 0.2572 - val_accuracy: 0.9067\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6083 - accuracy: 0.8883 - val_loss: 0.2315 - val_accuracy: 0.9217\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.5359 - accuracy: 0.9025 - val_loss: 0.2709 - val_accuracy: 0.9083\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5441 - accuracy: 0.8820 - val_loss: 0.2645 - val_accuracy: 0.9033\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.5745 - accuracy: 0.8865 - val_loss: 0.3009 - val_accuracy: 0.8933\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.4848 - accuracy: 0.8847 - val_loss: 0.3171 - val_accuracy: 0.8767\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3091 - accuracy: 0.5675 - val_loss: 0.6180 - val_accuracy: 0.6783\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9778 - accuracy: 0.7193 - val_loss: 0.6401 - val_accuracy: 0.6550\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.9618 - accuracy: 0.7185 - val_loss: 0.5188 - val_accuracy: 0.7450\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8766 - accuracy: 0.7872 - val_loss: 0.2967 - val_accuracy: 0.8983\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8817 - accuracy: 0.7951 - val_loss: 0.3608 - val_accuracy: 0.8483\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.7436 - accuracy: 0.8259 - val_loss: 0.4015 - val_accuracy: 0.8350\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.7917 - accuracy: 0.8232 - val_loss: 0.3821 - val_accuracy: 0.8617\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7949 - accuracy: 0.8280 - val_loss: 0.4190 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7674 - accuracy: 0.8324 - val_loss: 0.2825 - val_accuracy: 0.9033\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 976us/step - loss: 0.7093 - accuracy: 0.8450 - val_loss: 0.3557 - val_accuracy: 0.8717\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7882 - accuracy: 0.8260 - val_loss: 0.3461 - val_accuracy: 0.8617\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 827us/step - loss: 0.6980 - accuracy: 0.8496 - val_loss: 0.4491 - val_accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7433 - accuracy: 0.8361 - val_loss: 0.4365 - val_accuracy: 0.8167\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.6932 - accuracy: 0.8446 - val_loss: 0.5255 - val_accuracy: 0.7533\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6424 - accuracy: 0.8508 - val_loss: 0.4382 - val_accuracy: 0.8350\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.6235 - accuracy: 0.8694 - val_loss: 0.4242 - val_accuracy: 0.8450\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.6791 - accuracy: 0.8535 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.6559 - accuracy: 0.8542 - val_loss: 0.3908 - val_accuracy: 0.8550\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.8419 - val_loss: 0.3119 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.8870 - val_loss: 0.3725 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.8645 - val_loss: 0.3024 - val_accuracy: 0.8967\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.6612 - accuracy: 0.8758 - val_loss: 0.2995 - val_accuracy: 0.8867\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.8798 - val_loss: 0.3346 - val_accuracy: 0.8833\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6880 - accuracy: 0.8690 - val_loss: 0.3755 - val_accuracy: 0.8650\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.6456 - accuracy: 0.8714 - val_loss: 0.3219 - val_accuracy: 0.8950\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.8671 - val_loss: 0.3319 - val_accuracy: 0.8850\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.8740 - val_loss: 0.2559 - val_accuracy: 0.9150\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.8918 - val_loss: 0.3390 - val_accuracy: 0.8800\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.8769 - val_loss: 0.3063 - val_accuracy: 0.9033\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.8744 - val_loss: 0.3058 - val_accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.8798 - val_loss: 0.3816 - val_accuracy: 0.8600\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.8673 - val_loss: 0.3310 - val_accuracy: 0.8950\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.5732 - accuracy: 0.8853 - val_loss: 0.3625 - val_accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.6173 - accuracy: 0.8760 - val_loss: 0.4064 - val_accuracy: 0.8267\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6322 - accuracy: 0.8726 - val_loss: 0.3013 - val_accuracy: 0.8967\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 958us/step - loss: 0.6500 - accuracy: 0.8884 - val_loss: 0.2998 - val_accuracy: 0.8933\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.8931 - val_loss: 0.3332 - val_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.8674 - val_loss: 0.2969 - val_accuracy: 0.9017\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8999 - val_loss: 0.4557 - val_accuracy: 0.8417\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 982us/step - loss: 0.6043 - accuracy: 0.8862 - val_loss: 0.4406 - val_accuracy: 0.8267\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.8644 - val_loss: 0.3786 - val_accuracy: 0.8350\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 996us/step - loss: 0.6326 - accuracy: 0.8708 - val_loss: 0.3153 - val_accuracy: 0.8917\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.5848 - accuracy: 0.8885 - val_loss: 0.3334 - val_accuracy: 0.8883\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.5925 - accuracy: 0.8776 - val_loss: 0.2855 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6039 - accuracy: 0.8899 - val_loss: 0.3181 - val_accuracy: 0.8817\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.4808 - accuracy: 0.9050 - val_loss: 0.3935 - val_accuracy: 0.8533\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 972us/step - loss: 0.5480 - accuracy: 0.8979 - val_loss: 0.2645 - val_accuracy: 0.9167\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.1975 - accuracy: 0.6197 - val_loss: 0.4925 - val_accuracy: 0.7783\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.9572 - accuracy: 0.7352 - val_loss: 0.5714 - val_accuracy: 0.7117\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 964us/step - loss: 0.8518 - accuracy: 0.7768 - val_loss: 0.4778 - val_accuracy: 0.8083\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7877 - accuracy: 0.7972 - val_loss: 0.4581 - val_accuracy: 0.8183\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8065 - accuracy: 0.8104 - val_loss: 0.4301 - val_accuracy: 0.8433\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8215 - accuracy: 0.8168 - val_loss: 0.3467 - val_accuracy: 0.8800\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.7488 - accuracy: 0.8332 - val_loss: 0.3509 - val_accuracy: 0.8783\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.7772 - accuracy: 0.8399 - val_loss: 0.5427 - val_accuracy: 0.7717\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.7618 - accuracy: 0.8210 - val_loss: 0.3166 - val_accuracy: 0.8917\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7214 - accuracy: 0.8582 - val_loss: 0.4211 - val_accuracy: 0.8483\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7518 - accuracy: 0.8430 - val_loss: 0.4673 - val_accuracy: 0.8117\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.8444 - val_loss: 0.3633 - val_accuracy: 0.8767\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.8482 - val_loss: 0.4275 - val_accuracy: 0.8250\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.8402 - val_loss: 0.3844 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.8495 - val_loss: 0.3040 - val_accuracy: 0.9017\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.8700 - val_loss: 0.3179 - val_accuracy: 0.8950\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7867 - accuracy: 0.8402 - val_loss: 0.2999 - val_accuracy: 0.8783\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.8712 - val_loss: 0.4340 - val_accuracy: 0.8417\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.8534 - val_loss: 0.3801 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.8718 - val_loss: 0.3686 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.8592 - val_loss: 0.3511 - val_accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.8477 - val_loss: 0.2662 - val_accuracy: 0.9100\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.8728 - val_loss: 0.3678 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.8674 - val_loss: 0.3774 - val_accuracy: 0.8500\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.8631 - val_loss: 0.3300 - val_accuracy: 0.8900\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.6994 - accuracy: 0.8523 - val_loss: 0.3730 - val_accuracy: 0.8583\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.6133 - accuracy: 0.8836 - val_loss: 0.3728 - val_accuracy: 0.8683\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.5751 - accuracy: 0.8816 - val_loss: 0.3243 - val_accuracy: 0.8783\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.8647 - val_loss: 0.2707 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.8832 - val_loss: 0.3533 - val_accuracy: 0.8567\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.8619 - val_loss: 0.3374 - val_accuracy: 0.8733\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.8760 - val_loss: 0.2507 - val_accuracy: 0.9033\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.6488 - accuracy: 0.8744 - val_loss: 0.3116 - val_accuracy: 0.8933\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7021 - accuracy: 0.8593 - val_loss: 0.4014 - val_accuracy: 0.8533\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6395 - accuracy: 0.8726 - val_loss: 0.3206 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.8875 - val_loss: 0.3419 - val_accuracy: 0.8850\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.8705 - val_loss: 0.2513 - val_accuracy: 0.9133\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.8880 - val_loss: 0.3426 - val_accuracy: 0.8700\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.8805 - val_loss: 0.2614 - val_accuracy: 0.9083\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.5650 - accuracy: 0.8997 - val_loss: 0.2699 - val_accuracy: 0.9050\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.8939 - val_loss: 0.2767 - val_accuracy: 0.9067\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.88 - 0s 1ms/step - loss: 0.5400 - accuracy: 0.8841 - val_loss: 0.3265 - val_accuracy: 0.8850\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.8628 - val_loss: 0.2855 - val_accuracy: 0.8933\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.5650 - accuracy: 0.8793 - val_loss: 0.2818 - val_accuracy: 0.8967\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.8751 - val_loss: 0.3338 - val_accuracy: 0.8800\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.4810 - accuracy: 0.8948 - val_loss: 0.3275 - val_accuracy: 0.8717\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.5329 - accuracy: 0.8879 - val_loss: 0.2777 - val_accuracy: 0.8933\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.5204 - accuracy: 0.8897 - val_loss: 0.2990 - val_accuracy: 0.8867\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.8978 - val_loss: 0.3746 - val_accuracy: 0.8283\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.5484 - accuracy: 0.8790 - val_loss: 0.3501 - val_accuracy: 0.8567\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4672 - accuracy: 0.8989 - val_loss: 0.3688 - val_accuracy: 0.8517\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5427 - accuracy: 0.8874 - val_loss: 0.4498 - val_accuracy: 0.8067\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.2865 - accuracy: 0.5741 - val_loss: 0.5341 - val_accuracy: 0.7567\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9919 - accuracy: 0.7231 - val_loss: 0.4042 - val_accuracy: 0.8150\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.9923 - accuracy: 0.7631 - val_loss: 0.4368 - val_accuracy: 0.8317\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9014 - accuracy: 0.7928 - val_loss: 0.4409 - val_accuracy: 0.8167\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8091 - accuracy: 0.8086 - val_loss: 0.4460 - val_accuracy: 0.8267\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 987us/step - loss: 0.7342 - accuracy: 0.8229 - val_loss: 0.4921 - val_accuracy: 0.8050\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.7571 - accuracy: 0.8404 - val_loss: 0.3734 - val_accuracy: 0.8533\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.7487 - accuracy: 0.8443 - val_loss: 0.4715 - val_accuracy: 0.8100\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 0.8235 - val_loss: 0.4220 - val_accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.8570 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7673 - accuracy: 0.8203 - val_loss: 0.3277 - val_accuracy: 0.8867\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.7431 - accuracy: 0.8516 - val_loss: 0.3549 - val_accuracy: 0.8850\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.7462 - accuracy: 0.8487 - val_loss: 0.3315 - val_accuracy: 0.8767\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.6796 - accuracy: 0.8575 - val_loss: 0.3787 - val_accuracy: 0.8617\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.8703 - val_loss: 0.3799 - val_accuracy: 0.8617\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 1s 3ms/step - loss: 0.7232 - accuracy: 0.8632 - val_loss: 0.3081 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6393 - accuracy: 0.8794 - val_loss: 0.3377 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.8816 - val_loss: 0.3134 - val_accuracy: 0.8967\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.8824 - val_loss: 0.2846 - val_accuracy: 0.8983\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.6233 - accuracy: 0.8777 - val_loss: 0.3333 - val_accuracy: 0.9017\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 940us/step - loss: 0.6787 - accuracy: 0.8670 - val_loss: 0.3821 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.6248 - accuracy: 0.8728 - val_loss: 0.2759 - val_accuracy: 0.9033\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.8748 - val_loss: 0.3335 - val_accuracy: 0.8950\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.8709 - val_loss: 0.3683 - val_accuracy: 0.8717\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.8584 - val_loss: 0.3632 - val_accuracy: 0.8633\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6217 - accuracy: 0.8656 - val_loss: 0.3632 - val_accuracy: 0.8733\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.8775 - val_loss: 0.3658 - val_accuracy: 0.8700\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.8814 - val_loss: 0.3772 - val_accuracy: 0.8783\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.8723 - val_loss: 0.3189 - val_accuracy: 0.8917\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.5766 - accuracy: 0.8702 - val_loss: 0.3290 - val_accuracy: 0.8833\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.8720 - val_loss: 0.3086 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.8810 - val_loss: 0.2729 - val_accuracy: 0.9067\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6195 - accuracy: 0.8843 - val_loss: 0.3029 - val_accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5614 - accuracy: 0.8869 - val_loss: 0.3247 - val_accuracy: 0.8983\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.5758 - accuracy: 0.8804 - val_loss: 0.2387 - val_accuracy: 0.9283\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.5276 - accuracy: 0.8921 - val_loss: 0.4148 - val_accuracy: 0.8517\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.5544 - accuracy: 0.8854 - val_loss: 0.3496 - val_accuracy: 0.8567\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.5978 - accuracy: 0.8767 - val_loss: 0.3691 - val_accuracy: 0.8567\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.4470 - accuracy: 0.9010 - val_loss: 0.2911 - val_accuracy: 0.8983\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.8899 - val_loss: 0.3887 - val_accuracy: 0.8317\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.8627 - val_loss: 0.2691 - val_accuracy: 0.9150\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.8914 - val_loss: 0.3049 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.8968 - val_loss: 0.2708 - val_accuracy: 0.9067\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.8919 - val_loss: 0.2725 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.8993 - val_loss: 0.2576 - val_accuracy: 0.9133\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 998us/step - loss: 0.4782 - accuracy: 0.9138 - val_loss: 0.2937 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.4655 - accuracy: 0.9034 - val_loss: 0.2928 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 0.4463 - accuracy: 0.9091 - val_loss: 0.3225 - val_accuracy: 0.8883\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.5659 - accuracy: 0.8819 - val_loss: 0.2715 - val_accuracy: 0.9067\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.9115 - val_loss: 0.3462 - val_accuracy: 0.8533\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.9002 - val_loss: 0.2825 - val_accuracy: 0.8967\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.9108 - val_loss: 0.4207 - val_accuracy: 0.8117\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 969us/step - loss: 0.5254 - accuracy: 0.8785 - val_loss: 0.2698 - val_accuracy: 0.8917\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8986 - val_loss: 0.3164 - val_accuracy: 0.8833\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6153 - accuracy: 0.8792 - val_loss: 0.2955 - val_accuracy: 0.8850\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.2903 - accuracy: 0.6046 - val_loss: 0.4938 - val_accuracy: 0.7833\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9691 - accuracy: 0.7331 - val_loss: 0.4273 - val_accuracy: 0.8117\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9290 - accuracy: 0.7746 - val_loss: 0.5131 - val_accuracy: 0.7817\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8052 - accuracy: 0.8043 - val_loss: 0.5068 - val_accuracy: 0.7533\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8620 - accuracy: 0.7889 - val_loss: 0.3693 - val_accuracy: 0.8433\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.8809 - accuracy: 0.8026 - val_loss: 0.3380 - val_accuracy: 0.8783\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.7528 - accuracy: 0.8355 - val_loss: 0.4028 - val_accuracy: 0.8433\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 958us/step - loss: 0.7128 - accuracy: 0.8450 - val_loss: 0.3470 - val_accuracy: 0.8700\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.7845 - accuracy: 0.8255 - val_loss: 0.3774 - val_accuracy: 0.8383\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7920 - accuracy: 0.8246 - val_loss: 0.4355 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7594 - accuracy: 0.8318 - val_loss: 0.4350 - val_accuracy: 0.8233\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.8296 - val_loss: 0.4517 - val_accuracy: 0.8050\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.8373 - val_loss: 0.3053 - val_accuracy: 0.8967\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.8636 - val_loss: 0.4306 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6666 - accuracy: 0.8629 - val_loss: 0.3074 - val_accuracy: 0.8883\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.7026 - accuracy: 0.8665 - val_loss: 0.3786 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6618 - accuracy: 0.8838 - val_loss: 0.2997 - val_accuracy: 0.8933\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6891 - accuracy: 0.8737 - val_loss: 0.3772 - val_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7056 - accuracy: 0.8534 - val_loss: 0.3005 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.6254 - accuracy: 0.8912 - val_loss: 0.2955 - val_accuracy: 0.8950\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7492 - accuracy: 0.8512 - val_loss: 0.3856 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.7385 - accuracy: 0.8549 - val_loss: 0.3210 - val_accuracy: 0.8900\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7137 - accuracy: 0.8532 - val_loss: 0.3015 - val_accuracy: 0.8950\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 902us/step - loss: 0.6935 - accuracy: 0.8706 - val_loss: 0.3234 - val_accuracy: 0.8783\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.6223 - accuracy: 0.8842 - val_loss: 0.3524 - val_accuracy: 0.8817\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 0.6610 - accuracy: 0.8861 - val_loss: 0.3589 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.5780 - accuracy: 0.8976 - val_loss: 0.3936 - val_accuracy: 0.8433\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.6586 - accuracy: 0.8626 - val_loss: 0.3712 - val_accuracy: 0.8833\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5972 - accuracy: 0.8855 - val_loss: 0.2857 - val_accuracy: 0.9033\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5867 - accuracy: 0.8798 - val_loss: 0.2973 - val_accuracy: 0.8917\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.5394 - accuracy: 0.9121 - val_loss: 0.3440 - val_accuracy: 0.8750\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.5992 - accuracy: 0.8724 - val_loss: 0.3893 - val_accuracy: 0.8417\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5310 - accuracy: 0.8879 - val_loss: 0.2835 - val_accuracy: 0.9133\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.6190 - accuracy: 0.8709 - val_loss: 0.2367 - val_accuracy: 0.9250\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.5982 - accuracy: 0.8798 - val_loss: 0.2698 - val_accuracy: 0.9133\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.8999 - val_loss: 0.3510 - val_accuracy: 0.8800\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6144 - accuracy: 0.8723 - val_loss: 0.2400 - val_accuracy: 0.9133\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.5743 - accuracy: 0.8886 - val_loss: 0.2938 - val_accuracy: 0.9017\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.5665 - accuracy: 0.8950 - val_loss: 0.2814 - val_accuracy: 0.9033\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5825 - accuracy: 0.8921 - val_loss: 0.2846 - val_accuracy: 0.8983\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5208 - accuracy: 0.9023 - val_loss: 0.3836 - val_accuracy: 0.8383\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6075 - accuracy: 0.8649 - val_loss: 0.2602 - val_accuracy: 0.9133\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.5211 - accuracy: 0.9004 - val_loss: 0.3141 - val_accuracy: 0.8933\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.8705 - val_loss: 0.2593 - val_accuracy: 0.9200\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.9033 - val_loss: 0.4295 - val_accuracy: 0.8017\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8824 - val_loss: 0.3367 - val_accuracy: 0.8483\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5126 - accuracy: 0.8979 - val_loss: 0.3550 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5248 - accuracy: 0.8831 - val_loss: 0.3239 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.5445 - accuracy: 0.8767 - val_loss: 0.2686 - val_accuracy: 0.9050\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 976us/step - loss: 0.4877 - accuracy: 0.9102 - val_loss: 0.2788 - val_accuracy: 0.8933\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.5536 - accuracy: 0.8858 - val_loss: 0.2843 - val_accuracy: 0.8917\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.5779 - accuracy: 0.8821 - val_loss: 0.3335 - val_accuracy: 0.8833\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.5440 - accuracy: 0.8841 - val_loss: 0.4168 - val_accuracy: 0.8150\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.5733 - accuracy: 0.8732 - val_loss: 0.2962 - val_accuracy: 0.8933\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3131 - accuracy: 0.5618 - val_loss: 0.6240 - val_accuracy: 0.6900\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 902us/step - loss: 1.0103 - accuracy: 0.6867 - val_loss: 0.5766 - val_accuracy: 0.7183\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.9065 - accuracy: 0.7532 - val_loss: 0.5231 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.8397 - accuracy: 0.7829 - val_loss: 0.4543 - val_accuracy: 0.8150\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.8222 - accuracy: 0.8151 - val_loss: 0.4268 - val_accuracy: 0.8133\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8341 - accuracy: 0.7947 - val_loss: 0.4194 - val_accuracy: 0.8183\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8823 - accuracy: 0.8013 - val_loss: 0.4140 - val_accuracy: 0.8567\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8674 - accuracy: 0.8107 - val_loss: 0.4198 - val_accuracy: 0.8183\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.8435 - val_loss: 0.4532 - val_accuracy: 0.8217\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7504 - accuracy: 0.8335 - val_loss: 0.5060 - val_accuracy: 0.8050\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.8450 - val_loss: 0.3668 - val_accuracy: 0.8850\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.8478 - val_loss: 0.4957 - val_accuracy: 0.7783\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7922 - accuracy: 0.8330 - val_loss: 0.4062 - val_accuracy: 0.8583\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.8616 - val_loss: 0.3602 - val_accuracy: 0.8583\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.8553 - val_loss: 0.3859 - val_accuracy: 0.8533\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.6789 - accuracy: 0.8556 - val_loss: 0.5111 - val_accuracy: 0.7600\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.8586 - val_loss: 0.4095 - val_accuracy: 0.8283\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6632 - accuracy: 0.8667 - val_loss: 0.3749 - val_accuracy: 0.8517\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6611 - accuracy: 0.8662 - val_loss: 0.3505 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.6363 - accuracy: 0.8773 - val_loss: 0.2787 - val_accuracy: 0.9083\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.7940 - accuracy: 0.8552 - val_loss: 0.2899 - val_accuracy: 0.9033\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.8857 - val_loss: 0.3742 - val_accuracy: 0.8717\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.8689 - val_loss: 0.3534 - val_accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.8835 - val_loss: 0.3199 - val_accuracy: 0.8850\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.8876 - val_loss: 0.3443 - val_accuracy: 0.8783\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.8814 - val_loss: 0.2669 - val_accuracy: 0.9083\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.6814 - accuracy: 0.8651 - val_loss: 0.3187 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.8957 - val_loss: 0.3152 - val_accuracy: 0.8933\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.7031 - accuracy: 0.8836 - val_loss: 0.3116 - val_accuracy: 0.8917\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6346 - accuracy: 0.8675 - val_loss: 0.4113 - val_accuracy: 0.8417\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.6437 - accuracy: 0.8723 - val_loss: 0.3193 - val_accuracy: 0.8733\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.8773 - val_loss: 0.3935 - val_accuracy: 0.8650\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.8697 - val_loss: 0.3020 - val_accuracy: 0.9017\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.8964 - val_loss: 0.2429 - val_accuracy: 0.9300\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.8920 - val_loss: 0.3391 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.8836 - val_loss: 0.3839 - val_accuracy: 0.8433\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.8892 - val_loss: 0.2680 - val_accuracy: 0.9217\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.9012 - val_loss: 0.3251 - val_accuracy: 0.8733\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.8843 - val_loss: 0.3408 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.8991 - val_loss: 0.3312 - val_accuracy: 0.8733\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.8898 - val_loss: 0.3192 - val_accuracy: 0.8883\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.9003 - val_loss: 0.2704 - val_accuracy: 0.9117\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.8918 - val_loss: 0.2793 - val_accuracy: 0.8967\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.8859 - val_loss: 0.2037 - val_accuracy: 0.9483\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5818 - accuracy: 0.9137 - val_loss: 0.3009 - val_accuracy: 0.8900\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6434 - accuracy: 0.8658 - val_loss: 0.2448 - val_accuracy: 0.9183\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.9030 - val_loss: 0.2504 - val_accuracy: 0.9200\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.9074 - val_loss: 0.2953 - val_accuracy: 0.8933\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.8970 - val_loss: 0.2749 - val_accuracy: 0.8967\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.5677 - accuracy: 0.8925 - val_loss: 0.3467 - val_accuracy: 0.8650\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.6054 - accuracy: 0.8785 - val_loss: 0.2850 - val_accuracy: 0.9050\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5239 - accuracy: 0.9012 - val_loss: 0.2302 - val_accuracy: 0.9350\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.5936 - accuracy: 0.9024 - val_loss: 0.2912 - val_accuracy: 0.9050\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.4530 - accuracy: 0.9030 - val_loss: 0.2399 - val_accuracy: 0.9300\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.8957 - val_loss: 0.2569 - val_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5896 - accuracy: 0.8803 - val_loss: 0.2844 - val_accuracy: 0.8883\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.5426 - accuracy: 0.8926 - val_loss: 0.2469 - val_accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.5801 - accuracy: 0.8954 - val_loss: 0.3184 - val_accuracy: 0.8883\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.4764 - accuracy: 0.9070 - val_loss: 0.2836 - val_accuracy: 0.8983\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.4920 - accuracy: 0.9022 - val_loss: 0.2502 - val_accuracy: 0.9133\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.4999 - accuracy: 0.9003 - val_loss: 0.2692 - val_accuracy: 0.9233\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.4983 - accuracy: 0.9089 - val_loss: 0.2784 - val_accuracy: 0.8883\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.4825 - accuracy: 0.9165 - val_loss: 0.2962 - val_accuracy: 0.8833\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.5217 - accuracy: 0.9036 - val_loss: 0.3411 - val_accuracy: 0.8750\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 1.2715 - accuracy: 0.5756 - val_loss: 0.4947 - val_accuracy: 0.7750\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9427 - accuracy: 0.7237 - val_loss: 0.4867 - val_accuracy: 0.7850\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9482 - accuracy: 0.7419 - val_loss: 0.4308 - val_accuracy: 0.8150\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.8104 - accuracy: 0.7988 - val_loss: 0.4879 - val_accuracy: 0.7850\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.8600 - accuracy: 0.7909 - val_loss: 0.4058 - val_accuracy: 0.8233\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8473 - accuracy: 0.7914 - val_loss: 0.3529 - val_accuracy: 0.8617\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8481 - accuracy: 0.8109 - val_loss: 0.4060 - val_accuracy: 0.8233\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7421 - accuracy: 0.8306 - val_loss: 0.4078 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7473 - accuracy: 0.8222 - val_loss: 0.4130 - val_accuracy: 0.8267\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.7812 - accuracy: 0.8169 - val_loss: 0.3725 - val_accuracy: 0.8733\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 964us/step - loss: 0.7265 - accuracy: 0.8403 - val_loss: 0.3427 - val_accuracy: 0.8650\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.7166 - accuracy: 0.8525 - val_loss: 0.3938 - val_accuracy: 0.8383\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.7547 - accuracy: 0.8269 - val_loss: 0.4221 - val_accuracy: 0.8233\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.7337 - accuracy: 0.8340 - val_loss: 0.4606 - val_accuracy: 0.8017\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6868 - accuracy: 0.8422 - val_loss: 0.3292 - val_accuracy: 0.8633\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.6971 - accuracy: 0.8580 - val_loss: 0.4008 - val_accuracy: 0.8433\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.8667 - val_loss: 0.3435 - val_accuracy: 0.8717\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.6371 - accuracy: 0.8649 - val_loss: 0.4816 - val_accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.7102 - accuracy: 0.8483 - val_loss: 0.2979 - val_accuracy: 0.8933\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.8471 - val_loss: 0.2897 - val_accuracy: 0.9050\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.8708 - val_loss: 0.3674 - val_accuracy: 0.8517\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.6410 - accuracy: 0.8569 - val_loss: 0.4168 - val_accuracy: 0.8350\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.8516 - val_loss: 0.3035 - val_accuracy: 0.8967\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7497 - accuracy: 0.8380 - val_loss: 0.3177 - val_accuracy: 0.8867\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.8619 - val_loss: 0.3804 - val_accuracy: 0.8550\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.8791 - val_loss: 0.3443 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.8757 - val_loss: 0.3008 - val_accuracy: 0.8883\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.8746 - val_loss: 0.3537 - val_accuracy: 0.8867\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.6277 - accuracy: 0.8706 - val_loss: 0.3248 - val_accuracy: 0.8950\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.8746 - val_loss: 0.3539 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.8705 - val_loss: 0.3082 - val_accuracy: 0.8867\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.8719 - val_loss: 0.3294 - val_accuracy: 0.8833\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.8786 - val_loss: 0.4796 - val_accuracy: 0.7600\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5881 - accuracy: 0.8529 - val_loss: 0.2699 - val_accuracy: 0.9233\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.6597 - accuracy: 0.8807 - val_loss: 0.2641 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5805 - accuracy: 0.9017 - val_loss: 0.3653 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.8830 - val_loss: 0.3118 - val_accuracy: 0.8967\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.5744 - accuracy: 0.8814 - val_loss: 0.4018 - val_accuracy: 0.8433\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5878 - accuracy: 0.8786 - val_loss: 0.3192 - val_accuracy: 0.8783\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5974 - accuracy: 0.8766 - val_loss: 0.3221 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.5556 - accuracy: 0.8809 - val_loss: 0.2932 - val_accuracy: 0.9017\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5289 - accuracy: 0.9004 - val_loss: 0.3095 - val_accuracy: 0.8933\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.6339 - accuracy: 0.8866 - val_loss: 0.4112 - val_accuracy: 0.8383\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.5661 - accuracy: 0.8806 - val_loss: 0.3393 - val_accuracy: 0.8783\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8901 - val_loss: 0.3283 - val_accuracy: 0.8700\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1000us/step - loss: 0.6426 - accuracy: 0.8843 - val_loss: 0.3752 - val_accuracy: 0.8650\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.5468 - accuracy: 0.8940 - val_loss: 0.3134 - val_accuracy: 0.8817\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.5562 - accuracy: 0.8921 - val_loss: 0.2581 - val_accuracy: 0.9200\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.4981 - accuracy: 0.9057 - val_loss: 0.3703 - val_accuracy: 0.8633\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.5524 - accuracy: 0.8951 - val_loss: 0.2637 - val_accuracy: 0.9117\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.8934 - val_loss: 0.2915 - val_accuracy: 0.8967\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5114 - accuracy: 0.8936 - val_loss: 0.3366 - val_accuracy: 0.8633\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.5019 - accuracy: 0.9019 - val_loss: 0.3560 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 818us/step - loss: 0.5105 - accuracy: 0.9084 - val_loss: 0.3737 - val_accuracy: 0.8433\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.4586 - accuracy: 0.9055 - val_loss: 0.3301 - val_accuracy: 0.8783\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.5165 - accuracy: 0.8829 - val_loss: 0.3214 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5870 - accuracy: 0.8865 - val_loss: 0.2218 - val_accuracy: 0.9233\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.5283 - accuracy: 0.9129 - val_loss: 0.4035 - val_accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.5669 - accuracy: 0.8800 - val_loss: 0.3504 - val_accuracy: 0.8500\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.5719 - accuracy: 0.8854 - val_loss: 0.3322 - val_accuracy: 0.8583\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.4641 - accuracy: 0.8971 - val_loss: 0.2618 - val_accuracy: 0.9017\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.5022 - accuracy: 0.9076 - val_loss: 0.2667 - val_accuracy: 0.9067\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.9194 - val_loss: 0.3914 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.4953 - accuracy: 0.8972 - val_loss: 0.3051 - val_accuracy: 0.8850\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.8950 - val_loss: 0.2498 - val_accuracy: 0.9200\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4576 - accuracy: 0.9035 - val_loss: 0.2932 - val_accuracy: 0.8867\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.9053 - val_loss: 0.2718 - val_accuracy: 0.9100\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.9059 - val_loss: 0.3160 - val_accuracy: 0.8950\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.9120 - val_loss: 0.2551 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4624 - accuracy: 0.9111 - val_loss: 0.3364 - val_accuracy: 0.8633\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.8843 - val_loss: 0.3205 - val_accuracy: 0.8933\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.8999 - val_loss: 0.3404 - val_accuracy: 0.8617\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.9120 - val_loss: 0.2903 - val_accuracy: 0.8917\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.9085 - val_loss: 0.4134 - val_accuracy: 0.8200\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.9073 - val_loss: 0.2681 - val_accuracy: 0.9183\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.9175 - val_loss: 0.3527 - val_accuracy: 0.8433\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.9104 - val_loss: 0.2798 - val_accuracy: 0.8983\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2364 - accuracy: 0.6042 - val_loss: 0.5663 - val_accuracy: 0.7283\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.9522 - accuracy: 0.7411 - val_loss: 0.5173 - val_accuracy: 0.7850\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.8742 - accuracy: 0.7695 - val_loss: 0.4924 - val_accuracy: 0.7717\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.8258 - accuracy: 0.7831 - val_loss: 0.3690 - val_accuracy: 0.8467\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.8253 - accuracy: 0.8096 - val_loss: 0.4444 - val_accuracy: 0.8200\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.8019 - accuracy: 0.8183 - val_loss: 0.5658 - val_accuracy: 0.7300\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.8592 - accuracy: 0.7718 - val_loss: 0.4818 - val_accuracy: 0.8067\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.7405 - accuracy: 0.8324 - val_loss: 0.4107 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7954 - accuracy: 0.8198 - val_loss: 0.5333 - val_accuracy: 0.7817\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.8517 - val_loss: 0.4202 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.7972 - accuracy: 0.8164 - val_loss: 0.5871 - val_accuracy: 0.7517\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.7412 - accuracy: 0.8200 - val_loss: 0.4012 - val_accuracy: 0.8467\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 0.7445 - accuracy: 0.8258 - val_loss: 0.5011 - val_accuracy: 0.8033\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.7238 - accuracy: 0.8400 - val_loss: 0.3878 - val_accuracy: 0.8467\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.7409 - accuracy: 0.8498 - val_loss: 0.3224 - val_accuracy: 0.8883\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.6985 - accuracy: 0.8727 - val_loss: 0.3686 - val_accuracy: 0.8650\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.7335 - accuracy: 0.8550 - val_loss: 0.4282 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.7392 - accuracy: 0.8446 - val_loss: 0.3087 - val_accuracy: 0.8917\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.6621 - accuracy: 0.8641 - val_loss: 0.4964 - val_accuracy: 0.8083\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 993us/step - loss: 0.6516 - accuracy: 0.8588 - val_loss: 0.3666 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.6378 - accuracy: 0.8590 - val_loss: 0.3414 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7234 - accuracy: 0.8441 - val_loss: 0.3650 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.7110 - accuracy: 0.8401 - val_loss: 0.2734 - val_accuracy: 0.9017\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 890us/step - loss: 0.6784 - accuracy: 0.8696 - val_loss: 0.3227 - val_accuracy: 0.8850\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.6942 - accuracy: 0.8686 - val_loss: 0.3586 - val_accuracy: 0.8833\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6349 - accuracy: 0.8723 - val_loss: 0.2513 - val_accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 0.6379 - accuracy: 0.8750 - val_loss: 0.2982 - val_accuracy: 0.8850\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.6302 - accuracy: 0.8736 - val_loss: 0.4479 - val_accuracy: 0.8117\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6717 - accuracy: 0.8600 - val_loss: 0.3741 - val_accuracy: 0.8633\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.6054 - accuracy: 0.8834 - val_loss: 0.4207 - val_accuracy: 0.8283\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.5934 - accuracy: 0.8672 - val_loss: 0.3665 - val_accuracy: 0.8650\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.5587 - accuracy: 0.8737 - val_loss: 0.3297 - val_accuracy: 0.8933\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.6849 - accuracy: 0.8720 - val_loss: 0.2633 - val_accuracy: 0.9183\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5716 - accuracy: 0.8948 - val_loss: 0.2873 - val_accuracy: 0.9033\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.6062 - accuracy: 0.8816 - val_loss: 0.3577 - val_accuracy: 0.8700\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5586 - accuracy: 0.8863 - val_loss: 0.3552 - val_accuracy: 0.8783\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5874 - accuracy: 0.8723 - val_loss: 0.2680 - val_accuracy: 0.9067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.6157 - accuracy: 0.8835 - val_loss: 0.3064 - val_accuracy: 0.8950\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.5839 - accuracy: 0.8861 - val_loss: 0.2873 - val_accuracy: 0.8967\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.5426 - accuracy: 0.8962 - val_loss: 0.3103 - val_accuracy: 0.8967\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.5729 - accuracy: 0.8875 - val_loss: 0.3832 - val_accuracy: 0.8617\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.6563 - accuracy: 0.8644 - val_loss: 0.4277 - val_accuracy: 0.8550\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6063 - accuracy: 0.8838 - val_loss: 0.4558 - val_accuracy: 0.8200\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.5185 - accuracy: 0.8945 - val_loss: 0.2890 - val_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.6136 - accuracy: 0.8899 - val_loss: 0.3197 - val_accuracy: 0.8983\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.8998 - val_loss: 0.3614 - val_accuracy: 0.8800\n",
      "9\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4181 - accuracy: 0.5684 - val_loss: 0.7062 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 1.0634 - accuracy: 0.6707 - val_loss: 0.4507 - val_accuracy: 0.8017\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.9180 - accuracy: 0.7519 - val_loss: 0.4720 - val_accuracy: 0.7883\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.0051 - accuracy: 0.7556 - val_loss: 0.5436 - val_accuracy: 0.7267\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.7555 - val_loss: 0.3655 - val_accuracy: 0.8467\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.8553 - accuracy: 0.8051 - val_loss: 0.5183 - val_accuracy: 0.7717\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.8651 - accuracy: 0.7898 - val_loss: 0.3828 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.8751 - accuracy: 0.8009 - val_loss: 0.4603 - val_accuracy: 0.8100\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8438 - accuracy: 0.7959 - val_loss: 0.4233 - val_accuracy: 0.8233\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7579 - accuracy: 0.8322 - val_loss: 0.4202 - val_accuracy: 0.8050\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7982 - accuracy: 0.8155 - val_loss: 0.5489 - val_accuracy: 0.7333\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8151 - accuracy: 0.8008 - val_loss: 0.4399 - val_accuracy: 0.8317\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7370 - accuracy: 0.8287 - val_loss: 0.3309 - val_accuracy: 0.8783\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.8086 - accuracy: 0.8187 - val_loss: 0.3316 - val_accuracy: 0.8717\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8063 - accuracy: 0.8204 - val_loss: 0.3624 - val_accuracy: 0.8483\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7922 - accuracy: 0.8270 - val_loss: 0.3679 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8009 - accuracy: 0.8279 - val_loss: 0.3457 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.8507 - val_loss: 0.4612 - val_accuracy: 0.8217\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8095 - accuracy: 0.8196 - val_loss: 0.3128 - val_accuracy: 0.8867\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7636 - accuracy: 0.8231 - val_loss: 0.3466 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.8472 - val_loss: 0.4417 - val_accuracy: 0.8167\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.8477 - val_loss: 0.4316 - val_accuracy: 0.8300\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.8530 - val_loss: 0.3426 - val_accuracy: 0.8817\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.8549 - val_loss: 0.3008 - val_accuracy: 0.8883\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.8789 - val_loss: 0.3426 - val_accuracy: 0.8567\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.8601 - val_loss: 0.3878 - val_accuracy: 0.8450\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.8390 - val_loss: 0.4430 - val_accuracy: 0.8050\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.7073 - accuracy: 0.8295 - val_loss: 0.3556 - val_accuracy: 0.8550\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.6528 - accuracy: 0.8628 - val_loss: 0.3727 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.5977 - accuracy: 0.8695 - val_loss: 0.3875 - val_accuracy: 0.8567\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6831 - accuracy: 0.8553 - val_loss: 0.3710 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.6854 - accuracy: 0.8531 - val_loss: 0.3794 - val_accuracy: 0.8567\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.6485 - accuracy: 0.8520 - val_loss: 0.4250 - val_accuracy: 0.8233\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.7183 - accuracy: 0.8509 - val_loss: 0.3778 - val_accuracy: 0.8450\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.7747 - accuracy: 0.8557 - val_loss: 0.3358 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.6214 - accuracy: 0.8841 - val_loss: 0.2991 - val_accuracy: 0.8933\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5899 - accuracy: 0.8784 - val_loss: 0.3833 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6386 - accuracy: 0.8647 - val_loss: 0.3198 - val_accuracy: 0.9067\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.8499 - val_loss: 0.3319 - val_accuracy: 0.8850\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.8730 - val_loss: 0.3514 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.8953 - val_loss: 0.3748 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.8584 - val_loss: 0.2825 - val_accuracy: 0.8983\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.8746 - val_loss: 0.2920 - val_accuracy: 0.9033\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.8851 - val_loss: 0.4067 - val_accuracy: 0.8117\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.8755 - val_loss: 0.3727 - val_accuracy: 0.8583\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.6396 - accuracy: 0.8618 - val_loss: 0.3217 - val_accuracy: 0.8600\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.5328 - accuracy: 0.8759 - val_loss: 0.3875 - val_accuracy: 0.8350\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 976us/step - loss: 0.5541 - accuracy: 0.8695 - val_loss: 0.3610 - val_accuracy: 0.8800\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.5338 - accuracy: 0.8810 - val_loss: 0.3165 - val_accuracy: 0.8833\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.5247 - accuracy: 0.9074 - val_loss: 0.3754 - val_accuracy: 0.8700\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.5985 - accuracy: 0.8699 - val_loss: 0.2703 - val_accuracy: 0.9100\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.5505 - accuracy: 0.8951 - val_loss: 0.3773 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5261 - accuracy: 0.8904 - val_loss: 0.4375 - val_accuracy: 0.8150\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.6632 - accuracy: 0.8597 - val_loss: 0.3053 - val_accuracy: 0.8883\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.5444 - accuracy: 0.8718 - val_loss: 0.4419 - val_accuracy: 0.8117\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.5123 - accuracy: 0.8883 - val_loss: 0.2737 - val_accuracy: 0.9050\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.5680 - accuracy: 0.8803 - val_loss: 0.3202 - val_accuracy: 0.8683\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.5979 - accuracy: 0.8825 - val_loss: 0.3351 - val_accuracy: 0.8500\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.4952 - accuracy: 0.8972 - val_loss: 0.3372 - val_accuracy: 0.8733\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.5676 - accuracy: 0.8765 - val_loss: 0.3024 - val_accuracy: 0.8833\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.5118 - accuracy: 0.8915 - val_loss: 0.2845 - val_accuracy: 0.8883\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.6015 - accuracy: 0.8756 - val_loss: 0.2939 - val_accuracy: 0.9033\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6089 - accuracy: 0.8760 - val_loss: 0.2572 - val_accuracy: 0.9117\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 0.5918 - accuracy: 0.8865 - val_loss: 0.2786 - val_accuracy: 0.9133\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.5588 - accuracy: 0.8917 - val_loss: 0.3507 - val_accuracy: 0.8617\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.4678 - accuracy: 0.9012 - val_loss: 0.2559 - val_accuracy: 0.9083\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.5587 - accuracy: 0.8888 - val_loss: 0.4072 - val_accuracy: 0.8550\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.4299 - accuracy: 0.8943 - val_loss: 0.3182 - val_accuracy: 0.8683\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.5588 - accuracy: 0.8806 - val_loss: 0.3095 - val_accuracy: 0.8783\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.6360 - accuracy: 0.8797 - val_loss: 0.3196 - val_accuracy: 0.8783\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.4950 - accuracy: 0.8990 - val_loss: 0.4422 - val_accuracy: 0.8083\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.6768 - accuracy: 0.8549 - val_loss: 0.3474 - val_accuracy: 0.8500\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6029 - accuracy: 0.8799 - val_loss: 0.3487 - val_accuracy: 0.8583\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.4778 - accuracy: 0.8989 - val_loss: 0.3204 - val_accuracy: 0.8750\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.6346 - accuracy: 0.8704 - val_loss: 0.3074 - val_accuracy: 0.8867\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.5187 - accuracy: 0.8925 - val_loss: 0.4956 - val_accuracy: 0.8050\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.5386 - accuracy: 0.8848 - val_loss: 0.3493 - val_accuracy: 0.8717\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6832 - accuracy: 0.8763 - val_loss: 0.3000 - val_accuracy: 0.8850\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.4119 - accuracy: 0.9194 - val_loss: 0.2789 - val_accuracy: 0.8983\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.4994 - accuracy: 0.9000 - val_loss: 0.2806 - val_accuracy: 0.9033\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.4020 - accuracy: 0.9150 - val_loss: 0.3225 - val_accuracy: 0.8817\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.5069 - accuracy: 0.8928 - val_loss: 0.2931 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 0.4700 - accuracy: 0.9077 - val_loss: 0.3622 - val_accuracy: 0.8483\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.3851 - accuracy: 0.9087 - val_loss: 0.2601 - val_accuracy: 0.9133\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.4113 - accuracy: 0.9101 - val_loss: 0.3615 - val_accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5295 - accuracy: 0.8981 - val_loss: 0.3130 - val_accuracy: 0.8883\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2556 - accuracy: 0.5778 - val_loss: 0.5703 - val_accuracy: 0.7233\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9827 - accuracy: 0.7184 - val_loss: 0.5107 - val_accuracy: 0.7800\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.8383 - accuracy: 0.7906 - val_loss: 0.4820 - val_accuracy: 0.8067\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8943 - accuracy: 0.7678 - val_loss: 0.3725 - val_accuracy: 0.8517\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.8291 - accuracy: 0.8031 - val_loss: 0.4670 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.9405 - accuracy: 0.7524 - val_loss: 0.5055 - val_accuracy: 0.7733\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8341 - accuracy: 0.7919 - val_loss: 0.3924 - val_accuracy: 0.8517\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7638 - accuracy: 0.8228 - val_loss: 0.4079 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.8428 - accuracy: 0.8121 - val_loss: 0.3886 - val_accuracy: 0.8483\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7112 - accuracy: 0.8372 - val_loss: 0.4256 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.7329 - accuracy: 0.8443 - val_loss: 0.3771 - val_accuracy: 0.8567\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.8563 - accuracy: 0.8316 - val_loss: 0.4459 - val_accuracy: 0.8167\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.8072 - accuracy: 0.8307 - val_loss: 0.4321 - val_accuracy: 0.8250\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7675 - accuracy: 0.8379 - val_loss: 0.4847 - val_accuracy: 0.8017\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.8032 - accuracy: 0.8049 - val_loss: 0.3230 - val_accuracy: 0.8833\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7250 - accuracy: 0.8428 - val_loss: 0.4165 - val_accuracy: 0.8467\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.7405 - accuracy: 0.8345 - val_loss: 0.3575 - val_accuracy: 0.8750\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7202 - accuracy: 0.8542 - val_loss: 0.4300 - val_accuracy: 0.8117\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.7352 - accuracy: 0.8245 - val_loss: 0.4190 - val_accuracy: 0.8350\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.7016 - accuracy: 0.8539 - val_loss: 0.4795 - val_accuracy: 0.8050\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.5842 - accuracy: 0.8633 - val_loss: 0.3924 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.8678 - val_loss: 0.4481 - val_accuracy: 0.8383\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.8407 - val_loss: 0.3393 - val_accuracy: 0.8767\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.6403 - accuracy: 0.8723 - val_loss: 0.3527 - val_accuracy: 0.8700\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.7064 - accuracy: 0.8656 - val_loss: 0.4396 - val_accuracy: 0.8400\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 0.7009 - accuracy: 0.8590 - val_loss: 0.3551 - val_accuracy: 0.8733\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.5958 - accuracy: 0.8906 - val_loss: 0.3016 - val_accuracy: 0.9083\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.8821 - val_loss: 0.3998 - val_accuracy: 0.8500\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.7980 - accuracy: 0.8506 - val_loss: 0.3696 - val_accuracy: 0.8783\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6450 - accuracy: 0.8831 - val_loss: 0.3173 - val_accuracy: 0.8967\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6442 - accuracy: 0.8817 - val_loss: 0.3417 - val_accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.6826 - accuracy: 0.8664 - val_loss: 0.3146 - val_accuracy: 0.9017\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.6037 - accuracy: 0.8888 - val_loss: 0.3051 - val_accuracy: 0.9050\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.6039 - accuracy: 0.8852 - val_loss: 0.3404 - val_accuracy: 0.8633\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6594 - accuracy: 0.8663 - val_loss: 0.3235 - val_accuracy: 0.8900\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.5969 - accuracy: 0.8867 - val_loss: 0.4228 - val_accuracy: 0.8167\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.6188 - accuracy: 0.8749 - val_loss: 0.4227 - val_accuracy: 0.8367\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.6153 - accuracy: 0.8688 - val_loss: 0.3095 - val_accuracy: 0.8900\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.6450 - accuracy: 0.8699 - val_loss: 0.3364 - val_accuracy: 0.8733\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.6417 - accuracy: 0.8706 - val_loss: 0.2713 - val_accuracy: 0.9217\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.6325 - accuracy: 0.8754 - val_loss: 0.3858 - val_accuracy: 0.8517\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 940us/step - loss: 0.6669 - accuracy: 0.8584 - val_loss: 0.3345 - val_accuracy: 0.8783\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.6219 - accuracy: 0.8875 - val_loss: 0.3234 - val_accuracy: 0.8917\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.5461 - accuracy: 0.8973 - val_loss: 0.2925 - val_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.8868 - val_loss: 0.3194 - val_accuracy: 0.8867\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.8931 - val_loss: 0.3257 - val_accuracy: 0.9050\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6003 - accuracy: 0.8808 - val_loss: 0.4113 - val_accuracy: 0.8250\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6078 - accuracy: 0.8666 - val_loss: 0.2942 - val_accuracy: 0.8900\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.6762 - accuracy: 0.8729 - val_loss: 0.3705 - val_accuracy: 0.8683\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.5921 - accuracy: 0.8664 - val_loss: 0.1971 - val_accuracy: 0.9367\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5441 - accuracy: 0.9032 - val_loss: 0.3768 - val_accuracy: 0.8367\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5473 - accuracy: 0.8743 - val_loss: 0.3032 - val_accuracy: 0.8933\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.5772 - accuracy: 0.8788 - val_loss: 0.3446 - val_accuracy: 0.8283\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.8704 - val_loss: 0.3976 - val_accuracy: 0.8317\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.8735 - val_loss: 0.5218 - val_accuracy: 0.7450\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.5536 - accuracy: 0.8633 - val_loss: 0.6289 - val_accuracy: 0.7067\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.5672 - accuracy: 0.8511 - val_loss: 0.3163 - val_accuracy: 0.8867\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6816 - accuracy: 0.8501 - val_loss: 0.3733 - val_accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.5169 - accuracy: 0.8984 - val_loss: 0.3535 - val_accuracy: 0.8533\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.5641 - accuracy: 0.8823 - val_loss: 0.2705 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5212 - accuracy: 0.8988 - val_loss: 0.3800 - val_accuracy: 0.8433\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5463 - accuracy: 0.8808 - val_loss: 0.3925 - val_accuracy: 0.8633\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.5488 - accuracy: 0.8916 - val_loss: 0.3842 - val_accuracy: 0.8400\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.5808 - accuracy: 0.8803 - val_loss: 0.3479 - val_accuracy: 0.8550\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.4493 - accuracy: 0.9107 - val_loss: 0.2966 - val_accuracy: 0.8917\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5375 - accuracy: 0.8953 - val_loss: 0.3220 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.4834 - accuracy: 0.9115 - val_loss: 0.3498 - val_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.6181 - accuracy: 0.8749 - val_loss: 0.3376 - val_accuracy: 0.8733\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 993us/step - loss: 0.6231 - accuracy: 0.8763 - val_loss: 0.3318 - val_accuracy: 0.8633\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.5891 - accuracy: 0.8731 - val_loss: 0.2597 - val_accuracy: 0.9200\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3847 - accuracy: 0.5586 - val_loss: 0.6452 - val_accuracy: 0.6550\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 1.0290 - accuracy: 0.7045 - val_loss: 0.4991 - val_accuracy: 0.7733\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 1.0303 - accuracy: 0.7374 - val_loss: 0.4134 - val_accuracy: 0.8583\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.9344 - accuracy: 0.7740 - val_loss: 0.4220 - val_accuracy: 0.8367\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9745 - accuracy: 0.7519 - val_loss: 0.4029 - val_accuracy: 0.8400\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8256 - accuracy: 0.8104 - val_loss: 0.5157 - val_accuracy: 0.7800\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.8591 - accuracy: 0.7928 - val_loss: 0.7542 - val_accuracy: 0.5550\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.7970 - accuracy: 0.7984 - val_loss: 0.4583 - val_accuracy: 0.8067\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.8391 - accuracy: 0.8149 - val_loss: 0.4652 - val_accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 964us/step - loss: 0.8342 - accuracy: 0.7993 - val_loss: 0.3554 - val_accuracy: 0.8550\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 0.7510 - accuracy: 0.8503 - val_loss: 0.3689 - val_accuracy: 0.8567\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.7434 - accuracy: 0.8410 - val_loss: 0.3779 - val_accuracy: 0.8633\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8258 - accuracy: 0.8156 - val_loss: 0.4126 - val_accuracy: 0.8417\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7989 - accuracy: 0.8255 - val_loss: 0.5135 - val_accuracy: 0.7867\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7470 - accuracy: 0.8500 - val_loss: 0.3596 - val_accuracy: 0.8750\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7526 - accuracy: 0.8419 - val_loss: 0.3280 - val_accuracy: 0.8833\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7901 - accuracy: 0.8503 - val_loss: 0.4073 - val_accuracy: 0.8433\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.8578 - val_loss: 0.4097 - val_accuracy: 0.8550\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8190 - accuracy: 0.8307 - val_loss: 0.3964 - val_accuracy: 0.8617\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7486 - accuracy: 0.8532 - val_loss: 0.4094 - val_accuracy: 0.8600\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.6593 - accuracy: 0.87 - 0s 1ms/step - loss: 0.6629 - accuracy: 0.8729 - val_loss: 0.3620 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.8822 - val_loss: 0.3433 - val_accuracy: 0.8700\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7537 - accuracy: 0.8652 - val_loss: 0.4414 - val_accuracy: 0.8450\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.8619 - val_loss: 0.5366 - val_accuracy: 0.7700\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6547 - accuracy: 0.8701 - val_loss: 0.3408 - val_accuracy: 0.8733\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.8704 - val_loss: 0.3639 - val_accuracy: 0.8633\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.8759 - val_loss: 0.3200 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.8899 - val_loss: 0.3434 - val_accuracy: 0.8817\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.8718 - val_loss: 0.3693 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.8509 - val_loss: 0.3223 - val_accuracy: 0.8933\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.8843 - val_loss: 0.4612 - val_accuracy: 0.8250\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7370 - accuracy: 0.8301 - val_loss: 0.3916 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.8560 - val_loss: 0.3351 - val_accuracy: 0.8733\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.8953 - val_loss: 0.3210 - val_accuracy: 0.8950\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.8655 - val_loss: 0.3769 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.8477 - val_loss: 0.3783 - val_accuracy: 0.8700\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.8734 - val_loss: 0.3642 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.8624 - val_loss: 0.3469 - val_accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.8914 - val_loss: 0.3792 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.8708 - val_loss: 0.3232 - val_accuracy: 0.9033\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7575 - accuracy: 0.8634 - val_loss: 0.3416 - val_accuracy: 0.8800\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.8736 - val_loss: 0.3017 - val_accuracy: 0.9017\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.8854 - val_loss: 0.3060 - val_accuracy: 0.9133\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.5254 - accuracy: 0.9123 - val_loss: 0.3111 - val_accuracy: 0.8883\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.8895 - val_loss: 0.3394 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.8617 - val_loss: 0.2890 - val_accuracy: 0.8950\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.8954 - val_loss: 0.3370 - val_accuracy: 0.8733\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.9099 - val_loss: 0.4083 - val_accuracy: 0.8400\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.8766 - val_loss: 0.3290 - val_accuracy: 0.8833\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.8652 - val_loss: 0.3376 - val_accuracy: 0.8717\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.8887 - val_loss: 0.3455 - val_accuracy: 0.8600\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.8766 - val_loss: 0.3921 - val_accuracy: 0.8367\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6005 - accuracy: 0.8712 - val_loss: 0.2730 - val_accuracy: 0.9117\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6946 - accuracy: 0.8886 - val_loss: 0.3386 - val_accuracy: 0.8783\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 972us/step - loss: 0.5886 - accuracy: 0.8654 - val_loss: 0.3533 - val_accuracy: 0.8683\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.8937 - val_loss: 0.3195 - val_accuracy: 0.8917\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 979us/step - loss: 0.5817 - accuracy: 0.8847 - val_loss: 0.3272 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 964us/step - loss: 0.5541 - accuracy: 0.8924 - val_loss: 0.3534 - val_accuracy: 0.8850\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.5997 - accuracy: 0.8662 - val_loss: 0.3746 - val_accuracy: 0.8683\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 0.5932 - accuracy: 0.8777 - val_loss: 0.3967 - val_accuracy: 0.8567\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.8889 - val_loss: 0.3391 - val_accuracy: 0.8683\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.9063 - val_loss: 0.4524 - val_accuracy: 0.7950\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.8856 - val_loss: 0.3936 - val_accuracy: 0.8183\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8892 - val_loss: 0.3376 - val_accuracy: 0.8633\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.5226 - accuracy: 0.8852 - val_loss: 0.3228 - val_accuracy: 0.8733\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.8889 - val_loss: 0.3677 - val_accuracy: 0.8450\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.8980 - val_loss: 0.2439 - val_accuracy: 0.9233\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.8961 - val_loss: 0.4110 - val_accuracy: 0.8267\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.5297 - accuracy: 0.8668 - val_loss: 0.3025 - val_accuracy: 0.8883\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5057 - accuracy: 0.9070 - val_loss: 0.4120 - val_accuracy: 0.8267\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.5423 - accuracy: 0.8730 - val_loss: 0.3732 - val_accuracy: 0.8517\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.4953 - accuracy: 0.8981 - val_loss: 0.2900 - val_accuracy: 0.9100\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.5786 - accuracy: 0.8857 - val_loss: 0.2660 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.5849 - accuracy: 0.8794 - val_loss: 0.3815 - val_accuracy: 0.8533\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.8967 - val_loss: 0.2745 - val_accuracy: 0.9117\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.8960 - val_loss: 0.2956 - val_accuracy: 0.8833\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.5172 - accuracy: 0.8987 - val_loss: 0.3147 - val_accuracy: 0.8817\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5469 - accuracy: 0.8795 - val_loss: 0.3047 - val_accuracy: 0.8917\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5263 - accuracy: 0.9046 - val_loss: 0.3223 - val_accuracy: 0.8667\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.5498 - accuracy: 0.8912 - val_loss: 0.3145 - val_accuracy: 0.8617\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.5213 - accuracy: 0.8923 - val_loss: 0.3299 - val_accuracy: 0.8650\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.4994 - accuracy: 0.8936 - val_loss: 0.3238 - val_accuracy: 0.8633\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.4844 - accuracy: 0.8787 - val_loss: 0.2717 - val_accuracy: 0.9017\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.4224 - accuracy: 0.9248 - val_loss: 0.2985 - val_accuracy: 0.8917\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.9021 - val_loss: 0.2368 - val_accuracy: 0.9217\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5236 - accuracy: 0.9049 - val_loss: 0.3437 - val_accuracy: 0.8550\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.9111 - val_loss: 0.2802 - val_accuracy: 0.8983\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.4898 - accuracy: 0.9066 - val_loss: 0.3093 - val_accuracy: 0.8833\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.8925 - val_loss: 0.2801 - val_accuracy: 0.9017\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.8891 - val_loss: 0.3464 - val_accuracy: 0.8717\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.8985 - val_loss: 0.2645 - val_accuracy: 0.9133\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.8917 - val_loss: 0.3229 - val_accuracy: 0.8817\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 0s 969us/step - loss: 0.4924 - accuracy: 0.9058 - val_loss: 0.3091 - val_accuracy: 0.8867\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.4751 - accuracy: 0.8901 - val_loss: 0.3070 - val_accuracy: 0.8850\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.9144 - val_loss: 0.3610 - val_accuracy: 0.8550\n",
      "Epoch 96/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 0.4991 - accuracy: 0.8992 - val_loss: 0.2523 - val_accuracy: 0.9083\n",
      "Epoch 97/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.9187 - val_loss: 0.3084 - val_accuracy: 0.8850\n",
      "Epoch 98/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.5592 - accuracy: 0.8931 - val_loss: 0.2600 - val_accuracy: 0.8933\n",
      "Epoch 99/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.4755 - accuracy: 0.8997 - val_loss: 0.3376 - val_accuracy: 0.8600\n",
      "Epoch 100/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.9042 - val_loss: 0.3536 - val_accuracy: 0.8650\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2960 - accuracy: 0.5863 - val_loss: 0.5845 - val_accuracy: 0.7350\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9765 - accuracy: 0.7209 - val_loss: 0.4769 - val_accuracy: 0.7867\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9429 - accuracy: 0.7423 - val_loss: 0.4591 - val_accuracy: 0.8267\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8773 - accuracy: 0.7914 - val_loss: 0.3393 - val_accuracy: 0.8767\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.8733 - accuracy: 0.8128 - val_loss: 0.4185 - val_accuracy: 0.8383\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.8273 - accuracy: 0.8132 - val_loss: 0.3871 - val_accuracy: 0.8467\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.8481 - accuracy: 0.8043 - val_loss: 0.4915 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.8260 - accuracy: 0.7975 - val_loss: 0.4845 - val_accuracy: 0.8017\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8270 - accuracy: 0.8023 - val_loss: 0.3423 - val_accuracy: 0.8817\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.7510 - accuracy: 0.8352 - val_loss: 0.5233 - val_accuracy: 0.7800\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 0.6987 - accuracy: 0.8320 - val_loss: 0.3858 - val_accuracy: 0.8583\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.7992 - accuracy: 0.8219 - val_loss: 0.4262 - val_accuracy: 0.8283\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.8498 - val_loss: 0.3430 - val_accuracy: 0.8800\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.8052 - accuracy: 0.8327 - val_loss: 0.4383 - val_accuracy: 0.8167\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7666 - accuracy: 0.8231 - val_loss: 0.3425 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.8062 - accuracy: 0.8298 - val_loss: 0.5320 - val_accuracy: 0.7883\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6627 - accuracy: 0.8616 - val_loss: 0.3741 - val_accuracy: 0.8717\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7056 - accuracy: 0.8573 - val_loss: 0.3185 - val_accuracy: 0.8883\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.6847 - accuracy: 0.8685 - val_loss: 0.3573 - val_accuracy: 0.8717\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.7686 - accuracy: 0.8440 - val_loss: 0.3434 - val_accuracy: 0.8800\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.6874 - accuracy: 0.8686 - val_loss: 0.3581 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6829 - accuracy: 0.8641 - val_loss: 0.3919 - val_accuracy: 0.8417\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6807 - accuracy: 0.8553 - val_loss: 0.4363 - val_accuracy: 0.8350\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.6253 - accuracy: 0.8739 - val_loss: 0.3411 - val_accuracy: 0.8717\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.8761 - val_loss: 0.3593 - val_accuracy: 0.8733\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.8579 - val_loss: 0.3642 - val_accuracy: 0.8700\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6374 - accuracy: 0.8795 - val_loss: 0.3878 - val_accuracy: 0.8433\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.7020 - accuracy: 0.8456 - val_loss: 0.4769 - val_accuracy: 0.8283\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.6696 - accuracy: 0.8697 - val_loss: 0.3394 - val_accuracy: 0.8950\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.8734 - val_loss: 0.4562 - val_accuracy: 0.7900\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6520 - accuracy: 0.8768 - val_loss: 0.3342 - val_accuracy: 0.8800\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.8622 - val_loss: 0.2904 - val_accuracy: 0.8900\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.8795 - val_loss: 0.3361 - val_accuracy: 0.8800\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.8770 - val_loss: 0.2707 - val_accuracy: 0.9200\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.6119 - accuracy: 0.8815 - val_loss: 0.3923 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.7187 - accuracy: 0.8578 - val_loss: 0.3550 - val_accuracy: 0.8867\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5872 - accuracy: 0.8946 - val_loss: 0.2962 - val_accuracy: 0.9083\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.5927 - accuracy: 0.8886 - val_loss: 0.4707 - val_accuracy: 0.7883\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6748 - accuracy: 0.8585 - val_loss: 0.2830 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.8882 - val_loss: 0.4272 - val_accuracy: 0.8400\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.8837 - val_loss: 0.3332 - val_accuracy: 0.8600\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6369 - accuracy: 0.8765 - val_loss: 0.3486 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 987us/step - loss: 0.6032 - accuracy: 0.8754 - val_loss: 0.4435 - val_accuracy: 0.8133\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6169 - accuracy: 0.8706 - val_loss: 0.3514 - val_accuracy: 0.8683\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.8650 - val_loss: 0.3279 - val_accuracy: 0.8900\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6255 - accuracy: 0.8958 - val_loss: 0.2810 - val_accuracy: 0.8900\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.8702 - val_loss: 0.3996 - val_accuracy: 0.8350\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.8923 - val_loss: 0.3662 - val_accuracy: 0.8467\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.8810 - val_loss: 0.3931 - val_accuracy: 0.8383\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.8789 - val_loss: 0.4095 - val_accuracy: 0.8133\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.8883 - val_loss: 0.3266 - val_accuracy: 0.8850\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.9029 - val_loss: 0.2971 - val_accuracy: 0.8883\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.8836 - val_loss: 0.2473 - val_accuracy: 0.9150\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.8920 - val_loss: 0.3089 - val_accuracy: 0.8883\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.9136 - val_loss: 0.4512 - val_accuracy: 0.8400\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.8743 - val_loss: 0.2720 - val_accuracy: 0.9033\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.8892 - val_loss: 0.3062 - val_accuracy: 0.8817\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.8752 - val_loss: 0.2780 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.8961 - val_loss: 0.3188 - val_accuracy: 0.8867\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.9015 - val_loss: 0.3445 - val_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.8999 - val_loss: 0.2865 - val_accuracy: 0.8917\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.8774 - val_loss: 0.2996 - val_accuracy: 0.8833\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.8859 - val_loss: 0.2582 - val_accuracy: 0.9067\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.8926 - val_loss: 0.3138 - val_accuracy: 0.8783\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.9046 - val_loss: 0.3213 - val_accuracy: 0.8900\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.9005 - val_loss: 0.4050 - val_accuracy: 0.8350\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.8730 - val_loss: 0.2721 - val_accuracy: 0.9067\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.8855 - val_loss: 0.3355 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.9062 - val_loss: 0.2964 - val_accuracy: 0.8867\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.8882 - val_loss: 0.3440 - val_accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.9062 - val_loss: 0.3454 - val_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.9055 - val_loss: 0.3643 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.8968 - val_loss: 0.3261 - val_accuracy: 0.8817\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 2ms/step - loss: 1.4295 - accuracy: 0.5380 - val_loss: 0.6417 - val_accuracy: 0.6883\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0924 - accuracy: 0.6833 - val_loss: 0.5212 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.9884 - accuracy: 0.7381 - val_loss: 0.4789 - val_accuracy: 0.8017\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9002 - accuracy: 0.7710 - val_loss: 0.6225 - val_accuracy: 0.6967\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8960 - accuracy: 0.7514 - val_loss: 0.4334 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8164 - accuracy: 0.8038 - val_loss: 0.3799 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8626 - accuracy: 0.7926 - val_loss: 0.4169 - val_accuracy: 0.8350\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.8923 - accuracy: 0.8035 - val_loss: 0.4326 - val_accuracy: 0.8433\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8362 - accuracy: 0.8244 - val_loss: 0.4647 - val_accuracy: 0.8117\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8381 - accuracy: 0.8114 - val_loss: 0.4583 - val_accuracy: 0.8150\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7552 - accuracy: 0.8318 - val_loss: 0.3728 - val_accuracy: 0.8517\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7164 - accuracy: 0.8528 - val_loss: 0.4375 - val_accuracy: 0.8183\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8437 - accuracy: 0.8230 - val_loss: 0.4292 - val_accuracy: 0.8350\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7702 - accuracy: 0.8568 - val_loss: 0.4157 - val_accuracy: 0.8517\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6523 - accuracy: 0.8689 - val_loss: 0.3822 - val_accuracy: 0.8633\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7964 - accuracy: 0.8500 - val_loss: 0.3682 - val_accuracy: 0.8633\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.8636 - val_loss: 0.3414 - val_accuracy: 0.8850\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.6793 - accuracy: 0.8682 - val_loss: 0.3712 - val_accuracy: 0.8733\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7366 - accuracy: 0.8510 - val_loss: 0.3933 - val_accuracy: 0.8583\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6518 - accuracy: 0.8664 - val_loss: 0.3875 - val_accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6755 - accuracy: 0.8610 - val_loss: 0.3882 - val_accuracy: 0.8433\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6777 - accuracy: 0.8670 - val_loss: 0.4266 - val_accuracy: 0.8533\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7354 - accuracy: 0.8471 - val_loss: 0.3398 - val_accuracy: 0.8783\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.8791 - val_loss: 0.3366 - val_accuracy: 0.8717\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 0.8576 - val_loss: 0.3507 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6744 - accuracy: 0.8731 - val_loss: 0.4754 - val_accuracy: 0.8200\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.8459 - val_loss: 0.3503 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7499 - accuracy: 0.8496 - val_loss: 0.3259 - val_accuracy: 0.8783\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5630 - accuracy: 0.8990 - val_loss: 0.4976 - val_accuracy: 0.8183\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6763 - accuracy: 0.8550 - val_loss: 0.3736 - val_accuracy: 0.8617\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6599 - accuracy: 0.8564 - val_loss: 0.3692 - val_accuracy: 0.8533\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6012 - accuracy: 0.8847 - val_loss: 0.3635 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7113 - accuracy: 0.8549 - val_loss: 0.2720 - val_accuracy: 0.8967\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6502 - accuracy: 0.8693 - val_loss: 0.3128 - val_accuracy: 0.9017\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7946 - accuracy: 0.8536 - val_loss: 0.3591 - val_accuracy: 0.8550\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6159 - accuracy: 0.8726 - val_loss: 0.3408 - val_accuracy: 0.8733\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6453 - accuracy: 0.8716 - val_loss: 0.3285 - val_accuracy: 0.8833\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4977 - accuracy: 0.9035 - val_loss: 0.4201 - val_accuracy: 0.8200\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6089 - accuracy: 0.8726 - val_loss: 0.4046 - val_accuracy: 0.8617\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6165 - accuracy: 0.8667 - val_loss: 0.3257 - val_accuracy: 0.8700\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6590 - accuracy: 0.8666 - val_loss: 0.3537 - val_accuracy: 0.8533\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6574 - accuracy: 0.8539 - val_loss: 0.4255 - val_accuracy: 0.8183\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.5740 - accuracy: 0.8683 - val_loss: 0.4158 - val_accuracy: 0.8200\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.5129 - accuracy: 0.8893 - val_loss: 0.3881 - val_accuracy: 0.8450\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6153 - accuracy: 0.8764 - val_loss: 0.3584 - val_accuracy: 0.8600\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.5874 - accuracy: 0.8861 - val_loss: 0.3528 - val_accuracy: 0.8650\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.8831 - val_loss: 0.4245 - val_accuracy: 0.8350\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.5556 - accuracy: 0.8769 - val_loss: 0.3874 - val_accuracy: 0.8367\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5617 - accuracy: 0.8722 - val_loss: 0.2644 - val_accuracy: 0.9050\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5761 - accuracy: 0.8983 - val_loss: 0.3227 - val_accuracy: 0.8917\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5296 - accuracy: 0.8911 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.8484 - val_loss: 0.4471 - val_accuracy: 0.8050\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.8788 - val_loss: 0.4018 - val_accuracy: 0.8350\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8859 - val_loss: 0.3023 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6382 - accuracy: 0.8814 - val_loss: 0.3131 - val_accuracy: 0.8817\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6660 - accuracy: 0.8759 - val_loss: 0.2840 - val_accuracy: 0.8900\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5675 - accuracy: 0.8876 - val_loss: 0.3647 - val_accuracy: 0.8517\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5438 - accuracy: 0.8856 - val_loss: 0.3392 - val_accuracy: 0.8933\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6070 - accuracy: 0.8768 - val_loss: 0.2981 - val_accuracy: 0.8850\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5159 - accuracy: 0.8861 - val_loss: 0.3810 - val_accuracy: 0.8383\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5283 - accuracy: 0.8793 - val_loss: 0.3365 - val_accuracy: 0.8700\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5135 - accuracy: 0.9009 - val_loss: 0.3188 - val_accuracy: 0.8767\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.4871 - accuracy: 0.9038 - val_loss: 0.2485 - val_accuracy: 0.9183\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.8999 - val_loss: 0.2617 - val_accuracy: 0.9150\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.9035 - val_loss: 0.3279 - val_accuracy: 0.8733\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.9034 - val_loss: 0.3321 - val_accuracy: 0.8717\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5605 - accuracy: 0.8820 - val_loss: 0.3120 - val_accuracy: 0.8850\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5380 - accuracy: 0.8933 - val_loss: 0.3327 - val_accuracy: 0.8500\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.4408 - accuracy: 0.8972 - val_loss: 0.3183 - val_accuracy: 0.8700\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.4829 - accuracy: 0.8843 - val_loss: 0.2587 - val_accuracy: 0.9100\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.4239 - accuracy: 0.9051 - val_loss: 0.3111 - val_accuracy: 0.8650\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.4272 - accuracy: 0.9028 - val_loss: 0.2840 - val_accuracy: 0.8950\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5762 - accuracy: 0.8862 - val_loss: 0.3255 - val_accuracy: 0.8833\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4803 - accuracy: 0.8959 - val_loss: 0.3382 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4783 - accuracy: 0.9061 - val_loss: 0.2413 - val_accuracy: 0.9200\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4151 - accuracy: 0.9190 - val_loss: 0.2208 - val_accuracy: 0.9367\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.4513 - accuracy: 0.9211 - val_loss: 0.2801 - val_accuracy: 0.8950\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.3855 - accuracy: 0.9247 - val_loss: 0.3316 - val_accuracy: 0.8633\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.9112 - val_loss: 0.3178 - val_accuracy: 0.8683\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.9079 - val_loss: 0.3619 - val_accuracy: 0.8450\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5492 - accuracy: 0.8781 - val_loss: 0.2978 - val_accuracy: 0.8950\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.9096 - val_loss: 0.2960 - val_accuracy: 0.8667\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.4530 - accuracy: 0.9005 - val_loss: 0.2598 - val_accuracy: 0.9033\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.5208 - accuracy: 0.9029 - val_loss: 0.2347 - val_accuracy: 0.9183\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.3902 - accuracy: 0.9286 - val_loss: 0.2287 - val_accuracy: 0.9233\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.9142 - val_loss: 0.2344 - val_accuracy: 0.9233\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.9147 - val_loss: 0.2911 - val_accuracy: 0.9033\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.9190 - val_loss: 0.2718 - val_accuracy: 0.8883\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.4563 - accuracy: 0.9071 - val_loss: 0.3772 - val_accuracy: 0.8417\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.4095 - accuracy: 0.9074 - val_loss: 0.3335 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5014 - accuracy: 0.9086 - val_loss: 0.3126 - val_accuracy: 0.8750\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.4694 - accuracy: 0.8963 - val_loss: 0.2381 - val_accuracy: 0.9133\n",
      "Epoch 93/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.4266 - accuracy: 0.9030 - val_loss: 0.2375 - val_accuracy: 0.9150\n",
      "Epoch 94/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.4547 - accuracy: 0.9101 - val_loss: 0.2761 - val_accuracy: 0.8900\n",
      "Epoch 95/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.4152 - accuracy: 0.9195 - val_loss: 0.2171 - val_accuracy: 0.9233\n",
      "Epoch 96/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.4960 - accuracy: 0.9008 - val_loss: 0.3043 - val_accuracy: 0.8883\n",
      "Epoch 97/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5239 - accuracy: 0.9003 - val_loss: 0.2895 - val_accuracy: 0.8883\n",
      "Epoch 98/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.4495 - accuracy: 0.9167 - val_loss: 0.2533 - val_accuracy: 0.9067\n",
      "Epoch 99/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.3939 - accuracy: 0.9207 - val_loss: 0.3266 - val_accuracy: 0.8567\n",
      "Epoch 100/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.8998 - val_loss: 0.2725 - val_accuracy: 0.8833\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 2ms/step - loss: 1.4505 - accuracy: 0.5142 - val_loss: 0.5336 - val_accuracy: 0.7300\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 992us/step - loss: 1.1188 - accuracy: 0.6589 - val_loss: 0.4909 - val_accuracy: 0.7883\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9955 - accuracy: 0.7350 - val_loss: 0.5465 - val_accuracy: 0.7517\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.9601 - accuracy: 0.7560 - val_loss: 0.4544 - val_accuracy: 0.7967\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.9891 - accuracy: 0.7632 - val_loss: 0.4476 - val_accuracy: 0.8067\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.9811 - accuracy: 0.7608 - val_loss: 0.3613 - val_accuracy: 0.8533\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8732 - accuracy: 0.8128 - val_loss: 0.4588 - val_accuracy: 0.8150\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.8233 - accuracy: 0.8121 - val_loss: 0.4772 - val_accuracy: 0.7700\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8365 - accuracy: 0.8100 - val_loss: 0.3556 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8439 - accuracy: 0.8166 - val_loss: 0.5024 - val_accuracy: 0.7900\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.8299 - accuracy: 0.7832 - val_loss: 0.4906 - val_accuracy: 0.7633\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8107 - accuracy: 0.8182 - val_loss: 0.4149 - val_accuracy: 0.8317\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7393 - accuracy: 0.8328 - val_loss: 0.5461 - val_accuracy: 0.7367\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7964 - accuracy: 0.8138 - val_loss: 0.4623 - val_accuracy: 0.8283\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7838 - accuracy: 0.8284 - val_loss: 0.4005 - val_accuracy: 0.8533\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8463 - accuracy: 0.8307 - val_loss: 0.4046 - val_accuracy: 0.8450\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7036 - accuracy: 0.8520 - val_loss: 0.4103 - val_accuracy: 0.8400\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7399 - accuracy: 0.8481 - val_loss: 0.3568 - val_accuracy: 0.8617\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.7679 - accuracy: 0.8459 - val_loss: 0.4361 - val_accuracy: 0.8350\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6961 - accuracy: 0.8550 - val_loss: 0.3973 - val_accuracy: 0.8467\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6970 - accuracy: 0.8548 - val_loss: 0.3291 - val_accuracy: 0.9017\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6787 - accuracy: 0.8775 - val_loss: 0.3285 - val_accuracy: 0.8883\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7935 - accuracy: 0.8491 - val_loss: 0.2925 - val_accuracy: 0.8950\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7041 - accuracy: 0.8798 - val_loss: 0.4322 - val_accuracy: 0.8533\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7112 - accuracy: 0.8572 - val_loss: 0.4325 - val_accuracy: 0.8450\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.7295 - accuracy: 0.8417 - val_loss: 0.4180 - val_accuracy: 0.8500\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.6570 - accuracy: 0.8703 - val_loss: 0.3882 - val_accuracy: 0.8600\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.8722 - val_loss: 0.3737 - val_accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.8749 - val_loss: 0.3328 - val_accuracy: 0.8717\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.7173 - accuracy: 0.8488 - val_loss: 0.3590 - val_accuracy: 0.8867\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7081 - accuracy: 0.8699 - val_loss: 0.4276 - val_accuracy: 0.8450\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.8846 - val_loss: 0.3302 - val_accuracy: 0.8850\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.6382 - accuracy: 0.8840 - val_loss: 0.4388 - val_accuracy: 0.8367\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.8771 - val_loss: 0.4334 - val_accuracy: 0.8450\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.6335 - accuracy: 0.8785 - val_loss: 0.3032 - val_accuracy: 0.9033\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7129 - accuracy: 0.8682 - val_loss: 0.4484 - val_accuracy: 0.8183\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.5974 - accuracy: 0.8699 - val_loss: 0.3661 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7302 - accuracy: 0.8601 - val_loss: 0.3386 - val_accuracy: 0.8933\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6001 - accuracy: 0.8941 - val_loss: 0.4308 - val_accuracy: 0.8483\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.6132 - accuracy: 0.8902 - val_loss: 0.4937 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6347 - accuracy: 0.8623 - val_loss: 0.4090 - val_accuracy: 0.8483\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6200 - accuracy: 0.8684 - val_loss: 0.2655 - val_accuracy: 0.9017\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.8955 - val_loss: 0.3800 - val_accuracy: 0.8517\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.5254 - accuracy: 0.9026 - val_loss: 0.3293 - val_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.5759 - accuracy: 0.8749 - val_loss: 0.4896 - val_accuracy: 0.7750\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7120 - accuracy: 0.8503 - val_loss: 0.3334 - val_accuracy: 0.8683\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.8861 - val_loss: 0.3092 - val_accuracy: 0.8900\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.8925 - val_loss: 0.3236 - val_accuracy: 0.8883\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.9039 - val_loss: 0.3509 - val_accuracy: 0.8817\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5330 - accuracy: 0.8955 - val_loss: 0.4566 - val_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.8754 - val_loss: 0.4049 - val_accuracy: 0.8517\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.8944 - val_loss: 0.4060 - val_accuracy: 0.8400\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.8567 - val_loss: 0.3456 - val_accuracy: 0.8733\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5103 - accuracy: 0.9005 - val_loss: 0.3767 - val_accuracy: 0.8433\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5839 - accuracy: 0.8828 - val_loss: 0.4042 - val_accuracy: 0.8517\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6306 - accuracy: 0.8748 - val_loss: 0.3186 - val_accuracy: 0.8850\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5792 - accuracy: 0.8837 - val_loss: 0.3483 - val_accuracy: 0.8800\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5656 - accuracy: 0.8917 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5433 - accuracy: 0.9096 - val_loss: 0.2948 - val_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5235 - accuracy: 0.9043 - val_loss: 0.3785 - val_accuracy: 0.8617\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5254 - accuracy: 0.8825 - val_loss: 0.3019 - val_accuracy: 0.8983\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5174 - accuracy: 0.8965 - val_loss: 0.3922 - val_accuracy: 0.8367\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2322 - accuracy: 0.5774 - val_loss: 0.6317 - val_accuracy: 0.6600\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 1.0822 - accuracy: 0.6689 - val_loss: 0.5094 - val_accuracy: 0.7417\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.9604 - accuracy: 0.7488 - val_loss: 0.5188 - val_accuracy: 0.7583\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.9678 - accuracy: 0.7314 - val_loss: 0.3877 - val_accuracy: 0.8517\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8522 - accuracy: 0.8083 - val_loss: 0.5145 - val_accuracy: 0.7800\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.9077 - accuracy: 0.7772 - val_loss: 0.3891 - val_accuracy: 0.8267\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7933 - accuracy: 0.8132 - val_loss: 0.4882 - val_accuracy: 0.7883\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8142 - accuracy: 0.8233 - val_loss: 0.4514 - val_accuracy: 0.8167\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8105 - accuracy: 0.8214 - val_loss: 0.4680 - val_accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.7878 - accuracy: 0.8100 - val_loss: 0.3558 - val_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8453 - accuracy: 0.8190 - val_loss: 0.4285 - val_accuracy: 0.8550\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7987 - accuracy: 0.8305 - val_loss: 0.4590 - val_accuracy: 0.8150\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8050 - accuracy: 0.8267 - val_loss: 0.4457 - val_accuracy: 0.8217\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7805 - accuracy: 0.8191 - val_loss: 0.3923 - val_accuracy: 0.8517\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8069 - accuracy: 0.8225 - val_loss: 0.4003 - val_accuracy: 0.8433\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6315 - accuracy: 0.8586 - val_loss: 0.4090 - val_accuracy: 0.8483\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7056 - accuracy: 0.8525 - val_loss: 0.4936 - val_accuracy: 0.7900\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7264 - accuracy: 0.8356 - val_loss: 0.3017 - val_accuracy: 0.8950\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7592 - accuracy: 0.8468 - val_loss: 0.3556 - val_accuracy: 0.8850\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6752 - accuracy: 0.8686 - val_loss: 0.3537 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7569 - accuracy: 0.8466 - val_loss: 0.3002 - val_accuracy: 0.8883\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7354 - accuracy: 0.8613 - val_loss: 0.3829 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6712 - accuracy: 0.8601 - val_loss: 0.3111 - val_accuracy: 0.8967\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6889 - accuracy: 0.8695 - val_loss: 0.4035 - val_accuracy: 0.8500\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6966 - accuracy: 0.8459 - val_loss: 0.3774 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6786 - accuracy: 0.8778 - val_loss: 0.2871 - val_accuracy: 0.9050\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.7056 - accuracy: 0.8631 - val_loss: 0.3870 - val_accuracy: 0.8567\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7091 - accuracy: 0.8625 - val_loss: 0.3712 - val_accuracy: 0.8867\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6317 - accuracy: 0.8655 - val_loss: 0.3456 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7025 - accuracy: 0.8629 - val_loss: 0.3643 - val_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6775 - accuracy: 0.8681 - val_loss: 0.4075 - val_accuracy: 0.8617\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6303 - accuracy: 0.8799 - val_loss: 0.4045 - val_accuracy: 0.8533\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6351 - accuracy: 0.8669 - val_loss: 0.3590 - val_accuracy: 0.8717\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6502 - accuracy: 0.8822 - val_loss: 0.3244 - val_accuracy: 0.9017\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6059 - accuracy: 0.8725 - val_loss: 0.3255 - val_accuracy: 0.8983\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6047 - accuracy: 0.8737 - val_loss: 0.3255 - val_accuracy: 0.8767\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6345 - accuracy: 0.8740 - val_loss: 0.3584 - val_accuracy: 0.8817\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6683 - accuracy: 0.8742 - val_loss: 0.2913 - val_accuracy: 0.9083\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6387 - accuracy: 0.8636 - val_loss: 0.3026 - val_accuracy: 0.9083\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5633 - accuracy: 0.8892 - val_loss: 0.4794 - val_accuracy: 0.7700\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5839 - accuracy: 0.8737 - val_loss: 0.3318 - val_accuracy: 0.8833\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5497 - accuracy: 0.8834 - val_loss: 0.2893 - val_accuracy: 0.8983\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6694 - accuracy: 0.8744 - val_loss: 0.3194 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5872 - accuracy: 0.8950 - val_loss: 0.2976 - val_accuracy: 0.9083\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5696 - accuracy: 0.8850 - val_loss: 0.3091 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6228 - accuracy: 0.8708 - val_loss: 0.3110 - val_accuracy: 0.8983\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3518 - accuracy: 0.5625 - val_loss: 0.5692 - val_accuracy: 0.6967\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.9680 - accuracy: 0.7277 - val_loss: 0.5329 - val_accuracy: 0.7683\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9221 - accuracy: 0.7511 - val_loss: 0.6036 - val_accuracy: 0.7033\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9558 - accuracy: 0.7400 - val_loss: 0.5864 - val_accuracy: 0.7250\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8064 - accuracy: 0.7972 - val_loss: 0.3802 - val_accuracy: 0.8650\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8936 - accuracy: 0.8011 - val_loss: 0.4347 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7650 - accuracy: 0.8196 - val_loss: 0.4338 - val_accuracy: 0.8167\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.8103 - accuracy: 0.8090 - val_loss: 0.4458 - val_accuracy: 0.8150\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8695 - accuracy: 0.8004 - val_loss: 0.3906 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8407 - accuracy: 0.8139 - val_loss: 0.4375 - val_accuracy: 0.8200\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8084 - accuracy: 0.8132 - val_loss: 0.4584 - val_accuracy: 0.8167\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7805 - accuracy: 0.8138 - val_loss: 0.5091 - val_accuracy: 0.7833\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.8176 - val_loss: 0.3267 - val_accuracy: 0.9067\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.7524 - accuracy: 0.8447 - val_loss: 0.3846 - val_accuracy: 0.8567\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6941 - accuracy: 0.8384 - val_loss: 0.4601 - val_accuracy: 0.8150\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6419 - accuracy: 0.8461 - val_loss: 0.5093 - val_accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7281 - accuracy: 0.8339 - val_loss: 0.4778 - val_accuracy: 0.7983\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7330 - accuracy: 0.8405 - val_loss: 0.4513 - val_accuracy: 0.8350\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7564 - accuracy: 0.8322 - val_loss: 0.4268 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7418 - accuracy: 0.8468 - val_loss: 0.3255 - val_accuracy: 0.8917\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6756 - accuracy: 0.8685 - val_loss: 0.3444 - val_accuracy: 0.8650\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.8656 - val_loss: 0.4241 - val_accuracy: 0.8567\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.6845 - accuracy: 0.8606 - val_loss: 0.4355 - val_accuracy: 0.8233\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.7575 - accuracy: 0.8262 - val_loss: 0.3792 - val_accuracy: 0.8683\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.6793 - accuracy: 0.8631 - val_loss: 0.2732 - val_accuracy: 0.8983\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.7396 - accuracy: 0.8459 - val_loss: 0.3168 - val_accuracy: 0.8883\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7234 - accuracy: 0.8406 - val_loss: 0.4022 - val_accuracy: 0.8450\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5888 - accuracy: 0.8808 - val_loss: 0.4957 - val_accuracy: 0.7717\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.6982 - accuracy: 0.8440 - val_loss: 0.3043 - val_accuracy: 0.8917\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6133 - accuracy: 0.8800 - val_loss: 0.3617 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6662 - accuracy: 0.8531 - val_loss: 0.3533 - val_accuracy: 0.8700\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.6579 - accuracy: 0.8664 - val_loss: 0.4453 - val_accuracy: 0.7950\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7171 - accuracy: 0.8370 - val_loss: 0.2816 - val_accuracy: 0.9017\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6128 - accuracy: 0.8832 - val_loss: 0.3715 - val_accuracy: 0.8583\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5740 - accuracy: 0.8784 - val_loss: 0.3472 - val_accuracy: 0.8650\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.8767 - val_loss: 0.3292 - val_accuracy: 0.8783\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.6685 - accuracy: 0.8742 - val_loss: 0.3852 - val_accuracy: 0.8717\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.8592 - val_loss: 0.3146 - val_accuracy: 0.8950\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.8797 - val_loss: 0.2776 - val_accuracy: 0.9083\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.8804 - val_loss: 0.3102 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.8774 - val_loss: 0.2761 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6780 - accuracy: 0.8729 - val_loss: 0.3732 - val_accuracy: 0.8383\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6535 - accuracy: 0.8747 - val_loss: 0.3035 - val_accuracy: 0.8883\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.5784 - accuracy: 0.8806 - val_loss: 0.4302 - val_accuracy: 0.8033\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5900 - accuracy: 0.8674 - val_loss: 0.3649 - val_accuracy: 0.8467\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 3ms/step - loss: 1.3442 - accuracy: 0.5929 - val_loss: 0.7077 - val_accuracy: 0.6133\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.6748 - val_loss: 0.5392 - val_accuracy: 0.7383\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9324 - accuracy: 0.7546 - val_loss: 0.6156 - val_accuracy: 0.6817\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9398 - accuracy: 0.7411 - val_loss: 0.4729 - val_accuracy: 0.8067\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8240 - accuracy: 0.7925 - val_loss: 0.5484 - val_accuracy: 0.7767\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.7756 - accuracy: 0.8086 - val_loss: 0.4898 - val_accuracy: 0.7800\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8419 - accuracy: 0.8078 - val_loss: 0.4717 - val_accuracy: 0.8100\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8193 - accuracy: 0.8039 - val_loss: 0.5933 - val_accuracy: 0.6850\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8226 - accuracy: 0.7890 - val_loss: 0.5443 - val_accuracy: 0.7533\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8177 - accuracy: 0.8157 - val_loss: 0.3463 - val_accuracy: 0.8767\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.8432 - accuracy: 0.8273 - val_loss: 0.4168 - val_accuracy: 0.8317\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8121 - accuracy: 0.8292 - val_loss: 0.3812 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7612 - accuracy: 0.8363 - val_loss: 0.4041 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7552 - accuracy: 0.8340 - val_loss: 0.4500 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.7597 - accuracy: 0.8302 - val_loss: 0.5194 - val_accuracy: 0.8017\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7848 - accuracy: 0.8320 - val_loss: 0.3189 - val_accuracy: 0.8817\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8435 - accuracy: 0.8431 - val_loss: 0.3475 - val_accuracy: 0.8617\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.8600 - val_loss: 0.4298 - val_accuracy: 0.8483\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.8500 - val_loss: 0.3073 - val_accuracy: 0.8900\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7861 - accuracy: 0.8529 - val_loss: 0.4305 - val_accuracy: 0.8317\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7207 - accuracy: 0.8575 - val_loss: 0.3560 - val_accuracy: 0.8633\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.6814 - accuracy: 0.8593 - val_loss: 0.3812 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6792 - accuracy: 0.8559 - val_loss: 0.3550 - val_accuracy: 0.8733\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6763 - accuracy: 0.8634 - val_loss: 0.4648 - val_accuracy: 0.8200\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.8731 - val_loss: 0.3406 - val_accuracy: 0.8850\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.7313 - accuracy: 0.8603 - val_loss: 0.3505 - val_accuracy: 0.8683\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7775 - accuracy: 0.8434 - val_loss: 0.3708 - val_accuracy: 0.8833\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6962 - accuracy: 0.8562 - val_loss: 0.2892 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.6282 - accuracy: 0.8694 - val_loss: 0.5062 - val_accuracy: 0.7550\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6423 - accuracy: 0.8515 - val_loss: 0.3963 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6615 - accuracy: 0.8465 - val_loss: 0.3199 - val_accuracy: 0.8950\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6657 - accuracy: 0.8740 - val_loss: 0.4189 - val_accuracy: 0.8383\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.6633 - accuracy: 0.8626 - val_loss: 0.3252 - val_accuracy: 0.8917\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.7073 - accuracy: 0.8771 - val_loss: 0.3040 - val_accuracy: 0.8883\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.7416 - accuracy: 0.8475 - val_loss: 0.2997 - val_accuracy: 0.8900\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6693 - accuracy: 0.8678 - val_loss: 0.3846 - val_accuracy: 0.8700\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6119 - accuracy: 0.8764 - val_loss: 0.3260 - val_accuracy: 0.8850\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5653 - accuracy: 0.8826 - val_loss: 0.3580 - val_accuracy: 0.8617\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.7195 - accuracy: 0.8513 - val_loss: 0.2997 - val_accuracy: 0.8900\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6813 - accuracy: 0.8568 - val_loss: 0.3692 - val_accuracy: 0.8617\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5816 - accuracy: 0.8757 - val_loss: 0.3546 - val_accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6023 - accuracy: 0.8821 - val_loss: 0.3477 - val_accuracy: 0.8767\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.8704 - val_loss: 0.3293 - val_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.8775 - val_loss: 0.3413 - val_accuracy: 0.8700\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.8748 - val_loss: 0.3275 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.8597 - val_loss: 0.3804 - val_accuracy: 0.8583\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6496 - accuracy: 0.8588 - val_loss: 0.2970 - val_accuracy: 0.8950\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5606 - accuracy: 0.8875 - val_loss: 0.2784 - val_accuracy: 0.9033\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6466 - accuracy: 0.8746 - val_loss: 0.3285 - val_accuracy: 0.8633\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.8931 - val_loss: 0.2662 - val_accuracy: 0.8967\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.6512 - accuracy: 0.8736 - val_loss: 0.3290 - val_accuracy: 0.8900\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.8905 - val_loss: 0.2883 - val_accuracy: 0.8967\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5740 - accuracy: 0.8805 - val_loss: 0.3084 - val_accuracy: 0.8850\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5178 - accuracy: 0.8809 - val_loss: 0.3549 - val_accuracy: 0.8500\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5637 - accuracy: 0.8880 - val_loss: 0.2706 - val_accuracy: 0.9067\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5398 - accuracy: 0.8966 - val_loss: 0.2746 - val_accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5025 - accuracy: 0.8938 - val_loss: 0.3367 - val_accuracy: 0.8850\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.5942 - accuracy: 0.8848 - val_loss: 0.2720 - val_accuracy: 0.9050\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.5851 - accuracy: 0.8909 - val_loss: 0.3330 - val_accuracy: 0.8650\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.6195 - accuracy: 0.8548 - val_loss: 0.3497 - val_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6143 - accuracy: 0.8761 - val_loss: 0.2723 - val_accuracy: 0.8983\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5638 - accuracy: 0.8969 - val_loss: 0.2982 - val_accuracy: 0.8967\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.8855 - val_loss: 0.3209 - val_accuracy: 0.8833\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6084 - accuracy: 0.8858 - val_loss: 0.3049 - val_accuracy: 0.8850\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.4898 - accuracy: 0.9029 - val_loss: 0.3504 - val_accuracy: 0.8533\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5148 - accuracy: 0.8866 - val_loss: 0.2594 - val_accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5329 - accuracy: 0.8812 - val_loss: 0.2661 - val_accuracy: 0.8983\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5697 - accuracy: 0.8954 - val_loss: 0.3638 - val_accuracy: 0.8567\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4823 - accuracy: 0.8851 - val_loss: 0.3254 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5848 - accuracy: 0.8733 - val_loss: 0.2683 - val_accuracy: 0.9100\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5153 - accuracy: 0.8980 - val_loss: 0.3310 - val_accuracy: 0.8650\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.5087 - accuracy: 0.8871 - val_loss: 0.2339 - val_accuracy: 0.9250\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7036 - accuracy: 0.8661 - val_loss: 0.2725 - val_accuracy: 0.8950\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.4486 - accuracy: 0.9059 - val_loss: 0.3141 - val_accuracy: 0.8767\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5160 - accuracy: 0.8882 - val_loss: 0.2992 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5202 - accuracy: 0.8981 - val_loss: 0.2458 - val_accuracy: 0.9117\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5396 - accuracy: 0.8989 - val_loss: 0.2742 - val_accuracy: 0.8917\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.8819 - val_loss: 0.3304 - val_accuracy: 0.8833\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5507 - accuracy: 0.8883 - val_loss: 0.3179 - val_accuracy: 0.8517\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5105 - accuracy: 0.8779 - val_loss: 0.3009 - val_accuracy: 0.8933\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.4802 - accuracy: 0.8898 - val_loss: 0.2594 - val_accuracy: 0.9067\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.5017 - accuracy: 0.8966 - val_loss: 0.2661 - val_accuracy: 0.9117\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5616 - accuracy: 0.9002 - val_loss: 0.3190 - val_accuracy: 0.8917\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.9055 - val_loss: 0.3225 - val_accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8987 - val_loss: 0.3028 - val_accuracy: 0.8867\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.4915 - accuracy: 0.9015 - val_loss: 0.3153 - val_accuracy: 0.8667\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.3966 - accuracy: 0.9089 - val_loss: 0.3281 - val_accuracy: 0.8750\n",
      "Epoch 88/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.4531 - accuracy: 0.9057 - val_loss: 0.3176 - val_accuracy: 0.8700\n",
      "Epoch 89/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4843 - accuracy: 0.8991 - val_loss: 0.3354 - val_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4554 - accuracy: 0.8983 - val_loss: 0.2451 - val_accuracy: 0.9117\n",
      "Epoch 91/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5059 - accuracy: 0.8988 - val_loss: 0.2883 - val_accuracy: 0.8950\n",
      "Epoch 92/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5122 - accuracy: 0.9037 - val_loss: 0.2714 - val_accuracy: 0.9133\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3123 - accuracy: 0.5543 - val_loss: 0.6287 - val_accuracy: 0.6833\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.9321 - accuracy: 0.7299 - val_loss: 0.6190 - val_accuracy: 0.6950\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.9456 - accuracy: 0.7300 - val_loss: 0.4327 - val_accuracy: 0.8400\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.9378 - accuracy: 0.7723 - val_loss: 0.4879 - val_accuracy: 0.7883\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8957 - accuracy: 0.7849 - val_loss: 0.4843 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8794 - accuracy: 0.7818 - val_loss: 0.4331 - val_accuracy: 0.8267\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7779 - accuracy: 0.8272 - val_loss: 0.4300 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8697 - accuracy: 0.7889 - val_loss: 0.4713 - val_accuracy: 0.8017\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8328 - accuracy: 0.8113 - val_loss: 0.3808 - val_accuracy: 0.8517\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7723 - accuracy: 0.8167 - val_loss: 0.4941 - val_accuracy: 0.7867\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.7677 - accuracy: 0.8131 - val_loss: 0.4878 - val_accuracy: 0.7867\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.8215 - accuracy: 0.7978 - val_loss: 0.3160 - val_accuracy: 0.8800\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7766 - accuracy: 0.8315 - val_loss: 0.4110 - val_accuracy: 0.8483\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.7869 - accuracy: 0.8257 - val_loss: 0.4454 - val_accuracy: 0.8217\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7875 - accuracy: 0.8089 - val_loss: 0.5261 - val_accuracy: 0.7317\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7429 - accuracy: 0.8292 - val_loss: 0.3315 - val_accuracy: 0.8917\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7764 - accuracy: 0.8317 - val_loss: 0.3903 - val_accuracy: 0.8350\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6998 - accuracy: 0.8393 - val_loss: 0.4687 - val_accuracy: 0.7900\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6722 - accuracy: 0.8477 - val_loss: 0.3648 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7640 - accuracy: 0.8387 - val_loss: 0.4174 - val_accuracy: 0.8467\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.6307 - accuracy: 0.8684 - val_loss: 0.3053 - val_accuracy: 0.8900\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7087 - accuracy: 0.8644 - val_loss: 0.3630 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.8653 - val_loss: 0.4472 - val_accuracy: 0.8167\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6888 - accuracy: 0.8619 - val_loss: 0.3202 - val_accuracy: 0.8883\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6591 - accuracy: 0.8614 - val_loss: 0.4206 - val_accuracy: 0.8050\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6504 - accuracy: 0.8447 - val_loss: 0.3093 - val_accuracy: 0.8717\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6681 - accuracy: 0.8648 - val_loss: 0.3213 - val_accuracy: 0.8767\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6203 - accuracy: 0.8796 - val_loss: 0.3606 - val_accuracy: 0.8500\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6850 - accuracy: 0.8570 - val_loss: 0.3659 - val_accuracy: 0.8600\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6827 - accuracy: 0.8564 - val_loss: 0.4095 - val_accuracy: 0.8283\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6573 - accuracy: 0.8471 - val_loss: 0.3235 - val_accuracy: 0.8683\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6946 - accuracy: 0.8645 - val_loss: 0.2917 - val_accuracy: 0.8900\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6187 - accuracy: 0.8648 - val_loss: 0.3670 - val_accuracy: 0.8617\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7095 - accuracy: 0.8308 - val_loss: 0.3244 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.8862 - val_loss: 0.3560 - val_accuracy: 0.8250\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.8686 - val_loss: 0.4118 - val_accuracy: 0.7983\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6357 - accuracy: 0.8512 - val_loss: 0.4002 - val_accuracy: 0.8167\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.8727 - val_loss: 0.2940 - val_accuracy: 0.8733\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.8696 - val_loss: 0.4067 - val_accuracy: 0.8267\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.8498 - val_loss: 0.3249 - val_accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.8658 - val_loss: 0.2800 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6436 - accuracy: 0.8642 - val_loss: 0.2468 - val_accuracy: 0.9067\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.5896 - accuracy: 0.8706 - val_loss: 0.3214 - val_accuracy: 0.8717\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.8627 - val_loss: 0.2983 - val_accuracy: 0.8833\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.8766 - val_loss: 0.2589 - val_accuracy: 0.9033\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.8987 - val_loss: 0.2945 - val_accuracy: 0.8783\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.8806 - val_loss: 0.2371 - val_accuracy: 0.9150\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6080 - accuracy: 0.8902 - val_loss: 0.2962 - val_accuracy: 0.8933\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5805 - accuracy: 0.8836 - val_loss: 0.3300 - val_accuracy: 0.8633\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.6261 - accuracy: 0.8626 - val_loss: 0.2726 - val_accuracy: 0.8933\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.4923 - accuracy: 0.8909 - val_loss: 0.2380 - val_accuracy: 0.9133\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6113 - accuracy: 0.8858 - val_loss: 0.2500 - val_accuracy: 0.9133\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.4904 - accuracy: 0.9013 - val_loss: 0.3356 - val_accuracy: 0.8483\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5649 - accuracy: 0.8693 - val_loss: 0.2951 - val_accuracy: 0.8817\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.4867 - accuracy: 0.8828 - val_loss: 0.3047 - val_accuracy: 0.8833\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5007 - accuracy: 0.8867 - val_loss: 0.3245 - val_accuracy: 0.8700\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6519 - accuracy: 0.8805 - val_loss: 0.2886 - val_accuracy: 0.9033\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.5326 - accuracy: 0.8832 - val_loss: 0.3627 - val_accuracy: 0.8683\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4630 - accuracy: 0.9009 - val_loss: 0.2934 - val_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5305 - accuracy: 0.8931 - val_loss: 0.4040 - val_accuracy: 0.8317\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.8811 - val_loss: 0.3230 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.9042 - val_loss: 0.2488 - val_accuracy: 0.9133\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.8928 - val_loss: 0.2598 - val_accuracy: 0.9017\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.4143 - accuracy: 0.9154 - val_loss: 0.2491 - val_accuracy: 0.9050\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4912 - accuracy: 0.9005 - val_loss: 0.2679 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.8885 - val_loss: 0.3184 - val_accuracy: 0.8550\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.4311 - accuracy: 0.9103 - val_loss: 0.2423 - val_accuracy: 0.9200\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4960 - accuracy: 0.5167 - val_loss: 0.5247 - val_accuracy: 0.7533\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 1.1184 - accuracy: 0.6818 - val_loss: 0.5147 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9249 - accuracy: 0.7515 - val_loss: 0.4774 - val_accuracy: 0.7650\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.9400 - accuracy: 0.7577 - val_loss: 0.4182 - val_accuracy: 0.8250\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.8357 - accuracy: 0.8081 - val_loss: 0.4420 - val_accuracy: 0.8083\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8674 - accuracy: 0.8025 - val_loss: 0.5141 - val_accuracy: 0.7950\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.8132 - accuracy: 0.8023 - val_loss: 0.4703 - val_accuracy: 0.8217\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.9109 - accuracy: 0.7829 - val_loss: 0.4380 - val_accuracy: 0.8367\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.8187 - accuracy: 0.8038 - val_loss: 0.3704 - val_accuracy: 0.8567\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.8708 - accuracy: 0.8190 - val_loss: 0.5637 - val_accuracy: 0.7483\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8197 - accuracy: 0.8145 - val_loss: 0.4766 - val_accuracy: 0.8250\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7708 - accuracy: 0.8274 - val_loss: 0.4144 - val_accuracy: 0.8533\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7561 - accuracy: 0.8282 - val_loss: 0.3335 - val_accuracy: 0.8767\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7554 - accuracy: 0.8567 - val_loss: 0.4449 - val_accuracy: 0.8183\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6660 - accuracy: 0.8459 - val_loss: 0.4196 - val_accuracy: 0.8300\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.8462 - val_loss: 0.3735 - val_accuracy: 0.8567\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.7795 - accuracy: 0.8505 - val_loss: 0.3914 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.6735 - accuracy: 0.8719 - val_loss: 0.4264 - val_accuracy: 0.8383\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7054 - accuracy: 0.8526 - val_loss: 0.4213 - val_accuracy: 0.8433\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7381 - accuracy: 0.8539 - val_loss: 0.4187 - val_accuracy: 0.8550\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.6829 - accuracy: 0.8502 - val_loss: 0.3761 - val_accuracy: 0.8717\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6761 - accuracy: 0.8516 - val_loss: 0.5033 - val_accuracy: 0.7567\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6931 - accuracy: 0.8415 - val_loss: 0.3618 - val_accuracy: 0.8733\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7326 - accuracy: 0.8523 - val_loss: 0.3953 - val_accuracy: 0.8467\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6732 - accuracy: 0.8607 - val_loss: 0.4347 - val_accuracy: 0.8167\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6422 - accuracy: 0.8556 - val_loss: 0.2774 - val_accuracy: 0.9050\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7663 - accuracy: 0.8490 - val_loss: 0.4370 - val_accuracy: 0.8283\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6097 - accuracy: 0.8714 - val_loss: 0.4197 - val_accuracy: 0.8367\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6850 - accuracy: 0.8580 - val_loss: 0.3369 - val_accuracy: 0.8867\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7042 - accuracy: 0.8691 - val_loss: 0.4034 - val_accuracy: 0.8533\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.5852 - accuracy: 0.8821 - val_loss: 0.3340 - val_accuracy: 0.8867\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.5926 - accuracy: 0.8935 - val_loss: 0.3608 - val_accuracy: 0.8567\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7427 - accuracy: 0.8401 - val_loss: 0.3468 - val_accuracy: 0.8933\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.6921 - accuracy: 0.8588 - val_loss: 0.4002 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6638 - accuracy: 0.8583 - val_loss: 0.3402 - val_accuracy: 0.8867\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.8690 - val_loss: 0.3927 - val_accuracy: 0.8567\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6563 - accuracy: 0.8716 - val_loss: 0.3240 - val_accuracy: 0.8867\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6640 - accuracy: 0.8753 - val_loss: 0.3857 - val_accuracy: 0.8517\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6248 - accuracy: 0.8701 - val_loss: 0.3938 - val_accuracy: 0.8550\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6156 - accuracy: 0.8731 - val_loss: 0.3674 - val_accuracy: 0.8450\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6524 - accuracy: 0.8668 - val_loss: 0.2741 - val_accuracy: 0.8867\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6476 - accuracy: 0.9002 - val_loss: 0.2856 - val_accuracy: 0.8883\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6867 - accuracy: 0.8678 - val_loss: 0.2659 - val_accuracy: 0.8983\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6587 - accuracy: 0.8605 - val_loss: 0.3289 - val_accuracy: 0.8817\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6652 - accuracy: 0.8495 - val_loss: 0.3692 - val_accuracy: 0.8483\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6419 - accuracy: 0.8936 - val_loss: 0.3939 - val_accuracy: 0.8550\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5935 - accuracy: 0.8830 - val_loss: 0.2658 - val_accuracy: 0.9050\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5500 - accuracy: 0.8998 - val_loss: 0.3237 - val_accuracy: 0.8883\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5672 - accuracy: 0.8859 - val_loss: 0.3007 - val_accuracy: 0.8850\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6054 - accuracy: 0.8874 - val_loss: 0.3543 - val_accuracy: 0.8550\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.6265 - accuracy: 0.8716 - val_loss: 0.3377 - val_accuracy: 0.8617\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6707 - accuracy: 0.8764 - val_loss: 0.3498 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7387 - accuracy: 0.8696 - val_loss: 0.3525 - val_accuracy: 0.8583\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4769 - accuracy: 0.9031 - val_loss: 0.3368 - val_accuracy: 0.8483\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6060 - accuracy: 0.8849 - val_loss: 0.3695 - val_accuracy: 0.8300\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6167 - accuracy: 0.8754 - val_loss: 0.4098 - val_accuracy: 0.8133\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5632 - accuracy: 0.8615 - val_loss: 0.3553 - val_accuracy: 0.8583\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.4920 - accuracy: 0.8984 - val_loss: 0.3372 - val_accuracy: 0.8567\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5414 - accuracy: 0.8900 - val_loss: 0.3623 - val_accuracy: 0.8650\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5565 - accuracy: 0.8828 - val_loss: 0.3575 - val_accuracy: 0.8583\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5254 - accuracy: 0.8866 - val_loss: 0.4397 - val_accuracy: 0.8050\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5868 - accuracy: 0.8752 - val_loss: 0.3828 - val_accuracy: 0.8317\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5786 - accuracy: 0.8689 - val_loss: 0.3618 - val_accuracy: 0.8550\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5986 - accuracy: 0.8895 - val_loss: 0.3290 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6293 - accuracy: 0.8668 - val_loss: 0.3029 - val_accuracy: 0.8700\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5825 - accuracy: 0.8918 - val_loss: 0.2848 - val_accuracy: 0.9033\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5657 - accuracy: 0.8852 - val_loss: 0.3118 - val_accuracy: 0.8750\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.3892 - accuracy: 0.5417 - val_loss: 0.5563 - val_accuracy: 0.7183\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 1.0610 - accuracy: 0.6955 - val_loss: 0.5687 - val_accuracy: 0.7433\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.9655 - accuracy: 0.7339 - val_loss: 0.3788 - val_accuracy: 0.8467\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.8728 - accuracy: 0.8067 - val_loss: 0.5016 - val_accuracy: 0.7817\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.9425 - accuracy: 0.7785 - val_loss: 0.4154 - val_accuracy: 0.8483\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.7947 - accuracy: 0.8174 - val_loss: 0.4946 - val_accuracy: 0.7983\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.8643 - accuracy: 0.8085 - val_loss: 0.3504 - val_accuracy: 0.8717\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.8431 - accuracy: 0.8237 - val_loss: 0.3896 - val_accuracy: 0.8550\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8149 - accuracy: 0.8379 - val_loss: 0.5251 - val_accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7836 - accuracy: 0.8277 - val_loss: 0.4759 - val_accuracy: 0.8150\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.7971 - accuracy: 0.8290 - val_loss: 0.3563 - val_accuracy: 0.8800\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7448 - accuracy: 0.8587 - val_loss: 0.5017 - val_accuracy: 0.8183\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8036 - accuracy: 0.8272 - val_loss: 0.4433 - val_accuracy: 0.8467\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7167 - accuracy: 0.8505 - val_loss: 0.4438 - val_accuracy: 0.8383\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7597 - accuracy: 0.8487 - val_loss: 0.3814 - val_accuracy: 0.8783\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7322 - accuracy: 0.8561 - val_loss: 0.3606 - val_accuracy: 0.8617\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.7819 - accuracy: 0.8486 - val_loss: 0.4441 - val_accuracy: 0.8300\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6767 - accuracy: 0.8616 - val_loss: 0.3287 - val_accuracy: 0.8817\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.7224 - accuracy: 0.8639 - val_loss: 0.4018 - val_accuracy: 0.8483\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6747 - accuracy: 0.8725 - val_loss: 0.4207 - val_accuracy: 0.8450\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6514 - accuracy: 0.8698 - val_loss: 0.3518 - val_accuracy: 0.8650\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7699 - accuracy: 0.8523 - val_loss: 0.2962 - val_accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6522 - accuracy: 0.8832 - val_loss: 0.3343 - val_accuracy: 0.8817\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6693 - accuracy: 0.8702 - val_loss: 0.3782 - val_accuracy: 0.8733\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6432 - accuracy: 0.8802 - val_loss: 0.3476 - val_accuracy: 0.8733\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6794 - accuracy: 0.8696 - val_loss: 0.4047 - val_accuracy: 0.8433\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6241 - accuracy: 0.8792 - val_loss: 0.4067 - val_accuracy: 0.8450\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7267 - accuracy: 0.8594 - val_loss: 0.3826 - val_accuracy: 0.8600\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6411 - accuracy: 0.8700 - val_loss: 0.3210 - val_accuracy: 0.8850\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6161 - accuracy: 0.8832 - val_loss: 0.4486 - val_accuracy: 0.8183\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6964 - accuracy: 0.8648 - val_loss: 0.3267 - val_accuracy: 0.9050\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.5964 - accuracy: 0.8921 - val_loss: 0.3443 - val_accuracy: 0.8800\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.6881 - accuracy: 0.8820 - val_loss: 0.3535 - val_accuracy: 0.8617\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6412 - accuracy: 0.8829 - val_loss: 0.3224 - val_accuracy: 0.8933\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5808 - accuracy: 0.8941 - val_loss: 0.5114 - val_accuracy: 0.7583\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6486 - accuracy: 0.8561 - val_loss: 0.3542 - val_accuracy: 0.8683\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5865 - accuracy: 0.8871 - val_loss: 0.3507 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5779 - accuracy: 0.8976 - val_loss: 0.4530 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6189 - accuracy: 0.8777 - val_loss: 0.3579 - val_accuracy: 0.8683\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.5816 - accuracy: 0.8933 - val_loss: 0.3526 - val_accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.6373 - accuracy: 0.8710 - val_loss: 0.3276 - val_accuracy: 0.8833\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6464 - accuracy: 0.8556 - val_loss: 0.4339 - val_accuracy: 0.8617\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3814 - accuracy: 0.5386 - val_loss: 0.5509 - val_accuracy: 0.7400\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.1121 - accuracy: 0.6984 - val_loss: 0.5785 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 1.0226 - accuracy: 0.7202 - val_loss: 0.3958 - val_accuracy: 0.8517\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.8762 - accuracy: 0.7847 - val_loss: 0.4992 - val_accuracy: 0.8067\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.9479 - accuracy: 0.7622 - val_loss: 0.4493 - val_accuracy: 0.8133\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8794 - accuracy: 0.7858 - val_loss: 0.4397 - val_accuracy: 0.8217\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.8971 - accuracy: 0.7851 - val_loss: 0.5108 - val_accuracy: 0.7783\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7938 - accuracy: 0.8033 - val_loss: 0.4274 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.7858 - accuracy: 0.8115 - val_loss: 0.4423 - val_accuracy: 0.8250\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8284 - accuracy: 0.8081 - val_loss: 0.3808 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.8438 - accuracy: 0.8015 - val_loss: 0.3968 - val_accuracy: 0.8450\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8735 - accuracy: 0.8014 - val_loss: 0.4863 - val_accuracy: 0.7983\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.8136 - accuracy: 0.8060 - val_loss: 0.3403 - val_accuracy: 0.8633\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.7198 - accuracy: 0.8403 - val_loss: 0.5280 - val_accuracy: 0.7400\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7376 - accuracy: 0.8256 - val_loss: 0.3713 - val_accuracy: 0.8533\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7314 - accuracy: 0.8410 - val_loss: 0.3584 - val_accuracy: 0.8717\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.7228 - accuracy: 0.8505 - val_loss: 0.3513 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7770 - accuracy: 0.8411 - val_loss: 0.4219 - val_accuracy: 0.8283\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7228 - accuracy: 0.8349 - val_loss: 0.4042 - val_accuracy: 0.8483\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7533 - accuracy: 0.8435 - val_loss: 0.2886 - val_accuracy: 0.8883\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7148 - accuracy: 0.8532 - val_loss: 0.3260 - val_accuracy: 0.8817\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.7541 - accuracy: 0.8471 - val_loss: 0.3292 - val_accuracy: 0.8883\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6518 - accuracy: 0.8506 - val_loss: 0.4377 - val_accuracy: 0.8050\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6980 - accuracy: 0.8335 - val_loss: 0.3925 - val_accuracy: 0.8617\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6497 - accuracy: 0.8585 - val_loss: 0.5287 - val_accuracy: 0.7617\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6319 - accuracy: 0.8523 - val_loss: 0.3990 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.6859 - accuracy: 0.8419 - val_loss: 0.3765 - val_accuracy: 0.8517\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6774 - accuracy: 0.8550 - val_loss: 0.4165 - val_accuracy: 0.8217\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6427 - accuracy: 0.8570 - val_loss: 0.3819 - val_accuracy: 0.8450\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6595 - accuracy: 0.8570 - val_loss: 0.3311 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6747 - accuracy: 0.8596 - val_loss: 0.3508 - val_accuracy: 0.8700\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6616 - accuracy: 0.8719 - val_loss: 0.3502 - val_accuracy: 0.8850\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6359 - accuracy: 0.8631 - val_loss: 0.2725 - val_accuracy: 0.8900\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5757 - accuracy: 0.8809 - val_loss: 0.4564 - val_accuracy: 0.8050\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6243 - accuracy: 0.8517 - val_loss: 0.4211 - val_accuracy: 0.8150\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.7183 - accuracy: 0.8428 - val_loss: 0.3703 - val_accuracy: 0.8433\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6636 - accuracy: 0.8643 - val_loss: 0.4221 - val_accuracy: 0.8350\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6706 - accuracy: 0.8513 - val_loss: 0.3000 - val_accuracy: 0.8900\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6614 - accuracy: 0.8684 - val_loss: 0.3954 - val_accuracy: 0.8233\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6564 - accuracy: 0.8556 - val_loss: 0.4067 - val_accuracy: 0.8133\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6238 - accuracy: 0.8721 - val_loss: 0.3004 - val_accuracy: 0.8867\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6012 - accuracy: 0.8792 - val_loss: 0.3071 - val_accuracy: 0.8817\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6733 - accuracy: 0.8519 - val_loss: 0.2985 - val_accuracy: 0.8817\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6541 - accuracy: 0.8585 - val_loss: 0.4728 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5533 - accuracy: 0.8721 - val_loss: 0.3429 - val_accuracy: 0.8717\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5252 - accuracy: 0.8875 - val_loss: 0.3962 - val_accuracy: 0.8450\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 996us/step - loss: 0.6311 - accuracy: 0.8537 - val_loss: 0.3730 - val_accuracy: 0.8467\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5422 - accuracy: 0.8780 - val_loss: 0.3621 - val_accuracy: 0.8350\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6090 - accuracy: 0.8698 - val_loss: 0.2797 - val_accuracy: 0.8967\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6092 - accuracy: 0.8673 - val_loss: 0.4041 - val_accuracy: 0.8367\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5845 - accuracy: 0.8593 - val_loss: 0.3829 - val_accuracy: 0.8317\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5981 - accuracy: 0.8789 - val_loss: 0.3205 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5853 - accuracy: 0.8726 - val_loss: 0.3044 - val_accuracy: 0.8817\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.2627 - accuracy: 0.5860 - val_loss: 0.5491 - val_accuracy: 0.7350\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.9849 - accuracy: 0.7385 - val_loss: 0.5444 - val_accuracy: 0.7533\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.9503 - accuracy: 0.7658 - val_loss: 0.5994 - val_accuracy: 0.7033\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.76 - 0s 842us/step - loss: 0.9187 - accuracy: 0.7645 - val_loss: 0.4912 - val_accuracy: 0.7900\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.8288 - accuracy: 0.7916 - val_loss: 0.4574 - val_accuracy: 0.8083\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.8644 - accuracy: 0.7834 - val_loss: 0.4554 - val_accuracy: 0.8150\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8608 - accuracy: 0.8040 - val_loss: 0.5280 - val_accuracy: 0.7633\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8450 - accuracy: 0.8041 - val_loss: 0.4449 - val_accuracy: 0.8167\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8614 - accuracy: 0.8101 - val_loss: 0.4327 - val_accuracy: 0.8267\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8188 - accuracy: 0.8257 - val_loss: 0.3621 - val_accuracy: 0.8600\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7800 - accuracy: 0.8296 - val_loss: 0.4257 - val_accuracy: 0.8317\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7610 - accuracy: 0.8261 - val_loss: 0.4556 - val_accuracy: 0.8350\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7416 - accuracy: 0.8471 - val_loss: 0.4153 - val_accuracy: 0.8583\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.7614 - accuracy: 0.8371 - val_loss: 0.4461 - val_accuracy: 0.8217\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7672 - accuracy: 0.8367 - val_loss: 0.3618 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7448 - accuracy: 0.8487 - val_loss: 0.3854 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7175 - accuracy: 0.8572 - val_loss: 0.3739 - val_accuracy: 0.8683\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7080 - accuracy: 0.8624 - val_loss: 0.3884 - val_accuracy: 0.8583\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6663 - accuracy: 0.8662 - val_loss: 0.4533 - val_accuracy: 0.8317\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6832 - accuracy: 0.8625 - val_loss: 0.3461 - val_accuracy: 0.8900\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6960 - accuracy: 0.8607 - val_loss: 0.4553 - val_accuracy: 0.8217\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7202 - accuracy: 0.8599 - val_loss: 0.3421 - val_accuracy: 0.8733\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6222 - accuracy: 0.8731 - val_loss: 0.3948 - val_accuracy: 0.8683\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6742 - accuracy: 0.8652 - val_loss: 0.4052 - val_accuracy: 0.8583\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6686 - accuracy: 0.8784 - val_loss: 0.4291 - val_accuracy: 0.8533\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7059 - accuracy: 0.8542 - val_loss: 0.3797 - val_accuracy: 0.8633\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7119 - accuracy: 0.8658 - val_loss: 0.4301 - val_accuracy: 0.8183\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7718 - accuracy: 0.8443 - val_loss: 0.3404 - val_accuracy: 0.8833\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6957 - accuracy: 0.8695 - val_loss: 0.3152 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7177 - accuracy: 0.8687 - val_loss: 0.2862 - val_accuracy: 0.8983\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7060 - accuracy: 0.8691 - val_loss: 0.4270 - val_accuracy: 0.8317\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.5656 - accuracy: 0.8728 - val_loss: 0.4241 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6788 - accuracy: 0.8387 - val_loss: 0.3900 - val_accuracy: 0.8450\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6342 - accuracy: 0.8758 - val_loss: 0.3967 - val_accuracy: 0.8283\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6429 - accuracy: 0.8697 - val_loss: 0.3132 - val_accuracy: 0.8883\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6498 - accuracy: 0.8785 - val_loss: 0.3602 - val_accuracy: 0.8433\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6117 - accuracy: 0.8904 - val_loss: 0.3819 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.5814 - accuracy: 0.8875 - val_loss: 0.5047 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5984 - accuracy: 0.8676 - val_loss: 0.4973 - val_accuracy: 0.8017\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6550 - accuracy: 0.8601 - val_loss: 0.3708 - val_accuracy: 0.8617\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6393 - accuracy: 0.8752 - val_loss: 0.2742 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5906 - accuracy: 0.8889 - val_loss: 0.2726 - val_accuracy: 0.9033\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5373 - accuracy: 0.8871 - val_loss: 0.3167 - val_accuracy: 0.8833\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6187 - accuracy: 0.8777 - val_loss: 0.2872 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5923 - accuracy: 0.8828 - val_loss: 0.3937 - val_accuracy: 0.8250\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5964 - accuracy: 0.8850 - val_loss: 0.3771 - val_accuracy: 0.8600\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5534 - accuracy: 0.8922 - val_loss: 0.3352 - val_accuracy: 0.8683\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5703 - accuracy: 0.8777 - val_loss: 0.3475 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5606 - accuracy: 0.8781 - val_loss: 0.3148 - val_accuracy: 0.8817\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5594 - accuracy: 0.8829 - val_loss: 0.3376 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.5282 - accuracy: 0.8885 - val_loss: 0.3219 - val_accuracy: 0.8833\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.5796 - accuracy: 0.8791 - val_loss: 0.4798 - val_accuracy: 0.8117\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6024 - accuracy: 0.8761 - val_loss: 0.4074 - val_accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5942 - accuracy: 0.8707 - val_loss: 0.2418 - val_accuracy: 0.9167\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4988 - accuracy: 0.8907 - val_loss: 0.3951 - val_accuracy: 0.8283\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.4812 - accuracy: 0.8867 - val_loss: 0.3313 - val_accuracy: 0.8700\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6222 - accuracy: 0.8635 - val_loss: 0.3665 - val_accuracy: 0.8433\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5862 - accuracy: 0.8711 - val_loss: 0.4278 - val_accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5466 - accuracy: 0.8734 - val_loss: 0.3204 - val_accuracy: 0.8817\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5066 - accuracy: 0.8882 - val_loss: 0.2896 - val_accuracy: 0.8917\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5090 - accuracy: 0.9010 - val_loss: 0.3041 - val_accuracy: 0.8833\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6379 - accuracy: 0.8790 - val_loss: 0.3210 - val_accuracy: 0.8683\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.4830 - accuracy: 0.9048 - val_loss: 0.3415 - val_accuracy: 0.8567\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5153 - accuracy: 0.8939 - val_loss: 0.3097 - val_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5181 - accuracy: 0.8938 - val_loss: 0.2537 - val_accuracy: 0.9150\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.4303 - accuracy: 0.9196 - val_loss: 0.3212 - val_accuracy: 0.8800\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5276 - accuracy: 0.8907 - val_loss: 0.2193 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.4776 - accuracy: 0.8935 - val_loss: 0.3040 - val_accuracy: 0.8883\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5115 - accuracy: 0.8863 - val_loss: 0.2737 - val_accuracy: 0.9050\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.4839 - accuracy: 0.9141 - val_loss: 0.3893 - val_accuracy: 0.8417\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5239 - accuracy: 0.8886 - val_loss: 0.3145 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.4774 - accuracy: 0.9126 - val_loss: 0.3603 - val_accuracy: 0.8417\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.4803 - accuracy: 0.8904 - val_loss: 0.3129 - val_accuracy: 0.8783\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6173 - accuracy: 0.8712 - val_loss: 0.2374 - val_accuracy: 0.9133\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5149 - accuracy: 0.8897 - val_loss: 0.4225 - val_accuracy: 0.8300\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.4674 - accuracy: 0.8772 - val_loss: 0.3444 - val_accuracy: 0.8583\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5408 - accuracy: 0.8869 - val_loss: 0.3740 - val_accuracy: 0.8633\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4741 - accuracy: 0.9024 - val_loss: 0.3166 - val_accuracy: 0.8867\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.4752 - accuracy: 0.8884 - val_loss: 0.3417 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.4779 - accuracy: 0.8992 - val_loss: 0.2950 - val_accuracy: 0.8867\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4858 - accuracy: 0.8927 - val_loss: 0.3437 - val_accuracy: 0.8650\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.4932 - accuracy: 0.9069 - val_loss: 0.3012 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.4833 - accuracy: 0.9038 - val_loss: 0.3633 - val_accuracy: 0.8517\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5364 - accuracy: 0.8811 - val_loss: 0.3089 - val_accuracy: 0.8767\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.4896 - accuracy: 0.8916 - val_loss: 0.2533 - val_accuracy: 0.9117\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5226 - accuracy: 0.9012 - val_loss: 0.3877 - val_accuracy: 0.8617\n",
      "Epoch 87/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5105 - accuracy: 0.9051 - val_loss: 0.3308 - val_accuracy: 0.8833\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4227 - accuracy: 0.5444 - val_loss: 0.5663 - val_accuracy: 0.7017\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 1.0402 - accuracy: 0.7036 - val_loss: 0.5361 - val_accuracy: 0.7533\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.9738 - accuracy: 0.7406 - val_loss: 0.4388 - val_accuracy: 0.8233\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.9110 - accuracy: 0.7869 - val_loss: 0.6713 - val_accuracy: 0.6317\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8996 - accuracy: 0.7554 - val_loss: 0.4250 - val_accuracy: 0.8267\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7709 - accuracy: 0.8137 - val_loss: 0.4910 - val_accuracy: 0.7950\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8498 - accuracy: 0.8113 - val_loss: 0.5137 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8712 - accuracy: 0.8015 - val_loss: 0.4261 - val_accuracy: 0.8250\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8001 - accuracy: 0.8101 - val_loss: 0.3507 - val_accuracy: 0.8633\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.7293 - accuracy: 0.8317 - val_loss: 0.4943 - val_accuracy: 0.7967\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7689 - accuracy: 0.8072 - val_loss: 0.5468 - val_accuracy: 0.7250\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7940 - accuracy: 0.8190 - val_loss: 0.4738 - val_accuracy: 0.8017\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.8560 - accuracy: 0.7994 - val_loss: 0.3561 - val_accuracy: 0.8683\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6892 - accuracy: 0.8535 - val_loss: 0.4090 - val_accuracy: 0.8617\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 996us/step - loss: 0.7003 - accuracy: 0.8465 - val_loss: 0.4334 - val_accuracy: 0.8450\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.8249 - accuracy: 0.8187 - val_loss: 0.4506 - val_accuracy: 0.8233\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7447 - accuracy: 0.8202 - val_loss: 0.5079 - val_accuracy: 0.7733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7680 - accuracy: 0.8258 - val_loss: 0.4151 - val_accuracy: 0.8383\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7101 - accuracy: 0.8496 - val_loss: 0.4010 - val_accuracy: 0.8433\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7236 - accuracy: 0.8489 - val_loss: 0.3620 - val_accuracy: 0.8467\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7181 - accuracy: 0.8407 - val_loss: 0.3385 - val_accuracy: 0.8767\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7319 - accuracy: 0.8486 - val_loss: 0.2968 - val_accuracy: 0.8850\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6562 - accuracy: 0.8510 - val_loss: 0.3467 - val_accuracy: 0.8500\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6057 - accuracy: 0.8723 - val_loss: 0.3459 - val_accuracy: 0.8717\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6420 - accuracy: 0.8627 - val_loss: 0.3409 - val_accuracy: 0.8733\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6704 - accuracy: 0.8667 - val_loss: 0.3621 - val_accuracy: 0.8717\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6595 - accuracy: 0.8705 - val_loss: 0.3270 - val_accuracy: 0.8850\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.6272 - accuracy: 0.8782 - val_loss: 0.4321 - val_accuracy: 0.7833\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6110 - accuracy: 0.8829 - val_loss: 0.3783 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6657 - accuracy: 0.8613 - val_loss: 0.2902 - val_accuracy: 0.9050\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5470 - accuracy: 0.8872 - val_loss: 0.3744 - val_accuracy: 0.8467\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6936 - accuracy: 0.8530 - val_loss: 0.4231 - val_accuracy: 0.8267\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6324 - accuracy: 0.8678 - val_loss: 0.4896 - val_accuracy: 0.7767\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5943 - accuracy: 0.8664 - val_loss: 0.3436 - val_accuracy: 0.8783\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6954 - accuracy: 0.8613 - val_loss: 0.2435 - val_accuracy: 0.9217\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5831 - accuracy: 0.8835 - val_loss: 0.3711 - val_accuracy: 0.8367\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6393 - accuracy: 0.8573 - val_loss: 0.4228 - val_accuracy: 0.8383\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6489 - accuracy: 0.8663 - val_loss: 0.3644 - val_accuracy: 0.8683\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6059 - accuracy: 0.8787 - val_loss: 0.3419 - val_accuracy: 0.8683\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6425 - accuracy: 0.8714 - val_loss: 0.4035 - val_accuracy: 0.8133\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6370 - accuracy: 0.8610 - val_loss: 0.3506 - val_accuracy: 0.8617\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6366 - accuracy: 0.8666 - val_loss: 0.4492 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6115 - accuracy: 0.8681 - val_loss: 0.2956 - val_accuracy: 0.8817\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5699 - accuracy: 0.8829 - val_loss: 0.2851 - val_accuracy: 0.8883\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5345 - accuracy: 0.8904 - val_loss: 0.2674 - val_accuracy: 0.8983\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5956 - accuracy: 0.8738 - val_loss: 0.2647 - val_accuracy: 0.9083\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6405 - accuracy: 0.8905 - val_loss: 0.4112 - val_accuracy: 0.8417\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5881 - accuracy: 0.8738 - val_loss: 0.3453 - val_accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.5821 - accuracy: 0.8778 - val_loss: 0.3952 - val_accuracy: 0.8117\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5791 - accuracy: 0.8703 - val_loss: 0.2632 - val_accuracy: 0.9017\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6118 - accuracy: 0.8776 - val_loss: 0.3761 - val_accuracy: 0.8283\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6403 - accuracy: 0.8553 - val_loss: 0.3066 - val_accuracy: 0.8850\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5197 - accuracy: 0.8998 - val_loss: 0.3223 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5364 - accuracy: 0.8798 - val_loss: 0.2668 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5174 - accuracy: 0.9023 - val_loss: 0.3158 - val_accuracy: 0.8667\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3461 - accuracy: 0.5796 - val_loss: 0.6631 - val_accuracy: 0.6317\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 1.0330 - accuracy: 0.6979 - val_loss: 0.4517 - val_accuracy: 0.7983\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.9675 - accuracy: 0.7759 - val_loss: 0.5549 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.9496 - accuracy: 0.7545 - val_loss: 0.5255 - val_accuracy: 0.7567\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8932 - accuracy: 0.7522 - val_loss: 0.4534 - val_accuracy: 0.8167\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8744 - accuracy: 0.7899 - val_loss: 0.4317 - val_accuracy: 0.8350\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.8306 - accuracy: 0.8060 - val_loss: 0.3665 - val_accuracy: 0.8533\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7543 - accuracy: 0.8354 - val_loss: 0.3796 - val_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7672 - accuracy: 0.8389 - val_loss: 0.4129 - val_accuracy: 0.8250\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.7750 - accuracy: 0.8258 - val_loss: 0.4662 - val_accuracy: 0.8100\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7876 - accuracy: 0.8280 - val_loss: 0.4877 - val_accuracy: 0.8017\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7917 - accuracy: 0.8232 - val_loss: 0.5064 - val_accuracy: 0.7567\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7930 - accuracy: 0.8244 - val_loss: 0.5484 - val_accuracy: 0.7300\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8064 - accuracy: 0.7977 - val_loss: 0.4424 - val_accuracy: 0.8283\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7186 - accuracy: 0.8485 - val_loss: 0.4163 - val_accuracy: 0.8433\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6784 - accuracy: 0.8570 - val_loss: 0.4660 - val_accuracy: 0.8083\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8174 - accuracy: 0.8175 - val_loss: 0.3290 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7392 - accuracy: 0.8637 - val_loss: 0.4692 - val_accuracy: 0.8133\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6779 - accuracy: 0.8530 - val_loss: 0.3558 - val_accuracy: 0.8683\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7463 - accuracy: 0.8469 - val_loss: 0.3580 - val_accuracy: 0.8783\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6202 - accuracy: 0.8796 - val_loss: 0.3996 - val_accuracy: 0.8267\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6546 - accuracy: 0.8587 - val_loss: 0.3814 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6585 - accuracy: 0.8607 - val_loss: 0.4181 - val_accuracy: 0.8250\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5919 - accuracy: 0.8822 - val_loss: 0.3795 - val_accuracy: 0.8633\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7458 - accuracy: 0.8461 - val_loss: 0.3848 - val_accuracy: 0.8317\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6437 - accuracy: 0.8476 - val_loss: 0.4035 - val_accuracy: 0.8500\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6463 - accuracy: 0.8707 - val_loss: 0.3670 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7153 - accuracy: 0.8473 - val_loss: 0.2871 - val_accuracy: 0.8983\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6873 - accuracy: 0.8741 - val_loss: 0.4136 - val_accuracy: 0.8383\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6167 - accuracy: 0.8696 - val_loss: 0.3665 - val_accuracy: 0.8583\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.6577 - accuracy: 0.8685 - val_loss: 0.3720 - val_accuracy: 0.8583\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7243 - accuracy: 0.8466 - val_loss: 0.3532 - val_accuracy: 0.8617\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6094 - accuracy: 0.8831 - val_loss: 0.3757 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6192 - accuracy: 0.8687 - val_loss: 0.3237 - val_accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5569 - accuracy: 0.8965 - val_loss: 0.3494 - val_accuracy: 0.8733\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6096 - accuracy: 0.8708 - val_loss: 0.4406 - val_accuracy: 0.8400\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6488 - accuracy: 0.8560 - val_loss: 0.3387 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.5671 - accuracy: 0.8889 - val_loss: 0.3430 - val_accuracy: 0.8733\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6028 - accuracy: 0.8782 - val_loss: 0.3481 - val_accuracy: 0.8650\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.6631 - accuracy: 0.8608 - val_loss: 0.2957 - val_accuracy: 0.8933\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6310 - accuracy: 0.8757 - val_loss: 0.2959 - val_accuracy: 0.8817\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6119 - accuracy: 0.8891 - val_loss: 0.4059 - val_accuracy: 0.8467\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5286 - accuracy: 0.8865 - val_loss: 0.4238 - val_accuracy: 0.8150\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6617 - accuracy: 0.8652 - val_loss: 0.3794 - val_accuracy: 0.8467\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5631 - accuracy: 0.8928 - val_loss: 0.2835 - val_accuracy: 0.9033\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5065 - accuracy: 0.9120 - val_loss: 0.3693 - val_accuracy: 0.8633\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5965 - accuracy: 0.8831 - val_loss: 0.2944 - val_accuracy: 0.9017\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6070 - accuracy: 0.8941 - val_loss: 0.2820 - val_accuracy: 0.8917\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6030 - accuracy: 0.8963 - val_loss: 0.3124 - val_accuracy: 0.8867\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5203 - accuracy: 0.8963 - val_loss: 0.3381 - val_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5487 - accuracy: 0.8963 - val_loss: 0.2882 - val_accuracy: 0.9033\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5456 - accuracy: 0.9109 - val_loss: 0.4332 - val_accuracy: 0.8083\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5477 - accuracy: 0.8885 - val_loss: 0.4296 - val_accuracy: 0.8283\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6130 - accuracy: 0.8751 - val_loss: 0.2924 - val_accuracy: 0.8850\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6176 - accuracy: 0.8870 - val_loss: 0.4087 - val_accuracy: 0.8633\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5159 - accuracy: 0.8872 - val_loss: 0.3466 - val_accuracy: 0.8733\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5493 - accuracy: 0.8782 - val_loss: 0.3871 - val_accuracy: 0.8383\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 817us/step - loss: 0.5135 - accuracy: 0.8911 - val_loss: 0.4396 - val_accuracy: 0.8067\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5628 - accuracy: 0.8750 - val_loss: 0.3808 - val_accuracy: 0.8467\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5877 - accuracy: 0.8834 - val_loss: 0.2842 - val_accuracy: 0.8983\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5263 - accuracy: 0.9107 - val_loss: 0.3203 - val_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5365 - accuracy: 0.8925 - val_loss: 0.3073 - val_accuracy: 0.8900\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5391 - accuracy: 0.8924 - val_loss: 0.3737 - val_accuracy: 0.8400\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5392 - accuracy: 0.8888 - val_loss: 0.3018 - val_accuracy: 0.8950\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5132 - accuracy: 0.8850 - val_loss: 0.2957 - val_accuracy: 0.8833\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.4581 - accuracy: 0.9233 - val_loss: 0.2990 - val_accuracy: 0.8900\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5446 - accuracy: 0.8861 - val_loss: 0.3657 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5451 - accuracy: 0.8877 - val_loss: 0.3053 - val_accuracy: 0.8900\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4205 - accuracy: 0.5760 - val_loss: 0.6678 - val_accuracy: 0.6800\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 1.0608 - accuracy: 0.6884 - val_loss: 0.4304 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.9871 - accuracy: 0.7491 - val_loss: 0.5702 - val_accuracy: 0.7367\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.9489 - accuracy: 0.7518 - val_loss: 0.4360 - val_accuracy: 0.7983\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8275 - accuracy: 0.8107 - val_loss: 0.4547 - val_accuracy: 0.8083\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.9208 - accuracy: 0.7846 - val_loss: 0.4110 - val_accuracy: 0.8383\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.8790 - accuracy: 0.8010 - val_loss: 0.4259 - val_accuracy: 0.8217\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8247 - accuracy: 0.8212 - val_loss: 0.3914 - val_accuracy: 0.8433\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8732 - accuracy: 0.8184 - val_loss: 0.4544 - val_accuracy: 0.8233\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7508 - accuracy: 0.8509 - val_loss: 0.3466 - val_accuracy: 0.8683\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7798 - accuracy: 0.8367 - val_loss: 0.3030 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8046 - accuracy: 0.8431 - val_loss: 0.3297 - val_accuracy: 0.8850\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6733 - accuracy: 0.8614 - val_loss: 0.4266 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7216 - accuracy: 0.8613 - val_loss: 0.5073 - val_accuracy: 0.7583\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7364 - accuracy: 0.8394 - val_loss: 0.4415 - val_accuracy: 0.8317\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7371 - accuracy: 0.8584 - val_loss: 0.3679 - val_accuracy: 0.8533\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7697 - accuracy: 0.8542 - val_loss: 0.3707 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7302 - accuracy: 0.8486 - val_loss: 0.3426 - val_accuracy: 0.8833\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8199 - accuracy: 0.8383 - val_loss: 0.3245 - val_accuracy: 0.8867\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7040 - accuracy: 0.8650 - val_loss: 0.2911 - val_accuracy: 0.9100\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6976 - accuracy: 0.8646 - val_loss: 0.4117 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7241 - accuracy: 0.8555 - val_loss: 0.2920 - val_accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.6646 - accuracy: 0.8886 - val_loss: 0.4074 - val_accuracy: 0.8383\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6879 - accuracy: 0.8647 - val_loss: 0.3350 - val_accuracy: 0.8900\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5977 - accuracy: 0.8821 - val_loss: 0.4152 - val_accuracy: 0.8433\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.6758 - accuracy: 0.8687 - val_loss: 0.3904 - val_accuracy: 0.8700\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6436 - accuracy: 0.8806 - val_loss: 0.3803 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6024 - accuracy: 0.8905 - val_loss: 0.4158 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6375 - accuracy: 0.8745 - val_loss: 0.3507 - val_accuracy: 0.8700\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6791 - accuracy: 0.8815 - val_loss: 0.3997 - val_accuracy: 0.8583\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.5972 - accuracy: 0.8870 - val_loss: 0.2780 - val_accuracy: 0.9183\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5451 - accuracy: 0.8949 - val_loss: 0.3770 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6613 - accuracy: 0.8685 - val_loss: 0.3427 - val_accuracy: 0.8950\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.7303 - accuracy: 0.8648 - val_loss: 0.3244 - val_accuracy: 0.8917\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5842 - accuracy: 0.8879 - val_loss: 0.3687 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5443 - accuracy: 0.8966 - val_loss: 0.3734 - val_accuracy: 0.8567\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6125 - accuracy: 0.8740 - val_loss: 0.3036 - val_accuracy: 0.9050\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5805 - accuracy: 0.8917 - val_loss: 0.3088 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6028 - accuracy: 0.8856 - val_loss: 0.3999 - val_accuracy: 0.8583\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6323 - accuracy: 0.8635 - val_loss: 0.3418 - val_accuracy: 0.8883\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.5760 - accuracy: 0.8844 - val_loss: 0.3740 - val_accuracy: 0.8683\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6217 - accuracy: 0.8701 - val_loss: 0.3794 - val_accuracy: 0.8567\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6057 - accuracy: 0.8735 - val_loss: 0.3361 - val_accuracy: 0.8800\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5814 - accuracy: 0.8759 - val_loss: 0.3215 - val_accuracy: 0.8917\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5731 - accuracy: 0.8935 - val_loss: 0.2933 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 992us/step - loss: 0.5841 - accuracy: 0.8964 - val_loss: 0.4425 - val_accuracy: 0.8183\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5802 - accuracy: 0.8756 - val_loss: 0.3756 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.5149 - accuracy: 0.9034 - val_loss: 0.3539 - val_accuracy: 0.8733\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.5755 - accuracy: 0.8886 - val_loss: 0.4136 - val_accuracy: 0.8550\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.6118 - accuracy: 0.8723 - val_loss: 0.3670 - val_accuracy: 0.8717\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5076 - accuracy: 0.8876 - val_loss: 0.3459 - val_accuracy: 0.8767\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3168 - accuracy: 0.5861 - val_loss: 0.5922 - val_accuracy: 0.7050\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 1.0318 - accuracy: 0.7032 - val_loss: 0.5507 - val_accuracy: 0.7233\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.9932 - accuracy: 0.7241 - val_loss: 0.3670 - val_accuracy: 0.8517\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9309 - accuracy: 0.7739 - val_loss: 0.3869 - val_accuracy: 0.8383\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9447 - accuracy: 0.7918 - val_loss: 0.5021 - val_accuracy: 0.7817\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8773 - accuracy: 0.7766 - val_loss: 0.5042 - val_accuracy: 0.7867\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.9372 - accuracy: 0.7589 - val_loss: 0.3656 - val_accuracy: 0.8550\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7895 - accuracy: 0.8122 - val_loss: 0.4240 - val_accuracy: 0.8433\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.8694 - accuracy: 0.7988 - val_loss: 0.3569 - val_accuracy: 0.8567\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8024 - accuracy: 0.8042 - val_loss: 0.3812 - val_accuracy: 0.8433\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8254 - accuracy: 0.8125 - val_loss: 0.3926 - val_accuracy: 0.8550\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.7060 - accuracy: 0.8354 - val_loss: 0.3986 - val_accuracy: 0.8467\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8262 - accuracy: 0.8234 - val_loss: 0.4428 - val_accuracy: 0.8150\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7583 - accuracy: 0.8254 - val_loss: 0.3929 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.7339 - accuracy: 0.8445 - val_loss: 0.3607 - val_accuracy: 0.8733\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7053 - accuracy: 0.8582 - val_loss: 0.4027 - val_accuracy: 0.8517\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7493 - accuracy: 0.8389 - val_loss: 0.4731 - val_accuracy: 0.7967\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7309 - accuracy: 0.8283 - val_loss: 0.3713 - val_accuracy: 0.8583\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.7026 - accuracy: 0.8377 - val_loss: 0.3886 - val_accuracy: 0.8467\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7503 - accuracy: 0.8527 - val_loss: 0.2860 - val_accuracy: 0.8833\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6946 - accuracy: 0.8529 - val_loss: 0.3327 - val_accuracy: 0.8783\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6544 - accuracy: 0.8629 - val_loss: 0.3738 - val_accuracy: 0.8717\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6917 - accuracy: 0.8733 - val_loss: 0.5670 - val_accuracy: 0.6817\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7887 - accuracy: 0.8031 - val_loss: 0.3410 - val_accuracy: 0.8683\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6036 - accuracy: 0.8753 - val_loss: 0.3309 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6790 - accuracy: 0.8743 - val_loss: 0.3749 - val_accuracy: 0.8483\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6043 - accuracy: 0.8764 - val_loss: 0.4777 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7044 - accuracy: 0.8280 - val_loss: 0.3109 - val_accuracy: 0.8867\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6153 - accuracy: 0.8720 - val_loss: 0.5506 - val_accuracy: 0.7217\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6839 - accuracy: 0.8405 - val_loss: 0.3785 - val_accuracy: 0.8583\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.5706 - accuracy: 0.8877 - val_loss: 0.3491 - val_accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6434 - accuracy: 0.8532 - val_loss: 0.3205 - val_accuracy: 0.8950\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7036 - accuracy: 0.8595 - val_loss: 0.2942 - val_accuracy: 0.9100\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6774 - accuracy: 0.8607 - val_loss: 0.3534 - val_accuracy: 0.8650\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5949 - accuracy: 0.8793 - val_loss: 0.3708 - val_accuracy: 0.8483\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6586 - accuracy: 0.8706 - val_loss: 0.3286 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6014 - accuracy: 0.8756 - val_loss: 0.4291 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6036 - accuracy: 0.8527 - val_loss: 0.3008 - val_accuracy: 0.8950\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6474 - accuracy: 0.8557 - val_loss: 0.3419 - val_accuracy: 0.8733\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5785 - accuracy: 0.8840 - val_loss: 0.3198 - val_accuracy: 0.8717\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3776 - accuracy: 0.5736 - val_loss: 0.6389 - val_accuracy: 0.6267\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 1.0250 - accuracy: 0.6848 - val_loss: 0.4709 - val_accuracy: 0.8050\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.9291 - accuracy: 0.7510 - val_loss: 0.5744 - val_accuracy: 0.7050\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.9642 - accuracy: 0.7477 - val_loss: 0.5284 - val_accuracy: 0.7617\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.8558 - accuracy: 0.7765 - val_loss: 0.4643 - val_accuracy: 0.8100\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.9104 - accuracy: 0.7798 - val_loss: 0.5207 - val_accuracy: 0.7850\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.9116 - accuracy: 0.7721 - val_loss: 0.5143 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8629 - accuracy: 0.7796 - val_loss: 0.4329 - val_accuracy: 0.8383\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.8190 - accuracy: 0.8141 - val_loss: 0.4421 - val_accuracy: 0.8117\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.8578 - accuracy: 0.7976 - val_loss: 0.4273 - val_accuracy: 0.8450\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 987us/step - loss: 0.8542 - accuracy: 0.8087 - val_loss: 0.3977 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.8811 - accuracy: 0.8060 - val_loss: 0.4154 - val_accuracy: 0.8600\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7731 - accuracy: 0.8348 - val_loss: 0.4561 - val_accuracy: 0.8383\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.7567 - accuracy: 0.8378 - val_loss: 0.5436 - val_accuracy: 0.7550\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7440 - accuracy: 0.8278 - val_loss: 0.5373 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7568 - accuracy: 0.8177 - val_loss: 0.4248 - val_accuracy: 0.8533\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.7783 - accuracy: 0.8301 - val_loss: 0.3933 - val_accuracy: 0.8567\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8189 - accuracy: 0.8293 - val_loss: 0.2662 - val_accuracy: 0.9050\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.7224 - accuracy: 0.8688 - val_loss: 0.3539 - val_accuracy: 0.8767\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7658 - accuracy: 0.8458 - val_loss: 0.3889 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7511 - accuracy: 0.8408 - val_loss: 0.3055 - val_accuracy: 0.9050\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7739 - accuracy: 0.8521 - val_loss: 0.3430 - val_accuracy: 0.8800\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6471 - accuracy: 0.8751 - val_loss: 0.3168 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6542 - accuracy: 0.8675 - val_loss: 0.3841 - val_accuracy: 0.8717\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6807 - accuracy: 0.8602 - val_loss: 0.2896 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7296 - accuracy: 0.8691 - val_loss: 0.3951 - val_accuracy: 0.8533\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6744 - accuracy: 0.8610 - val_loss: 0.4892 - val_accuracy: 0.8133\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6679 - accuracy: 0.8710 - val_loss: 0.3158 - val_accuracy: 0.8917\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8270 - accuracy: 0.8699 - val_loss: 0.3325 - val_accuracy: 0.8900\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6307 - accuracy: 0.8794 - val_loss: 0.3549 - val_accuracy: 0.8850\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6742 - accuracy: 0.8827 - val_loss: 0.4703 - val_accuracy: 0.8400\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6781 - accuracy: 0.8638 - val_loss: 0.2833 - val_accuracy: 0.9100\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5991 - accuracy: 0.8865 - val_loss: 0.4190 - val_accuracy: 0.8517\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6348 - accuracy: 0.8758 - val_loss: 0.4003 - val_accuracy: 0.8683\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6193 - accuracy: 0.8852 - val_loss: 0.4423 - val_accuracy: 0.8233\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6806 - accuracy: 0.8614 - val_loss: 0.3348 - val_accuracy: 0.8850\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5679 - accuracy: 0.8959 - val_loss: 0.3819 - val_accuracy: 0.8733\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6573 - accuracy: 0.8832 - val_loss: 0.3495 - val_accuracy: 0.8700\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4364 - accuracy: 0.5772 - val_loss: 0.6788 - val_accuracy: 0.6133\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 1.0183 - accuracy: 0.6982 - val_loss: 0.4995 - val_accuracy: 0.7633\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.9558 - accuracy: 0.7487 - val_loss: 0.5699 - val_accuracy: 0.7467\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.9395 - accuracy: 0.7643 - val_loss: 0.5285 - val_accuracy: 0.7933\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.9569 - accuracy: 0.7608 - val_loss: 0.4563 - val_accuracy: 0.8083\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8732 - accuracy: 0.7851 - val_loss: 0.3503 - val_accuracy: 0.8783\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8771 - accuracy: 0.8060 - val_loss: 0.4530 - val_accuracy: 0.8300\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.9684 - accuracy: 0.7519 - val_loss: 0.3106 - val_accuracy: 0.8917\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8571 - accuracy: 0.8145 - val_loss: 0.4991 - val_accuracy: 0.7700\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.8095 - accuracy: 0.8074 - val_loss: 0.4212 - val_accuracy: 0.8433\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.8407 - accuracy: 0.8176 - val_loss: 0.3752 - val_accuracy: 0.8583\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.8286 - accuracy: 0.8177 - val_loss: 0.3518 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.8027 - accuracy: 0.8240 - val_loss: 0.5194 - val_accuracy: 0.7617\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8115 - accuracy: 0.8217 - val_loss: 0.3697 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7156 - accuracy: 0.8498 - val_loss: 0.4441 - val_accuracy: 0.8217\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7408 - accuracy: 0.8152 - val_loss: 0.3512 - val_accuracy: 0.8583\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7670 - accuracy: 0.8335 - val_loss: 0.3096 - val_accuracy: 0.8833\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6913 - accuracy: 0.8656 - val_loss: 0.3676 - val_accuracy: 0.8617\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7074 - accuracy: 0.8362 - val_loss: 0.5060 - val_accuracy: 0.7633\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7747 - accuracy: 0.8233 - val_loss: 0.3851 - val_accuracy: 0.8500\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7353 - accuracy: 0.8449 - val_loss: 0.3727 - val_accuracy: 0.8567\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7008 - accuracy: 0.8632 - val_loss: 0.4550 - val_accuracy: 0.8117\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7007 - accuracy: 0.8488 - val_loss: 0.2987 - val_accuracy: 0.8817\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7042 - accuracy: 0.8534 - val_loss: 0.4240 - val_accuracy: 0.8467\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7062 - accuracy: 0.8561 - val_loss: 0.3616 - val_accuracy: 0.8567\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6725 - accuracy: 0.8471 - val_loss: 0.3739 - val_accuracy: 0.8583\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6636 - accuracy: 0.8724 - val_loss: 0.4089 - val_accuracy: 0.8550\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.7073 - accuracy: 0.8373 - val_loss: 0.3053 - val_accuracy: 0.8917\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5858 - accuracy: 0.8814 - val_loss: 0.4507 - val_accuracy: 0.8083\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6814 - accuracy: 0.8359 - val_loss: 0.4066 - val_accuracy: 0.8400\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6431 - accuracy: 0.8552 - val_loss: 0.3148 - val_accuracy: 0.8850\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7172 - accuracy: 0.8500 - val_loss: 0.3604 - val_accuracy: 0.8650\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6193 - accuracy: 0.8669 - val_loss: 0.4300 - val_accuracy: 0.8317\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5532 - accuracy: 0.8733 - val_loss: 0.2825 - val_accuracy: 0.8900\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.6071 - accuracy: 0.8617 - val_loss: 0.2629 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7079 - accuracy: 0.8750 - val_loss: 0.4461 - val_accuracy: 0.8317\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5444 - accuracy: 0.8774 - val_loss: 0.3690 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5985 - accuracy: 0.8682 - val_loss: 0.3172 - val_accuracy: 0.8583\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6386 - accuracy: 0.8480 - val_loss: 0.2872 - val_accuracy: 0.8917\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6270 - accuracy: 0.8701 - val_loss: 0.3086 - val_accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5238 - accuracy: 0.9019 - val_loss: 0.4574 - val_accuracy: 0.8067\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5827 - accuracy: 0.8694 - val_loss: 0.3106 - val_accuracy: 0.8850\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6019 - accuracy: 0.8694 - val_loss: 0.3719 - val_accuracy: 0.8583\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6698 - accuracy: 0.8537 - val_loss: 0.2821 - val_accuracy: 0.9017\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5733 - accuracy: 0.8761 - val_loss: 0.3152 - val_accuracy: 0.8850\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.5374 - accuracy: 0.8793 - val_loss: 0.3622 - val_accuracy: 0.8483\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6780 - accuracy: 0.8545 - val_loss: 0.3150 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5977 - accuracy: 0.8668 - val_loss: 0.2660 - val_accuracy: 0.9050\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 838us/step - loss: 0.5694 - accuracy: 0.8847 - val_loss: 0.2946 - val_accuracy: 0.9050\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6620 - accuracy: 0.8760 - val_loss: 0.3221 - val_accuracy: 0.8717\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5420 - accuracy: 0.9014 - val_loss: 0.3390 - val_accuracy: 0.8800\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5584 - accuracy: 0.8747 - val_loss: 0.3686 - val_accuracy: 0.8483\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6304 - accuracy: 0.8445 - val_loss: 0.3503 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5455 - accuracy: 0.8710 - val_loss: 0.3629 - val_accuracy: 0.8567\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5919 - accuracy: 0.8651 - val_loss: 0.3256 - val_accuracy: 0.8700\n",
      "10\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4405 - accuracy: 0.5244 - val_loss: 0.6095 - val_accuracy: 0.6833\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 1.1151 - accuracy: 0.6772 - val_loss: 0.5310 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 1.1056 - accuracy: 0.6909 - val_loss: 0.4653 - val_accuracy: 0.8150\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 1.0064 - accuracy: 0.7366 - val_loss: 0.4250 - val_accuracy: 0.8300\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.9366 - accuracy: 0.7878 - val_loss: 0.5031 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.9449 - accuracy: 0.7649 - val_loss: 0.3549 - val_accuracy: 0.8683\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8880 - accuracy: 0.8130 - val_loss: 0.4087 - val_accuracy: 0.8417\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8814 - accuracy: 0.8017 - val_loss: 0.4376 - val_accuracy: 0.8150\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8977 - accuracy: 0.8029 - val_loss: 0.4635 - val_accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.9038 - accuracy: 0.7795 - val_loss: 0.4258 - val_accuracy: 0.8267\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8314 - accuracy: 0.8152 - val_loss: 0.4751 - val_accuracy: 0.8033\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8012 - accuracy: 0.8172 - val_loss: 0.6155 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8783 - accuracy: 0.7915 - val_loss: 0.4289 - val_accuracy: 0.8400\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8287 - accuracy: 0.8285 - val_loss: 0.4169 - val_accuracy: 0.8533\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 856us/step - loss: 0.8203 - accuracy: 0.8234 - val_loss: 0.4217 - val_accuracy: 0.8417\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7372 - accuracy: 0.8377 - val_loss: 0.5762 - val_accuracy: 0.7450\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8031 - accuracy: 0.8313 - val_loss: 0.4262 - val_accuracy: 0.8483\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7263 - accuracy: 0.8521 - val_loss: 0.4443 - val_accuracy: 0.8383\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7205 - accuracy: 0.8539 - val_loss: 0.4733 - val_accuracy: 0.8217\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7432 - accuracy: 0.8395 - val_loss: 0.3849 - val_accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6946 - accuracy: 0.8733 - val_loss: 0.4314 - val_accuracy: 0.8400\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7704 - accuracy: 0.8323 - val_loss: 0.4084 - val_accuracy: 0.8633\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7675 - accuracy: 0.8534 - val_loss: 0.3260 - val_accuracy: 0.8850\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6987 - accuracy: 0.8651 - val_loss: 0.4325 - val_accuracy: 0.8217\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7583 - accuracy: 0.8551 - val_loss: 0.4211 - val_accuracy: 0.8417\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7865 - accuracy: 0.8364 - val_loss: 0.3511 - val_accuracy: 0.8750\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7275 - accuracy: 0.8487 - val_loss: 0.3649 - val_accuracy: 0.8733\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7558 - accuracy: 0.8743 - val_loss: 0.4172 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7571 - accuracy: 0.8528 - val_loss: 0.3659 - val_accuracy: 0.8683\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6929 - accuracy: 0.8595 - val_loss: 0.3424 - val_accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.7291 - accuracy: 0.8500 - val_loss: 0.5349 - val_accuracy: 0.7950\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7550 - accuracy: 0.8447 - val_loss: 0.3847 - val_accuracy: 0.8467\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7798 - accuracy: 0.8303 - val_loss: 0.3134 - val_accuracy: 0.8700\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6968 - accuracy: 0.8746 - val_loss: 0.3448 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7021 - accuracy: 0.8658 - val_loss: 0.3425 - val_accuracy: 0.8783\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6053 - accuracy: 0.8736 - val_loss: 0.3217 - val_accuracy: 0.8800\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6962 - accuracy: 0.8618 - val_loss: 0.3920 - val_accuracy: 0.8350\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6683 - accuracy: 0.8626 - val_loss: 0.4135 - val_accuracy: 0.8267\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6880 - accuracy: 0.8558 - val_loss: 0.2882 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6735 - accuracy: 0.8744 - val_loss: 0.3542 - val_accuracy: 0.8817\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6726 - accuracy: 0.8666 - val_loss: 0.4052 - val_accuracy: 0.8567\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6804 - accuracy: 0.8610 - val_loss: 0.4002 - val_accuracy: 0.8367\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6276 - accuracy: 0.8714 - val_loss: 0.4017 - val_accuracy: 0.8483\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6605 - accuracy: 0.8562 - val_loss: 0.3696 - val_accuracy: 0.8583\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5813 - accuracy: 0.8760 - val_loss: 0.3964 - val_accuracy: 0.8367\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6270 - accuracy: 0.8689 - val_loss: 0.4013 - val_accuracy: 0.8250\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6499 - accuracy: 0.8665 - val_loss: 0.3156 - val_accuracy: 0.8933\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5438 - accuracy: 0.8918 - val_loss: 0.3006 - val_accuracy: 0.8833\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6224 - accuracy: 0.8621 - val_loss: 0.3869 - val_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5891 - accuracy: 0.8770 - val_loss: 0.3250 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6158 - accuracy: 0.8815 - val_loss: 0.3471 - val_accuracy: 0.8567\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6149 - accuracy: 0.8656 - val_loss: 0.4630 - val_accuracy: 0.7883\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6487 - accuracy: 0.8629 - val_loss: 0.2994 - val_accuracy: 0.8867\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6153 - accuracy: 0.8706 - val_loss: 0.4242 - val_accuracy: 0.8033\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6272 - accuracy: 0.8791 - val_loss: 0.2739 - val_accuracy: 0.9083\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.4800 - accuracy: 0.9037 - val_loss: 0.3393 - val_accuracy: 0.8533\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5904 - accuracy: 0.8777 - val_loss: 0.3243 - val_accuracy: 0.8833\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.5643 - accuracy: 0.8857 - val_loss: 0.3009 - val_accuracy: 0.8817\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.5877 - accuracy: 0.8683 - val_loss: 0.4228 - val_accuracy: 0.8050\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5741 - accuracy: 0.8701 - val_loss: 0.3618 - val_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5247 - accuracy: 0.8800 - val_loss: 0.3429 - val_accuracy: 0.8583\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5786 - accuracy: 0.8787 - val_loss: 0.3694 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.4777 - accuracy: 0.8981 - val_loss: 0.3852 - val_accuracy: 0.8217\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4932 - accuracy: 0.8841 - val_loss: 0.3255 - val_accuracy: 0.8617\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5461 - accuracy: 0.8723 - val_loss: 0.3833 - val_accuracy: 0.8183\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6331 - accuracy: 0.8445 - val_loss: 0.4095 - val_accuracy: 0.8183\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6311 - accuracy: 0.8609 - val_loss: 0.3022 - val_accuracy: 0.8783\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.4951 - accuracy: 0.8973 - val_loss: 0.4130 - val_accuracy: 0.8217\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.5976 - accuracy: 0.8688 - val_loss: 0.2857 - val_accuracy: 0.8933\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.4801 - accuracy: 0.8991 - val_loss: 0.3410 - val_accuracy: 0.8567\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5441 - accuracy: 0.8814 - val_loss: 0.2965 - val_accuracy: 0.8933\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.4391 - accuracy: 0.8986 - val_loss: 0.3895 - val_accuracy: 0.8217\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6353 - accuracy: 0.8722 - val_loss: 0.3744 - val_accuracy: 0.8517\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6258 - accuracy: 0.8751 - val_loss: 0.3463 - val_accuracy: 0.8567\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.4862 - accuracy: 0.8913 - val_loss: 0.3970 - val_accuracy: 0.8350\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5520 - accuracy: 0.5303 - val_loss: 0.6894 - val_accuracy: 0.6183\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 1.0739 - accuracy: 0.6755 - val_loss: 0.5181 - val_accuracy: 0.7600\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 1.0094 - accuracy: 0.7182 - val_loss: 0.5194 - val_accuracy: 0.7817\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.9677 - accuracy: 0.7438 - val_loss: 0.4079 - val_accuracy: 0.8367\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.9656 - accuracy: 0.7600 - val_loss: 0.6605 - val_accuracy: 0.6867\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.9246 - accuracy: 0.7573 - val_loss: 0.3465 - val_accuracy: 0.8617\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.9031 - accuracy: 0.8145 - val_loss: 0.4749 - val_accuracy: 0.8217\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8412 - accuracy: 0.8048 - val_loss: 0.4181 - val_accuracy: 0.8233\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8112 - accuracy: 0.8096 - val_loss: 0.4213 - val_accuracy: 0.8467\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8740 - accuracy: 0.7860 - val_loss: 0.5763 - val_accuracy: 0.7067\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8038 - accuracy: 0.8044 - val_loss: 0.5872 - val_accuracy: 0.7567\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8115 - accuracy: 0.7954 - val_loss: 0.4491 - val_accuracy: 0.8217\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8131 - accuracy: 0.8172 - val_loss: 0.5183 - val_accuracy: 0.7617\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7550 - accuracy: 0.8220 - val_loss: 0.4549 - val_accuracy: 0.8283\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.8191 - accuracy: 0.8146 - val_loss: 0.4143 - val_accuracy: 0.8433\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7809 - accuracy: 0.8327 - val_loss: 0.4578 - val_accuracy: 0.8117\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.8019 - accuracy: 0.8251 - val_loss: 0.3143 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7502 - accuracy: 0.8375 - val_loss: 0.4029 - val_accuracy: 0.8533\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7510 - accuracy: 0.8486 - val_loss: 0.3640 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7431 - accuracy: 0.8459 - val_loss: 0.3650 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.8013 - accuracy: 0.8117 - val_loss: 0.3970 - val_accuracy: 0.8467\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6841 - accuracy: 0.8558 - val_loss: 0.3412 - val_accuracy: 0.8833\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.7611 - accuracy: 0.8397 - val_loss: 0.3348 - val_accuracy: 0.8833\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7359 - accuracy: 0.8399 - val_loss: 0.4016 - val_accuracy: 0.8317\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7932 - accuracy: 0.8418 - val_loss: 0.3182 - val_accuracy: 0.8833\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7516 - accuracy: 0.8359 - val_loss: 0.3072 - val_accuracy: 0.9017\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7600 - accuracy: 0.8434 - val_loss: 0.3886 - val_accuracy: 0.8600\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6909 - accuracy: 0.8436 - val_loss: 0.3983 - val_accuracy: 0.8350\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6700 - accuracy: 0.8529 - val_loss: 0.4064 - val_accuracy: 0.8300\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7150 - accuracy: 0.8453 - val_loss: 0.4573 - val_accuracy: 0.7967\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5879 - accuracy: 0.8756 - val_loss: 0.4583 - val_accuracy: 0.7950\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6205 - accuracy: 0.8511 - val_loss: 0.3637 - val_accuracy: 0.8517\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.7153 - accuracy: 0.8300 - val_loss: 0.3733 - val_accuracy: 0.8700\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6506 - accuracy: 0.8665 - val_loss: 0.4524 - val_accuracy: 0.7883\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6743 - accuracy: 0.8437 - val_loss: 0.4359 - val_accuracy: 0.7883\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5856 - accuracy: 0.8622 - val_loss: 0.2979 - val_accuracy: 0.8967\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6578 - accuracy: 0.8698 - val_loss: 0.3874 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6659 - accuracy: 0.8567 - val_loss: 0.4129 - val_accuracy: 0.8483\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7290 - accuracy: 0.8360 - val_loss: 0.3770 - val_accuracy: 0.8617\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.5631 - accuracy: 0.8777 - val_loss: 0.3311 - val_accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6138 - accuracy: 0.8676 - val_loss: 0.4145 - val_accuracy: 0.8033\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.5987 - accuracy: 0.8585 - val_loss: 0.3407 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5901 - accuracy: 0.8742 - val_loss: 0.3225 - val_accuracy: 0.8783\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6368 - accuracy: 0.8671 - val_loss: 0.2566 - val_accuracy: 0.9083\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7128 - accuracy: 0.8604 - val_loss: 0.3789 - val_accuracy: 0.8150\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.5510 - accuracy: 0.8735 - val_loss: 0.2933 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7182 - accuracy: 0.8550 - val_loss: 0.3768 - val_accuracy: 0.8417\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5958 - accuracy: 0.8703 - val_loss: 0.2904 - val_accuracy: 0.8967\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6238 - accuracy: 0.8687 - val_loss: 0.3812 - val_accuracy: 0.8433\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5329 - accuracy: 0.8661 - val_loss: 0.3952 - val_accuracy: 0.8083\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5732 - accuracy: 0.8700 - val_loss: 0.3467 - val_accuracy: 0.8517\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7162 - accuracy: 0.8489 - val_loss: 0.3221 - val_accuracy: 0.8567\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5149 - accuracy: 0.8882 - val_loss: 0.2898 - val_accuracy: 0.8850\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6239 - accuracy: 0.8657 - val_loss: 0.3774 - val_accuracy: 0.8300\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5888 - accuracy: 0.8665 - val_loss: 0.3451 - val_accuracy: 0.8533\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5529 - accuracy: 0.8756 - val_loss: 0.3490 - val_accuracy: 0.8417\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5424 - accuracy: 0.8759 - val_loss: 0.3735 - val_accuracy: 0.8233\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5194 - accuracy: 0.8771 - val_loss: 0.2977 - val_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5651 - accuracy: 0.8792 - val_loss: 0.2759 - val_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6292 - accuracy: 0.8854 - val_loss: 0.3638 - val_accuracy: 0.8433\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5458 - accuracy: 0.8731 - val_loss: 0.3849 - val_accuracy: 0.8117\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5347 - accuracy: 0.8770 - val_loss: 0.4732 - val_accuracy: 0.7733\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5729 - accuracy: 0.8620 - val_loss: 0.3988 - val_accuracy: 0.8167\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6077 - accuracy: 0.8700 - val_loss: 0.3344 - val_accuracy: 0.8717\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4081 - accuracy: 0.5538 - val_loss: 0.6294 - val_accuracy: 0.6950\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 1.1825 - accuracy: 0.6680 - val_loss: 0.6024 - val_accuracy: 0.7033\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 1.0314 - accuracy: 0.7104 - val_loss: 0.5340 - val_accuracy: 0.7783\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.8878 - accuracy: 0.7714 - val_loss: 0.5343 - val_accuracy: 0.7833\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9247 - accuracy: 0.7800 - val_loss: 0.5196 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.8737 - accuracy: 0.7855 - val_loss: 0.5149 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 890us/step - loss: 0.8374 - accuracy: 0.7997 - val_loss: 0.4380 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.9113 - accuracy: 0.7853 - val_loss: 0.4983 - val_accuracy: 0.8050\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.8090 - accuracy: 0.8196 - val_loss: 0.4319 - val_accuracy: 0.8367\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.7502 - accuracy: 0.8460 - val_loss: 0.5186 - val_accuracy: 0.7867\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7629 - accuracy: 0.8256 - val_loss: 0.6130 - val_accuracy: 0.7400\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8446 - accuracy: 0.8058 - val_loss: 0.4570 - val_accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8090 - accuracy: 0.8215 - val_loss: 0.4018 - val_accuracy: 0.8450\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7739 - accuracy: 0.8355 - val_loss: 0.4358 - val_accuracy: 0.8117\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.7218 - accuracy: 0.8472 - val_loss: 0.4977 - val_accuracy: 0.7617\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7963 - accuracy: 0.8155 - val_loss: 0.4653 - val_accuracy: 0.8050\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.7246 - accuracy: 0.8403 - val_loss: 0.3866 - val_accuracy: 0.8600\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7646 - accuracy: 0.8548 - val_loss: 0.4067 - val_accuracy: 0.8500\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7779 - accuracy: 0.8421 - val_loss: 0.4555 - val_accuracy: 0.8250\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7459 - accuracy: 0.8359 - val_loss: 0.4333 - val_accuracy: 0.8317\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7823 - accuracy: 0.8374 - val_loss: 0.3944 - val_accuracy: 0.8700\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7066 - accuracy: 0.8411 - val_loss: 0.4811 - val_accuracy: 0.7917\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.7298 - accuracy: 0.8513 - val_loss: 0.4351 - val_accuracy: 0.8150\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7452 - accuracy: 0.8424 - val_loss: 0.3268 - val_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6202 - accuracy: 0.8688 - val_loss: 0.3781 - val_accuracy: 0.8450\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6934 - accuracy: 0.8749 - val_loss: 0.3328 - val_accuracy: 0.8867\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.6907 - accuracy: 0.8737 - val_loss: 0.3099 - val_accuracy: 0.8950\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.7144 - accuracy: 0.8694 - val_loss: 0.3058 - val_accuracy: 0.8950\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6757 - accuracy: 0.8679 - val_loss: 0.3620 - val_accuracy: 0.8583\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6602 - accuracy: 0.8714 - val_loss: 0.3524 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6752 - accuracy: 0.8707 - val_loss: 0.3220 - val_accuracy: 0.8967\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7399 - accuracy: 0.8706 - val_loss: 0.2545 - val_accuracy: 0.9167\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.5949 - accuracy: 0.9053 - val_loss: 0.5328 - val_accuracy: 0.7850\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6273 - accuracy: 0.8570 - val_loss: 0.4123 - val_accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6705 - accuracy: 0.8839 - val_loss: 0.4532 - val_accuracy: 0.7900\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6527 - accuracy: 0.8576 - val_loss: 0.3567 - val_accuracy: 0.8783\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6596 - accuracy: 0.8618 - val_loss: 0.3479 - val_accuracy: 0.8600\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5935 - accuracy: 0.8857 - val_loss: 0.4381 - val_accuracy: 0.8100\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6341 - accuracy: 0.8545 - val_loss: 0.3667 - val_accuracy: 0.8717\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.6115 - accuracy: 0.8756 - val_loss: 0.3774 - val_accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6152 - accuracy: 0.8953 - val_loss: 0.2952 - val_accuracy: 0.8967\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5598 - accuracy: 0.8878 - val_loss: 0.2896 - val_accuracy: 0.9050\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6938 - accuracy: 0.8713 - val_loss: 0.3131 - val_accuracy: 0.8933\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6424 - accuracy: 0.8755 - val_loss: 0.3826 - val_accuracy: 0.8767\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.6433 - accuracy: 0.8711 - val_loss: 0.4113 - val_accuracy: 0.8517\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6956 - accuracy: 0.8402 - val_loss: 0.2514 - val_accuracy: 0.9267\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6117 - accuracy: 0.8809 - val_loss: 0.2509 - val_accuracy: 0.9183\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5547 - accuracy: 0.8914 - val_loss: 0.2804 - val_accuracy: 0.8983\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6109 - accuracy: 0.8675 - val_loss: 0.3041 - val_accuracy: 0.8817\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6019 - accuracy: 0.8899 - val_loss: 0.4319 - val_accuracy: 0.8283\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6449 - accuracy: 0.8656 - val_loss: 0.3216 - val_accuracy: 0.8817\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6139 - accuracy: 0.8738 - val_loss: 0.3498 - val_accuracy: 0.8650\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6382 - accuracy: 0.8721 - val_loss: 0.3381 - val_accuracy: 0.8617\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5960 - accuracy: 0.8725 - val_loss: 0.2768 - val_accuracy: 0.9083\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6248 - accuracy: 0.8775 - val_loss: 0.2828 - val_accuracy: 0.9067\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5590 - accuracy: 0.8755 - val_loss: 0.2973 - val_accuracy: 0.8900\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5676 - accuracy: 0.8818 - val_loss: 0.3530 - val_accuracy: 0.8583\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5572 - accuracy: 0.8752 - val_loss: 0.3974 - val_accuracy: 0.8050\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6004 - accuracy: 0.8501 - val_loss: 0.2960 - val_accuracy: 0.8933\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.6716 - accuracy: 0.8914 - val_loss: 0.3388 - val_accuracy: 0.8567\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5637 - accuracy: 0.8813 - val_loss: 0.2812 - val_accuracy: 0.9017\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7098 - accuracy: 0.8740 - val_loss: 0.3121 - val_accuracy: 0.8933\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5149 - accuracy: 0.8935 - val_loss: 0.3476 - val_accuracy: 0.8600\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5457 - accuracy: 0.8842 - val_loss: 0.3465 - val_accuracy: 0.8550\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5578 - accuracy: 0.8728 - val_loss: 0.2861 - val_accuracy: 0.8983\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6438 - accuracy: 0.8781 - val_loss: 0.4985 - val_accuracy: 0.7400\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5681 - accuracy: 0.8507 - val_loss: 0.3340 - val_accuracy: 0.9017\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3916 - accuracy: 0.5363 - val_loss: 0.6683 - val_accuracy: 0.6267\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 1.1190 - accuracy: 0.6542 - val_loss: 0.5171 - val_accuracy: 0.7767\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 1.0162 - accuracy: 0.7473 - val_loss: 0.5133 - val_accuracy: 0.7733\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 1.0171 - accuracy: 0.7351 - val_loss: 0.4725 - val_accuracy: 0.7917\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.9311 - accuracy: 0.7758 - val_loss: 0.4116 - val_accuracy: 0.8317\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.9126 - accuracy: 0.7897 - val_loss: 0.4273 - val_accuracy: 0.8283\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.8798 - accuracy: 0.8137 - val_loss: 0.5117 - val_accuracy: 0.8017\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7785 - accuracy: 0.8261 - val_loss: 0.4771 - val_accuracy: 0.8017\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8180 - accuracy: 0.8153 - val_loss: 0.5433 - val_accuracy: 0.7433\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9194 - accuracy: 0.7731 - val_loss: 0.3675 - val_accuracy: 0.8717\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.8603 - accuracy: 0.8311 - val_loss: 0.3309 - val_accuracy: 0.8783\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7708 - accuracy: 0.8427 - val_loss: 0.3679 - val_accuracy: 0.8650\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7914 - accuracy: 0.8300 - val_loss: 0.4579 - val_accuracy: 0.8367\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8277 - accuracy: 0.8334 - val_loss: 0.3754 - val_accuracy: 0.8700\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.8144 - accuracy: 0.8463 - val_loss: 0.3648 - val_accuracy: 0.8733\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8224 - accuracy: 0.8317 - val_loss: 0.4116 - val_accuracy: 0.8450\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7621 - accuracy: 0.8657 - val_loss: 0.3495 - val_accuracy: 0.8783\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7584 - accuracy: 0.8597 - val_loss: 0.3645 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 806us/step - loss: 0.7142 - accuracy: 0.8648 - val_loss: 0.4615 - val_accuracy: 0.8267\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7776 - accuracy: 0.8426 - val_loss: 0.3157 - val_accuracy: 0.8867\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.7778 - accuracy: 0.8608 - val_loss: 0.3726 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8142 - accuracy: 0.8284 - val_loss: 0.3712 - val_accuracy: 0.8767\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6865 - accuracy: 0.8709 - val_loss: 0.3493 - val_accuracy: 0.8917\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6649 - accuracy: 0.8682 - val_loss: 0.3372 - val_accuracy: 0.8800\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.6802 - accuracy: 0.8715 - val_loss: 0.4118 - val_accuracy: 0.8450\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7175 - accuracy: 0.8599 - val_loss: 0.3148 - val_accuracy: 0.8917\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8227 - accuracy: 0.8378 - val_loss: 0.2453 - val_accuracy: 0.9133\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7454 - accuracy: 0.8522 - val_loss: 0.2430 - val_accuracy: 0.9183\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6795 - accuracy: 0.8787 - val_loss: 0.4023 - val_accuracy: 0.8500\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6708 - accuracy: 0.8658 - val_loss: 0.4263 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.6765 - accuracy: 0.8714 - val_loss: 0.3168 - val_accuracy: 0.9017\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.6652 - accuracy: 0.8771 - val_loss: 0.3281 - val_accuracy: 0.8850\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.6671 - accuracy: 0.8587 - val_loss: 0.3303 - val_accuracy: 0.8933\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6872 - accuracy: 0.8748 - val_loss: 0.3562 - val_accuracy: 0.8833\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.5898 - accuracy: 0.8900 - val_loss: 0.3467 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7020 - accuracy: 0.8572 - val_loss: 0.2386 - val_accuracy: 0.9233\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7072 - accuracy: 0.8677 - val_loss: 0.2846 - val_accuracy: 0.9050\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6526 - accuracy: 0.8857 - val_loss: 0.3203 - val_accuracy: 0.8883\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6683 - accuracy: 0.8617 - val_loss: 0.3644 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6686 - accuracy: 0.8820 - val_loss: 0.3342 - val_accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5872 - accuracy: 0.8750 - val_loss: 0.5885 - val_accuracy: 0.7117\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6178 - accuracy: 0.8483 - val_loss: 0.3569 - val_accuracy: 0.8700\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6457 - accuracy: 0.8682 - val_loss: 0.5519 - val_accuracy: 0.7533\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6371 - accuracy: 0.8546 - val_loss: 0.3975 - val_accuracy: 0.8267\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6197 - accuracy: 0.8533 - val_loss: 0.4007 - val_accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5707 - accuracy: 0.8745 - val_loss: 0.4737 - val_accuracy: 0.8017\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5564 - accuracy: 0.8720 - val_loss: 0.3045 - val_accuracy: 0.8917\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5995 - accuracy: 0.8819 - val_loss: 0.2868 - val_accuracy: 0.9033\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5131 - accuracy: 0.9023 - val_loss: 0.3824 - val_accuracy: 0.8583\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7167 - accuracy: 0.8765 - val_loss: 0.2624 - val_accuracy: 0.9100\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.8801 - val_loss: 0.2707 - val_accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.5428 - accuracy: 0.8936 - val_loss: 0.3788 - val_accuracy: 0.8617\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5653 - accuracy: 0.8805 - val_loss: 0.3306 - val_accuracy: 0.8900\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5490 - accuracy: 0.8847 - val_loss: 0.2934 - val_accuracy: 0.9017\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5199 - accuracy: 0.9025 - val_loss: 0.2927 - val_accuracy: 0.8967\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5311 - accuracy: 0.8939 - val_loss: 0.2771 - val_accuracy: 0.9083\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3432 - accuracy: 0.5774 - val_loss: 0.6029 - val_accuracy: 0.6967\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 1.0599 - accuracy: 0.6770 - val_loss: 0.6844 - val_accuracy: 0.6633\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.9817 - accuracy: 0.7295 - val_loss: 0.5106 - val_accuracy: 0.8083\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 1.0315 - accuracy: 0.7304 - val_loss: 0.5062 - val_accuracy: 0.7900\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.9435 - accuracy: 0.7753 - val_loss: 0.4150 - val_accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.9114 - accuracy: 0.7765 - val_loss: 0.4879 - val_accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8919 - accuracy: 0.7856 - val_loss: 0.4218 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.9067 - accuracy: 0.7987 - val_loss: 0.4233 - val_accuracy: 0.8283\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7655 - accuracy: 0.8190 - val_loss: 0.4855 - val_accuracy: 0.8117\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7982 - accuracy: 0.8095 - val_loss: 0.5174 - val_accuracy: 0.7850\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8480 - accuracy: 0.8011 - val_loss: 0.3817 - val_accuracy: 0.8533\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.8251 - accuracy: 0.8308 - val_loss: 0.4417 - val_accuracy: 0.8300\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8486 - accuracy: 0.8149 - val_loss: 0.4023 - val_accuracy: 0.8550\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8202 - accuracy: 0.8119 - val_loss: 0.3970 - val_accuracy: 0.8583\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7817 - accuracy: 0.8281 - val_loss: 0.3357 - val_accuracy: 0.8783\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8900 - accuracy: 0.8118 - val_loss: 0.4113 - val_accuracy: 0.8200\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.9422 - accuracy: 0.8126 - val_loss: 0.3590 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.8207 - accuracy: 0.8247 - val_loss: 0.3842 - val_accuracy: 0.8650\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.8508 - accuracy: 0.8190 - val_loss: 0.4083 - val_accuracy: 0.8500\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7029 - accuracy: 0.8491 - val_loss: 0.4117 - val_accuracy: 0.8533\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.8167 - accuracy: 0.8349 - val_loss: 0.4791 - val_accuracy: 0.8067\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7557 - accuracy: 0.8168 - val_loss: 0.3814 - val_accuracy: 0.8550\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7127 - accuracy: 0.8344 - val_loss: 0.4630 - val_accuracy: 0.8167\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6435 - accuracy: 0.8522 - val_loss: 0.4277 - val_accuracy: 0.8350\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.7266 - accuracy: 0.8340 - val_loss: 0.3591 - val_accuracy: 0.8717\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.7734 - accuracy: 0.8413 - val_loss: 0.3932 - val_accuracy: 0.8467\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7796 - accuracy: 0.8423 - val_loss: 0.4885 - val_accuracy: 0.8033\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7744 - accuracy: 0.8174 - val_loss: 0.3692 - val_accuracy: 0.8617\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7511 - accuracy: 0.8474 - val_loss: 0.4115 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6962 - accuracy: 0.8522 - val_loss: 0.3547 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7431 - accuracy: 0.8367 - val_loss: 0.5186 - val_accuracy: 0.7900\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5990 - accuracy: 0.8542 - val_loss: 0.4333 - val_accuracy: 0.8067\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6565 - accuracy: 0.8530 - val_loss: 0.4554 - val_accuracy: 0.8183\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7746 - accuracy: 0.8355 - val_loss: 0.4979 - val_accuracy: 0.8117\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7525 - accuracy: 0.8179 - val_loss: 0.4031 - val_accuracy: 0.8333\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4979 - accuracy: 0.5364 - val_loss: 0.5895 - val_accuracy: 0.6917\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 1.0613 - accuracy: 0.6798 - val_loss: 0.6324 - val_accuracy: 0.6950\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9941 - accuracy: 0.7324 - val_loss: 0.4883 - val_accuracy: 0.7967\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9309 - accuracy: 0.7540 - val_loss: 0.5465 - val_accuracy: 0.7550\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.9250 - accuracy: 0.7652 - val_loss: 0.5099 - val_accuracy: 0.7817\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9014 - accuracy: 0.7652 - val_loss: 0.5047 - val_accuracy: 0.7883\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.7994 - accuracy: 0.8087 - val_loss: 0.5944 - val_accuracy: 0.7433\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8535 - accuracy: 0.7774 - val_loss: 0.6358 - val_accuracy: 0.6933\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 990us/step - loss: 0.8974 - accuracy: 0.7629 - val_loss: 0.4481 - val_accuracy: 0.8100\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.7602 - accuracy: 0.8063 - val_loss: 0.5786 - val_accuracy: 0.6733\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8352 - accuracy: 0.7843 - val_loss: 0.4655 - val_accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.9214 - accuracy: 0.7755 - val_loss: 0.4705 - val_accuracy: 0.8167\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8219 - accuracy: 0.8014 - val_loss: 0.4349 - val_accuracy: 0.8383\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7575 - accuracy: 0.8325 - val_loss: 0.3962 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8184 - accuracy: 0.8071 - val_loss: 0.3649 - val_accuracy: 0.8700\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7479 - accuracy: 0.8499 - val_loss: 0.4807 - val_accuracy: 0.8017\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8280 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7800\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.7202 - accuracy: 0.8052 - val_loss: 0.5177 - val_accuracy: 0.7783\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.7110 - accuracy: 0.8395 - val_loss: 0.3605 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7999 - accuracy: 0.8388 - val_loss: 0.3182 - val_accuracy: 0.8750\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8009 - accuracy: 0.8480 - val_loss: 0.3279 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7471 - accuracy: 0.8347 - val_loss: 0.4636 - val_accuracy: 0.8217\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7673 - accuracy: 0.8295 - val_loss: 0.3424 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.8190 - accuracy: 0.8357 - val_loss: 0.4134 - val_accuracy: 0.8517\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.8649 - val_loss: 0.4310 - val_accuracy: 0.8267\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7716 - accuracy: 0.8139 - val_loss: 0.4965 - val_accuracy: 0.7817\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.8400 - val_loss: 0.3089 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8689 - accuracy: 0.8299 - val_loss: 0.3437 - val_accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7492 - accuracy: 0.8312 - val_loss: 0.3583 - val_accuracy: 0.8700\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.7713 - accuracy: 0.8408 - val_loss: 0.3709 - val_accuracy: 0.8633\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.8518 - val_loss: 0.4473 - val_accuracy: 0.7967\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.8444 - val_loss: 0.3553 - val_accuracy: 0.8417\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.8600 - val_loss: 0.4109 - val_accuracy: 0.8383\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.8566 - val_loss: 0.2794 - val_accuracy: 0.9033\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6481 - accuracy: 0.8639 - val_loss: 0.3307 - val_accuracy: 0.8700\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6898 - accuracy: 0.8530 - val_loss: 0.2992 - val_accuracy: 0.8833\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5926 - accuracy: 0.8785 - val_loss: 0.3617 - val_accuracy: 0.8517\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6882 - accuracy: 0.8565 - val_loss: 0.3117 - val_accuracy: 0.8867\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6046 - accuracy: 0.8736 - val_loss: 0.3812 - val_accuracy: 0.8517\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6871 - accuracy: 0.8468 - val_loss: 0.3646 - val_accuracy: 0.8583\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6475 - accuracy: 0.8847 - val_loss: 0.3789 - val_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6670 - accuracy: 0.8544 - val_loss: 0.3962 - val_accuracy: 0.8383\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7358 - accuracy: 0.8393 - val_loss: 0.3988 - val_accuracy: 0.8500\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6230 - accuracy: 0.8744 - val_loss: 0.3176 - val_accuracy: 0.8833\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.6949 - accuracy: 0.8668 - val_loss: 0.3465 - val_accuracy: 0.8650\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 978us/step - loss: 0.6534 - accuracy: 0.8727 - val_loss: 0.4149 - val_accuracy: 0.8267\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6411 - accuracy: 0.8616 - val_loss: 0.3348 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6645 - accuracy: 0.8629 - val_loss: 0.4118 - val_accuracy: 0.8033\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.8784 - val_loss: 0.3475 - val_accuracy: 0.8683\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.7062 - accuracy: 0.8532 - val_loss: 0.3033 - val_accuracy: 0.8983\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.8853 - val_loss: 0.3363 - val_accuracy: 0.8700\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6134 - accuracy: 0.8717 - val_loss: 0.3345 - val_accuracy: 0.8567\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.5850 - accuracy: 0.8927 - val_loss: 0.3610 - val_accuracy: 0.8467\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.8732 - val_loss: 0.3299 - val_accuracy: 0.8700\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.4196 - accuracy: 0.5420 - val_loss: 0.6983 - val_accuracy: 0.6450\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 1.0979 - accuracy: 0.6615 - val_loss: 0.6273 - val_accuracy: 0.7083\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0224 - accuracy: 0.7124 - val_loss: 0.5439 - val_accuracy: 0.7633\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 1.0112 - accuracy: 0.7253 - val_loss: 0.5594 - val_accuracy: 0.7533\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8873 - accuracy: 0.7707 - val_loss: 0.4773 - val_accuracy: 0.8133\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8411 - accuracy: 0.7908 - val_loss: 0.4508 - val_accuracy: 0.8083\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8930 - accuracy: 0.7845 - val_loss: 0.5132 - val_accuracy: 0.7800\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.8838 - accuracy: 0.7734 - val_loss: 0.4694 - val_accuracy: 0.8083\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.9462 - accuracy: 0.7693 - val_loss: 0.4929 - val_accuracy: 0.8017\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.8385 - accuracy: 0.7835 - val_loss: 0.4737 - val_accuracy: 0.7983\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8140 - accuracy: 0.8071 - val_loss: 0.4331 - val_accuracy: 0.8400\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7996 - accuracy: 0.8106 - val_loss: 0.3876 - val_accuracy: 0.8400\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8093 - accuracy: 0.8120 - val_loss: 0.5258 - val_accuracy: 0.7800\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8323 - accuracy: 0.8024 - val_loss: 0.3597 - val_accuracy: 0.8633\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7156 - accuracy: 0.8485 - val_loss: 0.3821 - val_accuracy: 0.8583\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.8180 - accuracy: 0.8098 - val_loss: 0.3638 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8701 - accuracy: 0.7989 - val_loss: 0.3939 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7009 - accuracy: 0.8396 - val_loss: 0.3709 - val_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7456 - accuracy: 0.8460 - val_loss: 0.4024 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6612 - accuracy: 0.8567 - val_loss: 0.3624 - val_accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8654 - accuracy: 0.8187 - val_loss: 0.4463 - val_accuracy: 0.8283\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7280 - accuracy: 0.8296 - val_loss: 0.3181 - val_accuracy: 0.8850\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7276 - accuracy: 0.8552 - val_loss: 0.3882 - val_accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7774 - accuracy: 0.8326 - val_loss: 0.3846 - val_accuracy: 0.8417\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7383 - accuracy: 0.8380 - val_loss: 0.4125 - val_accuracy: 0.8233\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6878 - accuracy: 0.8249 - val_loss: 0.4252 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7367 - accuracy: 0.8418 - val_loss: 0.4587 - val_accuracy: 0.7800\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7629 - accuracy: 0.8227 - val_loss: 0.4545 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7474 - accuracy: 0.8320 - val_loss: 0.3343 - val_accuracy: 0.8650\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 0.6780 - accuracy: 0.8587 - val_loss: 0.3578 - val_accuracy: 0.8783\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6467 - accuracy: 0.8490 - val_loss: 0.4757 - val_accuracy: 0.7917\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7316 - accuracy: 0.8277 - val_loss: 0.4483 - val_accuracy: 0.8317\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6365 - accuracy: 0.8537 - val_loss: 0.3843 - val_accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.7235 - accuracy: 0.8387 - val_loss: 0.3448 - val_accuracy: 0.8683\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6369 - accuracy: 0.8650 - val_loss: 0.3465 - val_accuracy: 0.8417\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6834 - accuracy: 0.8291 - val_loss: 0.3253 - val_accuracy: 0.8933\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7379 - accuracy: 0.8532 - val_loss: 0.3093 - val_accuracy: 0.8883\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6195 - accuracy: 0.8778 - val_loss: 0.4106 - val_accuracy: 0.8150\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.8394 - val_loss: 0.3236 - val_accuracy: 0.8783\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6399 - accuracy: 0.8705 - val_loss: 0.3055 - val_accuracy: 0.8933\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6360 - accuracy: 0.8649 - val_loss: 0.3191 - val_accuracy: 0.8867\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6839 - accuracy: 0.8494 - val_loss: 0.2737 - val_accuracy: 0.9017\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.5887 - accuracy: 0.8726 - val_loss: 0.3212 - val_accuracy: 0.8850\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.8469 - val_loss: 0.3535 - val_accuracy: 0.8633\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.6293 - accuracy: 0.8559 - val_loss: 0.3423 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6024 - accuracy: 0.8592 - val_loss: 0.2941 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5296 - accuracy: 0.8836 - val_loss: 0.3686 - val_accuracy: 0.8467\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5952 - accuracy: 0.8662 - val_loss: 0.3902 - val_accuracy: 0.8433\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5967 - accuracy: 0.8761 - val_loss: 0.3007 - val_accuracy: 0.8900\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6166 - accuracy: 0.8638 - val_loss: 0.3269 - val_accuracy: 0.8783\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5832 - accuracy: 0.8769 - val_loss: 0.4050 - val_accuracy: 0.8283\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6365 - accuracy: 0.8546 - val_loss: 0.3747 - val_accuracy: 0.8483\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5649 - accuracy: 0.8787 - val_loss: 0.3315 - val_accuracy: 0.8733\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5327 - accuracy: 0.8887 - val_loss: 0.3447 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6613 - accuracy: 0.8695 - val_loss: 0.3361 - val_accuracy: 0.8800\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5175 - accuracy: 0.9030 - val_loss: 0.3167 - val_accuracy: 0.8817\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 844us/step - loss: 0.6357 - accuracy: 0.8747 - val_loss: 0.3111 - val_accuracy: 0.8650\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5985 - accuracy: 0.8606 - val_loss: 0.3070 - val_accuracy: 0.8900\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5538 - accuracy: 0.8860 - val_loss: 0.3724 - val_accuracy: 0.8433\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5364 - accuracy: 0.8896 - val_loss: 0.4630 - val_accuracy: 0.8317\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6328 - accuracy: 0.8366 - val_loss: 0.3114 - val_accuracy: 0.8817\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.8659 - val_loss: 0.3297 - val_accuracy: 0.8817\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.4482 - accuracy: 0.5066 - val_loss: 0.6972 - val_accuracy: 0.6117\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0620 - accuracy: 0.6695 - val_loss: 0.5430 - val_accuracy: 0.7517\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9757 - accuracy: 0.7391 - val_loss: 0.5463 - val_accuracy: 0.7633\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9500 - accuracy: 0.7721 - val_loss: 0.4947 - val_accuracy: 0.8083\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9290 - accuracy: 0.7798 - val_loss: 0.6012 - val_accuracy: 0.7317\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.9620 - accuracy: 0.7568 - val_loss: 0.4980 - val_accuracy: 0.7850\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9118 - accuracy: 0.7693 - val_loss: 0.4050 - val_accuracy: 0.8467\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8949 - accuracy: 0.8058 - val_loss: 0.4750 - val_accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8555 - accuracy: 0.7923 - val_loss: 0.4904 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.7442 - accuracy: 0.8282 - val_loss: 0.4378 - val_accuracy: 0.8200\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.8084 - accuracy: 0.8059 - val_loss: 0.3746 - val_accuracy: 0.8483\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8897 - accuracy: 0.8089 - val_loss: 0.4062 - val_accuracy: 0.8383\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.8172 - accuracy: 0.8363 - val_loss: 0.3742 - val_accuracy: 0.8833\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7559 - accuracy: 0.8505 - val_loss: 0.3787 - val_accuracy: 0.8600\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.7652 - accuracy: 0.8464 - val_loss: 0.3393 - val_accuracy: 0.8950\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7721 - accuracy: 0.8498 - val_loss: 0.2981 - val_accuracy: 0.8933\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7847 - accuracy: 0.8372 - val_loss: 0.3496 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7205 - accuracy: 0.8604 - val_loss: 0.4654 - val_accuracy: 0.8067\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7403 - accuracy: 0.8428 - val_loss: 0.3186 - val_accuracy: 0.8817\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7592 - accuracy: 0.8503 - val_loss: 0.3661 - val_accuracy: 0.8617\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7447 - accuracy: 0.8513 - val_loss: 0.3320 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6435 - accuracy: 0.8461 - val_loss: 0.4141 - val_accuracy: 0.8450\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7919 - accuracy: 0.8317 - val_loss: 0.3885 - val_accuracy: 0.8383\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7403 - accuracy: 0.8640 - val_loss: 0.4513 - val_accuracy: 0.8483\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7553 - accuracy: 0.8438 - val_loss: 0.3805 - val_accuracy: 0.8550\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.6418 - accuracy: 0.8703 - val_loss: 0.3520 - val_accuracy: 0.8783\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.8728 - val_loss: 0.4242 - val_accuracy: 0.8483\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6514 - accuracy: 0.8657 - val_loss: 0.4489 - val_accuracy: 0.8483\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7599 - accuracy: 0.8421 - val_loss: 0.3361 - val_accuracy: 0.8850\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6928 - accuracy: 0.8664 - val_loss: 0.3457 - val_accuracy: 0.8850\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.8653 - val_loss: 0.5248 - val_accuracy: 0.7867\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.8399 - val_loss: 0.3183 - val_accuracy: 0.8733\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7412 - accuracy: 0.8546 - val_loss: 0.3551 - val_accuracy: 0.8783\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.8815 - val_loss: 0.4161 - val_accuracy: 0.8200\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.7258 - accuracy: 0.8319 - val_loss: 0.3884 - val_accuracy: 0.8600\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.8370 - val_loss: 0.4166 - val_accuracy: 0.8200\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4308 - accuracy: 0.5367 - val_loss: 0.5940 - val_accuracy: 0.6983\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0319 - accuracy: 0.6997 - val_loss: 0.5239 - val_accuracy: 0.7717\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9854 - accuracy: 0.7673 - val_loss: 0.4551 - val_accuracy: 0.8317\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8666 - accuracy: 0.7840 - val_loss: 0.5073 - val_accuracy: 0.7817\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8967 - accuracy: 0.7550 - val_loss: 0.4899 - val_accuracy: 0.7833\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8556 - accuracy: 0.7892 - val_loss: 0.4921 - val_accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.8623 - accuracy: 0.7948 - val_loss: 0.4571 - val_accuracy: 0.8283\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9308 - accuracy: 0.7769 - val_loss: 0.3870 - val_accuracy: 0.8617\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9053 - accuracy: 0.8025 - val_loss: 0.3351 - val_accuracy: 0.8683\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.8177 - accuracy: 0.8257 - val_loss: 0.4928 - val_accuracy: 0.8117\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8947 - accuracy: 0.7938 - val_loss: 0.4669 - val_accuracy: 0.8133\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8278 - accuracy: 0.8231 - val_loss: 0.3934 - val_accuracy: 0.8533\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.9578 - accuracy: 0.7985 - val_loss: 0.3512 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.8140 - accuracy: 0.8341 - val_loss: 0.4759 - val_accuracy: 0.8217\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.8441 - val_loss: 0.4766 - val_accuracy: 0.8100\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.8462 - val_loss: 0.4198 - val_accuracy: 0.8417\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.7449 - accuracy: 0.8405 - val_loss: 0.3518 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7424 - accuracy: 0.8459 - val_loss: 0.4320 - val_accuracy: 0.8417\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7580 - accuracy: 0.8369 - val_loss: 0.4246 - val_accuracy: 0.8217\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7504 - accuracy: 0.8428 - val_loss: 0.3510 - val_accuracy: 0.8650\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7498 - accuracy: 0.8605 - val_loss: 0.4355 - val_accuracy: 0.8433\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.8594 - val_loss: 0.3547 - val_accuracy: 0.8817\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7366 - accuracy: 0.8383 - val_loss: 0.4472 - val_accuracy: 0.8233\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7506 - accuracy: 0.8256 - val_loss: 0.3940 - val_accuracy: 0.8617\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.6790 - accuracy: 0.8676 - val_loss: 0.3530 - val_accuracy: 0.8683\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.8546 - val_loss: 0.4339 - val_accuracy: 0.8433\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.8561 - val_loss: 0.3906 - val_accuracy: 0.8633\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6985 - accuracy: 0.8590 - val_loss: 0.3389 - val_accuracy: 0.8817\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7741 - accuracy: 0.8511 - val_loss: 0.3837 - val_accuracy: 0.8500\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4860 - accuracy: 0.5356 - val_loss: 0.6022 - val_accuracy: 0.6850\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 1.0644 - accuracy: 0.6824 - val_loss: 0.5773 - val_accuracy: 0.7267\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 1.0890 - accuracy: 0.6823 - val_loss: 0.4596 - val_accuracy: 0.8017\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9117 - accuracy: 0.7736 - val_loss: 0.6750 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.9017 - accuracy: 0.7609 - val_loss: 0.5333 - val_accuracy: 0.7683\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.9362 - accuracy: 0.7642 - val_loss: 0.3708 - val_accuracy: 0.8533\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.7708 - accuracy: 0.8115 - val_loss: 0.5355 - val_accuracy: 0.7683\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.8826 - accuracy: 0.7983 - val_loss: 0.4549 - val_accuracy: 0.8233\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8377 - accuracy: 0.7990 - val_loss: 0.4308 - val_accuracy: 0.8350\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8506 - accuracy: 0.7976 - val_loss: 0.4852 - val_accuracy: 0.7883\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7833 - accuracy: 0.8197 - val_loss: 0.4332 - val_accuracy: 0.8300\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.8529 - accuracy: 0.7972 - val_loss: 0.4516 - val_accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8582 - accuracy: 0.7921 - val_loss: 0.3763 - val_accuracy: 0.8550\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9002 - accuracy: 0.8082 - val_loss: 0.3651 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8605 - accuracy: 0.8283 - val_loss: 0.4313 - val_accuracy: 0.8417\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8131 - accuracy: 0.8149 - val_loss: 0.3622 - val_accuracy: 0.8650\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8126 - accuracy: 0.8368 - val_loss: 0.4038 - val_accuracy: 0.8417\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.7111 - accuracy: 0.8476 - val_loss: 0.4348 - val_accuracy: 0.8483\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8219 - accuracy: 0.8328 - val_loss: 0.4738 - val_accuracy: 0.8367\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7625 - accuracy: 0.8249 - val_loss: 0.3988 - val_accuracy: 0.8617\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8143 - accuracy: 0.8236 - val_loss: 0.3743 - val_accuracy: 0.8533\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.8530 - val_loss: 0.3265 - val_accuracy: 0.8883\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7498 - accuracy: 0.8397 - val_loss: 0.3470 - val_accuracy: 0.8500\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.8490 - val_loss: 0.4751 - val_accuracy: 0.8183\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.8334 - val_loss: 0.3469 - val_accuracy: 0.8683\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7812 - accuracy: 0.8440 - val_loss: 0.4210 - val_accuracy: 0.8350\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.8441 - val_loss: 0.3667 - val_accuracy: 0.8533\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.7855 - accuracy: 0.8441 - val_loss: 0.3279 - val_accuracy: 0.8883\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.8611 - val_loss: 0.3357 - val_accuracy: 0.8700\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.8482 - val_loss: 0.3714 - val_accuracy: 0.8550\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7300 - accuracy: 0.8390 - val_loss: 0.3264 - val_accuracy: 0.8800\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.8517 - val_loss: 0.3588 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.8584 - val_loss: 0.4056 - val_accuracy: 0.8467\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6909 - accuracy: 0.8548 - val_loss: 0.3903 - val_accuracy: 0.8483\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7111 - accuracy: 0.8404 - val_loss: 0.3860 - val_accuracy: 0.8417\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.8675 - val_loss: 0.4735 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7006 - accuracy: 0.8367 - val_loss: 0.4804 - val_accuracy: 0.8067\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6432 - accuracy: 0.8572 - val_loss: 0.3419 - val_accuracy: 0.8817\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6647 - accuracy: 0.8666 - val_loss: 0.3986 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5884 - accuracy: 0.8766 - val_loss: 0.3781 - val_accuracy: 0.8483\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.8778 - val_loss: 0.4322 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6565 - accuracy: 0.8473 - val_loss: 0.2983 - val_accuracy: 0.8850\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.6331 - accuracy: 0.8945 - val_loss: 0.4728 - val_accuracy: 0.7900\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6480 - accuracy: 0.8533 - val_loss: 0.3856 - val_accuracy: 0.8417\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 902us/step - loss: 0.5460 - accuracy: 0.8727 - val_loss: 0.3692 - val_accuracy: 0.8567\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.8630 - val_loss: 0.3451 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.8562 - val_loss: 0.3136 - val_accuracy: 0.8950\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.5660 - accuracy: 0.8727 - val_loss: 0.3376 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.8630 - val_loss: 0.3259 - val_accuracy: 0.8733\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.8604 - val_loss: 0.4008 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.8746 - val_loss: 0.2742 - val_accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.8906 - val_loss: 0.3553 - val_accuracy: 0.8517\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.8704 - val_loss: 0.3959 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6439 - accuracy: 0.8607 - val_loss: 0.3450 - val_accuracy: 0.8567\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.8600 - val_loss: 0.4208 - val_accuracy: 0.8217\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.8551 - val_loss: 0.3342 - val_accuracy: 0.8717\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.8761 - val_loss: 0.4032 - val_accuracy: 0.8483\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.8665 - val_loss: 0.3170 - val_accuracy: 0.8800\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.8676 - val_loss: 0.2878 - val_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.8883 - val_loss: 0.4395 - val_accuracy: 0.8067\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.8438 - val_loss: 0.2746 - val_accuracy: 0.9083\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.8789 - val_loss: 0.3059 - val_accuracy: 0.8883\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.8877 - val_loss: 0.3391 - val_accuracy: 0.8717\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.8858 - val_loss: 0.4437 - val_accuracy: 0.8567\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.8707 - val_loss: 0.2975 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.8889 - val_loss: 0.2608 - val_accuracy: 0.9050\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.9015 - val_loss: 0.3829 - val_accuracy: 0.8467\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.8756 - val_loss: 0.3751 - val_accuracy: 0.8450\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.8727 - val_loss: 0.3308 - val_accuracy: 0.8817\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.8950 - val_loss: 0.3614 - val_accuracy: 0.8600\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.8681 - val_loss: 0.3677 - val_accuracy: 0.8717\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.6212 - accuracy: 0.8595 - val_loss: 0.2891 - val_accuracy: 0.9017\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.8944 - val_loss: 0.3646 - val_accuracy: 0.8517\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.9052 - val_loss: 0.3656 - val_accuracy: 0.8533\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.8768 - val_loss: 0.4327 - val_accuracy: 0.7900\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.8695 - val_loss: 0.2677 - val_accuracy: 0.8983\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.9040 - val_loss: 0.3733 - val_accuracy: 0.8483\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.8879 - val_loss: 0.4055 - val_accuracy: 0.8567\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.8649 - val_loss: 0.3141 - val_accuracy: 0.8783\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.8849 - val_loss: 0.3696 - val_accuracy: 0.8350\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.6715 - accuracy: 0.8605 - val_loss: 0.3502 - val_accuracy: 0.8683\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8879 - val_loss: 0.2701 - val_accuracy: 0.9033\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.9058 - val_loss: 0.4024 - val_accuracy: 0.8467\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.4191 - accuracy: 0.9023 - val_loss: 0.3447 - val_accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.4985 - accuracy: 0.8890 - val_loss: 0.3093 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.8841 - val_loss: 0.3951 - val_accuracy: 0.8417\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 2ms/step - loss: 1.4947 - accuracy: 0.5685 - val_loss: 0.7044 - val_accuracy: 0.5783\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.2096 - accuracy: 0.5858 - val_loss: 0.5287 - val_accuracy: 0.7800\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 862us/step - loss: 1.0394 - accuracy: 0.7260 - val_loss: 0.5108 - val_accuracy: 0.7700\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9955 - accuracy: 0.7353 - val_loss: 0.5102 - val_accuracy: 0.7600\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 976us/step - loss: 0.8470 - accuracy: 0.7755 - val_loss: 0.4327 - val_accuracy: 0.8350\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.8551 - accuracy: 0.8008 - val_loss: 0.4460 - val_accuracy: 0.8100\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.8779 - accuracy: 0.7857 - val_loss: 0.5240 - val_accuracy: 0.7467\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.8492 - accuracy: 0.7898 - val_loss: 0.5547 - val_accuracy: 0.7483\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8760 - accuracy: 0.7769 - val_loss: 0.4112 - val_accuracy: 0.8300\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8157 - accuracy: 0.8169 - val_loss: 0.5068 - val_accuracy: 0.7817\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.9407 - accuracy: 0.7920 - val_loss: 0.4364 - val_accuracy: 0.8383\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8665 - accuracy: 0.8041 - val_loss: 0.4373 - val_accuracy: 0.8267\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.8742 - accuracy: 0.8155 - val_loss: 0.3912 - val_accuracy: 0.8617\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7640 - accuracy: 0.8324 - val_loss: 0.3878 - val_accuracy: 0.8650\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7951 - accuracy: 0.8369 - val_loss: 0.4897 - val_accuracy: 0.7900\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8236 - accuracy: 0.8080 - val_loss: 0.4017 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8783 - accuracy: 0.8203 - val_loss: 0.3629 - val_accuracy: 0.8683\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8397 - accuracy: 0.8330 - val_loss: 0.4221 - val_accuracy: 0.8200\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7503 - accuracy: 0.8317 - val_loss: 0.3940 - val_accuracy: 0.8533\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.7252 - accuracy: 0.8450 - val_loss: 0.3334 - val_accuracy: 0.8900\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.7363 - accuracy: 0.8631 - val_loss: 0.4733 - val_accuracy: 0.7867\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.7396 - accuracy: 0.8431 - val_loss: 0.4469 - val_accuracy: 0.8350\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.7312 - accuracy: 0.8450 - val_loss: 0.4507 - val_accuracy: 0.8083\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.6771 - accuracy: 0.8440 - val_loss: 0.4396 - val_accuracy: 0.8450\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8011 - accuracy: 0.8282 - val_loss: 0.4303 - val_accuracy: 0.8267\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 943us/step - loss: 0.7863 - accuracy: 0.8223 - val_loss: 0.3539 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.7849 - accuracy: 0.8294 - val_loss: 0.3709 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.7385 - accuracy: 0.8488 - val_loss: 0.3724 - val_accuracy: 0.8767\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7376 - accuracy: 0.8495 - val_loss: 0.4271 - val_accuracy: 0.8267\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7023 - accuracy: 0.8476 - val_loss: 0.4095 - val_accuracy: 0.8517\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.6579 - accuracy: 0.8722 - val_loss: 0.3916 - val_accuracy: 0.8817\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.6580 - accuracy: 0.8681 - val_loss: 0.4626 - val_accuracy: 0.7800\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6688 - accuracy: 0.8737 - val_loss: 0.3598 - val_accuracy: 0.8733\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.6499 - accuracy: 0.8701 - val_loss: 0.3640 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.6113 - accuracy: 0.8730 - val_loss: 0.4071 - val_accuracy: 0.8467\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.6776 - accuracy: 0.8618 - val_loss: 0.4477 - val_accuracy: 0.8167\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.8478 - val_loss: 0.4379 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.8758 - val_loss: 0.3566 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 982us/step - loss: 0.6174 - accuracy: 0.8629 - val_loss: 0.3426 - val_accuracy: 0.8633\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6538 - accuracy: 0.8639 - val_loss: 0.3810 - val_accuracy: 0.8333\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5197 - accuracy: 0.5240 - val_loss: 0.7435 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 1.0779 - accuracy: 0.6651 - val_loss: 0.5011 - val_accuracy: 0.7867\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 1.0296 - accuracy: 0.7395 - val_loss: 0.4269 - val_accuracy: 0.8567\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 975us/step - loss: 0.9895 - accuracy: 0.7521 - val_loss: 0.4163 - val_accuracy: 0.8200\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9422 - accuracy: 0.7750 - val_loss: 0.3783 - val_accuracy: 0.8533\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.9254 - accuracy: 0.7933 - val_loss: 0.4651 - val_accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8988 - accuracy: 0.7815 - val_loss: 0.4000 - val_accuracy: 0.8533\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.7925 - accuracy: 0.8253 - val_loss: 0.5179 - val_accuracy: 0.7783\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8329 - accuracy: 0.8022 - val_loss: 0.5131 - val_accuracy: 0.7883\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8520 - accuracy: 0.8135 - val_loss: 0.4125 - val_accuracy: 0.8217\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8433 - accuracy: 0.8206 - val_loss: 0.5081 - val_accuracy: 0.7750\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8873 - accuracy: 0.7986 - val_loss: 0.4173 - val_accuracy: 0.8417\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7680 - accuracy: 0.8352 - val_loss: 0.4230 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.7779 - accuracy: 0.8425 - val_loss: 0.4205 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.8034 - accuracy: 0.8147 - val_loss: 0.3566 - val_accuracy: 0.8633\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7993 - accuracy: 0.8367 - val_loss: 0.3930 - val_accuracy: 0.8467\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 975us/step - loss: 0.7677 - accuracy: 0.8494 - val_loss: 0.4500 - val_accuracy: 0.8233\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.8342 - val_loss: 0.4212 - val_accuracy: 0.8283\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7927 - accuracy: 0.8466 - val_loss: 0.4580 - val_accuracy: 0.7967\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7062 - accuracy: 0.8519 - val_loss: 0.3877 - val_accuracy: 0.8567\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.7809 - accuracy: 0.8374 - val_loss: 0.4816 - val_accuracy: 0.7767\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7462 - accuracy: 0.8285 - val_loss: 0.4350 - val_accuracy: 0.8133\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7699 - accuracy: 0.8373 - val_loss: 0.3518 - val_accuracy: 0.8733\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.8538 - val_loss: 0.3675 - val_accuracy: 0.8617\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.7632 - accuracy: 0.8502 - val_loss: 0.3087 - val_accuracy: 0.8867\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.8550 - val_loss: 0.4610 - val_accuracy: 0.8267\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8004 - accuracy: 0.8260 - val_loss: 0.3141 - val_accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.7882 - accuracy: 0.8359 - val_loss: 0.3876 - val_accuracy: 0.8483\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.8655 - val_loss: 0.4420 - val_accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.8521 - val_loss: 0.3891 - val_accuracy: 0.8483\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.7894 - accuracy: 0.8294 - val_loss: 0.3354 - val_accuracy: 0.8800\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.6854 - accuracy: 0.8597 - val_loss: 0.3559 - val_accuracy: 0.8683\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6701 - accuracy: 0.8628 - val_loss: 0.4261 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.7452 - accuracy: 0.8437 - val_loss: 0.3149 - val_accuracy: 0.8883\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6215 - accuracy: 0.8779 - val_loss: 0.4181 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.6978 - accuracy: 0.8452 - val_loss: 0.4949 - val_accuracy: 0.8050\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6781 - accuracy: 0.8601 - val_loss: 0.4436 - val_accuracy: 0.8083\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6256 - accuracy: 0.8825 - val_loss: 0.3571 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.6690 - accuracy: 0.8706 - val_loss: 0.3181 - val_accuracy: 0.8800\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.6502 - accuracy: 0.8702 - val_loss: 0.3740 - val_accuracy: 0.8633\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.6214 - accuracy: 0.8736 - val_loss: 0.3318 - val_accuracy: 0.8800\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.5738 - accuracy: 0.8881 - val_loss: 0.3680 - val_accuracy: 0.8683\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 900us/step - loss: 0.6764 - accuracy: 0.8612 - val_loss: 0.2586 - val_accuracy: 0.9167\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6240 - accuracy: 0.8809 - val_loss: 0.3478 - val_accuracy: 0.8567\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7596 - accuracy: 0.8542 - val_loss: 0.3455 - val_accuracy: 0.8567\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6383 - accuracy: 0.8681 - val_loss: 0.3063 - val_accuracy: 0.8950\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.6785 - accuracy: 0.8705 - val_loss: 0.3207 - val_accuracy: 0.8917\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.8831 - val_loss: 0.4259 - val_accuracy: 0.8367\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.8899 - val_loss: 0.3311 - val_accuracy: 0.8850\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5511 - accuracy: 0.8911 - val_loss: 0.3779 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6023 - accuracy: 0.8635 - val_loss: 0.3412 - val_accuracy: 0.8650\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.6405 - accuracy: 0.8621 - val_loss: 0.3080 - val_accuracy: 0.8850\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5518 - accuracy: 0.8876 - val_loss: 0.4115 - val_accuracy: 0.8150\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6456 - accuracy: 0.8711 - val_loss: 0.3229 - val_accuracy: 0.8700\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.8618 - val_loss: 0.3179 - val_accuracy: 0.8917\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.5540 - accuracy: 0.8822 - val_loss: 0.4039 - val_accuracy: 0.8383\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6338 - accuracy: 0.8631 - val_loss: 0.3230 - val_accuracy: 0.8783\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.5727 - accuracy: 0.8912 - val_loss: 0.3727 - val_accuracy: 0.8400\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5200 - accuracy: 0.8881 - val_loss: 0.3474 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7521 - accuracy: 0.8614 - val_loss: 0.3246 - val_accuracy: 0.8883\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.6334 - accuracy: 0.8755 - val_loss: 0.4229 - val_accuracy: 0.8317\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 984us/step - loss: 0.4767 - accuracy: 0.8951 - val_loss: 0.4158 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.8855 - val_loss: 0.3527 - val_accuracy: 0.8600\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4433 - accuracy: 0.5259 - val_loss: 0.6969 - val_accuracy: 0.5883\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 1.0272 - accuracy: 0.6736 - val_loss: 0.5953 - val_accuracy: 0.6967\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 1.0722 - accuracy: 0.7116 - val_loss: 0.6048 - val_accuracy: 0.7100\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.9707 - accuracy: 0.7445 - val_loss: 0.4646 - val_accuracy: 0.7933\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.8278 - accuracy: 0.7994 - val_loss: 0.5291 - val_accuracy: 0.7567\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.8466 - accuracy: 0.7829 - val_loss: 0.5019 - val_accuracy: 0.7867\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8820 - accuracy: 0.8057 - val_loss: 0.4352 - val_accuracy: 0.8417\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.8237 - accuracy: 0.8164 - val_loss: 0.4530 - val_accuracy: 0.8133\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.7913 - accuracy: 0.8114 - val_loss: 0.4754 - val_accuracy: 0.8067\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.8209 - accuracy: 0.8293 - val_loss: 0.5143 - val_accuracy: 0.7633\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.8489 - accuracy: 0.8070 - val_loss: 0.3724 - val_accuracy: 0.8583\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.8090 - accuracy: 0.8353 - val_loss: 0.3699 - val_accuracy: 0.8567\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7858 - accuracy: 0.8361 - val_loss: 0.4111 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.7686 - accuracy: 0.8433 - val_loss: 0.4292 - val_accuracy: 0.8450\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 975us/step - loss: 0.8210 - accuracy: 0.8339 - val_loss: 0.4482 - val_accuracy: 0.8317\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.7693 - accuracy: 0.8379 - val_loss: 0.4402 - val_accuracy: 0.8300\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.8020 - accuracy: 0.8232 - val_loss: 0.4775 - val_accuracy: 0.8100\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.7014 - accuracy: 0.8405 - val_loss: 0.5655 - val_accuracy: 0.7483\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.7648 - accuracy: 0.8283 - val_loss: 0.4028 - val_accuracy: 0.8467\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.7503 - accuracy: 0.8503 - val_loss: 0.5425 - val_accuracy: 0.7283\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.7204 - accuracy: 0.8344 - val_loss: 0.4200 - val_accuracy: 0.8267\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7953 - accuracy: 0.8253 - val_loss: 0.3885 - val_accuracy: 0.8533\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7697 - accuracy: 0.8293 - val_loss: 0.3551 - val_accuracy: 0.8767\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7642 - accuracy: 0.8423 - val_loss: 0.3270 - val_accuracy: 0.8800\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6887 - accuracy: 0.8715 - val_loss: 0.4189 - val_accuracy: 0.8417\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.7315 - accuracy: 0.8399 - val_loss: 0.3634 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.7367 - accuracy: 0.8701 - val_loss: 0.3955 - val_accuracy: 0.8483\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.7097 - accuracy: 0.8591 - val_loss: 0.3191 - val_accuracy: 0.8833\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 972us/step - loss: 0.7494 - accuracy: 0.8615 - val_loss: 0.4502 - val_accuracy: 0.8183\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.6649 - accuracy: 0.8563 - val_loss: 0.4022 - val_accuracy: 0.8283\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7027 - accuracy: 0.8424 - val_loss: 0.3466 - val_accuracy: 0.8950\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.7148 - accuracy: 0.8622 - val_loss: 0.3795 - val_accuracy: 0.8650\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.8651 - val_loss: 0.3249 - val_accuracy: 0.8833\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.7562 - accuracy: 0.8453 - val_loss: 0.3007 - val_accuracy: 0.8900\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6312 - accuracy: 0.8824 - val_loss: 0.2976 - val_accuracy: 0.8867\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.7098 - accuracy: 0.8616 - val_loss: 0.3957 - val_accuracy: 0.8567\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7227 - accuracy: 0.8472 - val_loss: 0.2953 - val_accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6995 - accuracy: 0.8620 - val_loss: 0.3484 - val_accuracy: 0.8517\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.7443 - accuracy: 0.8345 - val_loss: 0.3692 - val_accuracy: 0.8483\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6842 - accuracy: 0.8648 - val_loss: 0.3420 - val_accuracy: 0.8683\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6674 - accuracy: 0.8508 - val_loss: 0.3681 - val_accuracy: 0.8650\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.8670 - val_loss: 0.3914 - val_accuracy: 0.8317\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.6592 - accuracy: 0.8724 - val_loss: 0.3598 - val_accuracy: 0.8433\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6970 - accuracy: 0.8505 - val_loss: 0.4289 - val_accuracy: 0.8250\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.6902 - accuracy: 0.8580 - val_loss: 0.3690 - val_accuracy: 0.8533\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.5781 - accuracy: 0.8750 - val_loss: 0.3162 - val_accuracy: 0.8800\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7086 - accuracy: 0.8567 - val_loss: 0.3689 - val_accuracy: 0.8517\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.5962 - accuracy: 0.8762 - val_loss: 0.3282 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.5664 - accuracy: 0.8846 - val_loss: 0.3311 - val_accuracy: 0.8650\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6547 - accuracy: 0.8568 - val_loss: 0.2584 - val_accuracy: 0.9133\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.6426 - accuracy: 0.8857 - val_loss: 0.3662 - val_accuracy: 0.8617\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.5862 - accuracy: 0.8683 - val_loss: 0.4347 - val_accuracy: 0.8550\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.5247 - accuracy: 0.8837 - val_loss: 0.4178 - val_accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5630 - accuracy: 0.8652 - val_loss: 0.3366 - val_accuracy: 0.8700\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5193 - accuracy: 0.8958 - val_loss: 0.3852 - val_accuracy: 0.8417\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6261 - accuracy: 0.8598 - val_loss: 0.3368 - val_accuracy: 0.8600\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.5573 - accuracy: 0.8742 - val_loss: 0.3116 - val_accuracy: 0.8783\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 982us/step - loss: 0.5581 - accuracy: 0.8951 - val_loss: 0.3810 - val_accuracy: 0.8533\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5899 - accuracy: 0.8582 - val_loss: 0.3100 - val_accuracy: 0.8783\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7531 - accuracy: 0.8599 - val_loss: 0.2697 - val_accuracy: 0.9117\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.5745 - accuracy: 0.8869 - val_loss: 0.3616 - val_accuracy: 0.8400\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.5537 - accuracy: 0.8739 - val_loss: 0.2840 - val_accuracy: 0.9067\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.6026 - accuracy: 0.8880 - val_loss: 0.2898 - val_accuracy: 0.8933\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.4941 - accuracy: 0.8891 - val_loss: 0.3103 - val_accuracy: 0.8783\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.6070 - accuracy: 0.8773 - val_loss: 0.3065 - val_accuracy: 0.8850\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 981us/step - loss: 0.6451 - accuracy: 0.8457 - val_loss: 0.3541 - val_accuracy: 0.8650\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.4903 - accuracy: 0.8893 - val_loss: 0.3297 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.8713 - val_loss: 0.3245 - val_accuracy: 0.8717\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.5658 - accuracy: 0.8795 - val_loss: 0.3385 - val_accuracy: 0.8700\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.5700 - accuracy: 0.8792 - val_loss: 0.3851 - val_accuracy: 0.8383\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4127 - accuracy: 0.5458 - val_loss: 0.6954 - val_accuracy: 0.5917\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 1.0601 - accuracy: 0.6521 - val_loss: 0.5363 - val_accuracy: 0.7533\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.9672 - accuracy: 0.7333 - val_loss: 0.5148 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 1.0215 - accuracy: 0.7332 - val_loss: 0.5014 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.9360 - accuracy: 0.7493 - val_loss: 0.5304 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 993us/step - loss: 0.9242 - accuracy: 0.7759 - val_loss: 0.5230 - val_accuracy: 0.7717\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.9759 - accuracy: 0.7641 - val_loss: 0.4075 - val_accuracy: 0.8517\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.8428 - accuracy: 0.8075 - val_loss: 0.5344 - val_accuracy: 0.7650\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.8641 - accuracy: 0.7903 - val_loss: 0.7077 - val_accuracy: 0.5417\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.9049 - accuracy: 0.7516 - val_loss: 0.3817 - val_accuracy: 0.8483\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.8394 - accuracy: 0.8279 - val_loss: 0.4729 - val_accuracy: 0.8100\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.8403 - accuracy: 0.8014 - val_loss: 0.4305 - val_accuracy: 0.8317\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7986 - accuracy: 0.8236 - val_loss: 0.4152 - val_accuracy: 0.8267\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.7807 - accuracy: 0.8300 - val_loss: 0.4353 - val_accuracy: 0.8350\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.7614 - accuracy: 0.8229 - val_loss: 0.4314 - val_accuracy: 0.8267\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.7727 - accuracy: 0.8264 - val_loss: 0.4990 - val_accuracy: 0.7800\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.7650 - accuracy: 0.8276 - val_loss: 0.5112 - val_accuracy: 0.7617\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.7939 - accuracy: 0.8013 - val_loss: 0.3754 - val_accuracy: 0.8533\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.8434 - val_loss: 0.3805 - val_accuracy: 0.8633\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7392 - accuracy: 0.8374 - val_loss: 0.4025 - val_accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.7570 - accuracy: 0.8342 - val_loss: 0.4407 - val_accuracy: 0.8267\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.6826 - accuracy: 0.8353 - val_loss: 0.3967 - val_accuracy: 0.8317\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7088 - accuracy: 0.8487 - val_loss: 0.3567 - val_accuracy: 0.8717\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6905 - accuracy: 0.8505 - val_loss: 0.4321 - val_accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.8302 - accuracy: 0.8193 - val_loss: 0.4503 - val_accuracy: 0.8267\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.7239 - accuracy: 0.8286 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.6775 - accuracy: 0.8699 - val_loss: 0.3885 - val_accuracy: 0.8267\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6440 - accuracy: 0.8676 - val_loss: 0.3996 - val_accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6996 - accuracy: 0.8558 - val_loss: 0.4254 - val_accuracy: 0.8117\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.8350 - val_loss: 0.3303 - val_accuracy: 0.8850\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 0.6529 - accuracy: 0.8696 - val_loss: 0.2710 - val_accuracy: 0.9117\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.6472 - accuracy: 0.8649 - val_loss: 0.4011 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.7066 - accuracy: 0.8697 - val_loss: 0.4291 - val_accuracy: 0.8117\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.5937 - accuracy: 0.8703 - val_loss: 0.3433 - val_accuracy: 0.8633\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6689 - accuracy: 0.8578 - val_loss: 0.4423 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.6673 - accuracy: 0.8493 - val_loss: 0.3706 - val_accuracy: 0.8483\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.6514 - accuracy: 0.8669 - val_loss: 0.3760 - val_accuracy: 0.8417\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6517 - accuracy: 0.8699 - val_loss: 0.3462 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.6413 - accuracy: 0.8480 - val_loss: 0.3967 - val_accuracy: 0.8167\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.7072 - accuracy: 0.8367 - val_loss: 0.3246 - val_accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 0.6905 - accuracy: 0.8469 - val_loss: 0.3528 - val_accuracy: 0.8583\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6340 - accuracy: 0.8597 - val_loss: 0.4212 - val_accuracy: 0.8083\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5770 - accuracy: 0.8592 - val_loss: 0.3318 - val_accuracy: 0.8533\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6081 - accuracy: 0.8622 - val_loss: 0.3704 - val_accuracy: 0.8317\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 900us/step - loss: 0.6404 - accuracy: 0.8539 - val_loss: 0.3542 - val_accuracy: 0.8450\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7231 - accuracy: 0.8355 - val_loss: 0.3316 - val_accuracy: 0.8900\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.5388 - accuracy: 0.8945 - val_loss: 0.3396 - val_accuracy: 0.8483\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.8865 - val_loss: 0.2639 - val_accuracy: 0.9067\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1000us/step - loss: 0.5903 - accuracy: 0.8861 - val_loss: 0.3143 - val_accuracy: 0.8833\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6074 - accuracy: 0.8645 - val_loss: 0.3497 - val_accuracy: 0.8733\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6815 - accuracy: 0.8709 - val_loss: 0.2966 - val_accuracy: 0.8783\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.8783 - val_loss: 0.3887 - val_accuracy: 0.8117\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.5962 - accuracy: 0.8592 - val_loss: 0.3905 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6030 - accuracy: 0.8727 - val_loss: 0.3484 - val_accuracy: 0.8567\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.5430 - accuracy: 0.8783 - val_loss: 0.3556 - val_accuracy: 0.8433\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.6297 - accuracy: 0.8568 - val_loss: 0.4915 - val_accuracy: 0.7567\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.8591 - val_loss: 0.4450 - val_accuracy: 0.7917\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 0.6253 - accuracy: 0.8560 - val_loss: 0.2852 - val_accuracy: 0.9017\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5000 - accuracy: 0.8853 - val_loss: 0.3662 - val_accuracy: 0.8433\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.5483 - accuracy: 0.8765 - val_loss: 0.2598 - val_accuracy: 0.9067\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.4602 - accuracy: 0.9130 - val_loss: 0.3783 - val_accuracy: 0.8517\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 964us/step - loss: 0.6198 - accuracy: 0.8661 - val_loss: 0.3947 - val_accuracy: 0.8167\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.6104 - accuracy: 0.8551 - val_loss: 0.2761 - val_accuracy: 0.8950\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5854 - accuracy: 0.8773 - val_loss: 0.2279 - val_accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5349 - accuracy: 0.8738 - val_loss: 0.3008 - val_accuracy: 0.8833\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.5591 - accuracy: 0.8738 - val_loss: 0.2611 - val_accuracy: 0.8950\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.5848 - accuracy: 0.8874 - val_loss: 0.2955 - val_accuracy: 0.8800\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 978us/step - loss: 0.5302 - accuracy: 0.8882 - val_loss: 0.3230 - val_accuracy: 0.8617\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.4804 - accuracy: 0.8923 - val_loss: 0.3621 - val_accuracy: 0.8567\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.5195 - accuracy: 0.8893 - val_loss: 0.3623 - val_accuracy: 0.8417\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.4946 - accuracy: 0.8911 - val_loss: 0.3341 - val_accuracy: 0.8683\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5264 - accuracy: 0.8861 - val_loss: 0.3835 - val_accuracy: 0.8267\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.5837 - accuracy: 0.8740 - val_loss: 0.3121 - val_accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.4971 - accuracy: 0.8885 - val_loss: 0.4209 - val_accuracy: 0.8483\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.5728 - accuracy: 0.8845 - val_loss: 0.3681 - val_accuracy: 0.8450\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.5092 - accuracy: 0.8794 - val_loss: 0.2553 - val_accuracy: 0.9017\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.5381 - accuracy: 0.8948 - val_loss: 0.3309 - val_accuracy: 0.8733\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5008 - accuracy: 0.8792 - val_loss: 0.4437 - val_accuracy: 0.8150\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5729 - accuracy: 0.8632 - val_loss: 0.3714 - val_accuracy: 0.8600\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 972us/step - loss: 0.4896 - accuracy: 0.8966 - val_loss: 0.3065 - val_accuracy: 0.8900\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.4812 - accuracy: 0.8862 - val_loss: 0.2777 - val_accuracy: 0.8967\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 0.6601 - accuracy: 0.8863 - val_loss: 0.2549 - val_accuracy: 0.9133\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.4721 - accuracy: 0.9080 - val_loss: 0.2957 - val_accuracy: 0.8850\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.4742 - accuracy: 0.8942 - val_loss: 0.3463 - val_accuracy: 0.8467\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4769 - accuracy: 0.5315 - val_loss: 0.5766 - val_accuracy: 0.6783\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 922us/step - loss: 1.1244 - accuracy: 0.6678 - val_loss: 0.6143 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 1.0041 - accuracy: 0.7322 - val_loss: 0.5758 - val_accuracy: 0.7100\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 1.0117 - accuracy: 0.7043 - val_loss: 0.4478 - val_accuracy: 0.8017\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.9841 - accuracy: 0.7472 - val_loss: 0.6363 - val_accuracy: 0.7067\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.9485 - accuracy: 0.7446 - val_loss: 0.4881 - val_accuracy: 0.7883\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.9077 - accuracy: 0.7808 - val_loss: 0.4016 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.9737 - accuracy: 0.7665 - val_loss: 0.4325 - val_accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 0.9608 - accuracy: 0.7748 - val_loss: 0.5018 - val_accuracy: 0.7867\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.9277 - accuracy: 0.7843 - val_loss: 0.4256 - val_accuracy: 0.8433\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8208 - accuracy: 0.8284 - val_loss: 0.5088 - val_accuracy: 0.7567\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.8078 - accuracy: 0.8019 - val_loss: 0.5532 - val_accuracy: 0.7250\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 963us/step - loss: 0.7753 - accuracy: 0.8153 - val_loss: 0.3889 - val_accuracy: 0.8483\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.7439 - accuracy: 0.8463 - val_loss: 0.4985 - val_accuracy: 0.7900\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.8324 - accuracy: 0.8018 - val_loss: 0.4313 - val_accuracy: 0.8250\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8391 - accuracy: 0.8181 - val_loss: 0.3863 - val_accuracy: 0.8400\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8176 - accuracy: 0.8340 - val_loss: 0.4115 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.9150 - accuracy: 0.7986 - val_loss: 0.4787 - val_accuracy: 0.8083\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.7094 - accuracy: 0.8336 - val_loss: 0.5284 - val_accuracy: 0.7617\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.6387 - accuracy: 0.8510 - val_loss: 0.4517 - val_accuracy: 0.8100\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7964 - accuracy: 0.8288 - val_loss: 0.3286 - val_accuracy: 0.8717\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7655 - accuracy: 0.8364 - val_loss: 0.3867 - val_accuracy: 0.8400\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.7414 - accuracy: 0.8380 - val_loss: 0.3720 - val_accuracy: 0.8483\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.7283 - accuracy: 0.8369 - val_loss: 0.4806 - val_accuracy: 0.8167\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7336 - accuracy: 0.8371 - val_loss: 0.4334 - val_accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7929 - accuracy: 0.8217 - val_loss: 0.3388 - val_accuracy: 0.8617\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.7137 - accuracy: 0.8474 - val_loss: 0.2806 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.6692 - accuracy: 0.8797 - val_loss: 0.4095 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6973 - accuracy: 0.8537 - val_loss: 0.3492 - val_accuracy: 0.8617\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7035 - accuracy: 0.8490 - val_loss: 0.4659 - val_accuracy: 0.8133\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 958us/step - loss: 0.6817 - accuracy: 0.8357 - val_loss: 0.3742 - val_accuracy: 0.8533\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 952us/step - loss: 0.6353 - accuracy: 0.8667 - val_loss: 0.4034 - val_accuracy: 0.8200\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.8419 - val_loss: 0.3840 - val_accuracy: 0.8267\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6131 - accuracy: 0.8554 - val_loss: 0.2868 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.5865 - accuracy: 0.8751 - val_loss: 0.3245 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 950us/step - loss: 0.6811 - accuracy: 0.8737 - val_loss: 0.4763 - val_accuracy: 0.8150\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 940us/step - loss: 0.6744 - accuracy: 0.8455 - val_loss: 0.3633 - val_accuracy: 0.8517\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6775 - accuracy: 0.8649 - val_loss: 0.4730 - val_accuracy: 0.7950\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.6842 - accuracy: 0.8450 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.6685 - accuracy: 0.8634 - val_loss: 0.3419 - val_accuracy: 0.8517\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.7141 - accuracy: 0.8580 - val_loss: 0.4078 - val_accuracy: 0.8200\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.6948 - accuracy: 0.8677 - val_loss: 0.3609 - val_accuracy: 0.8567\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6948 - accuracy: 0.8576 - val_loss: 0.3015 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6033 - accuracy: 0.8782 - val_loss: 0.3921 - val_accuracy: 0.8417\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.6535 - accuracy: 0.8578 - val_loss: 0.3914 - val_accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6251 - accuracy: 0.8643 - val_loss: 0.2546 - val_accuracy: 0.9117\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6372 - accuracy: 0.8741 - val_loss: 0.2950 - val_accuracy: 0.8900\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.6088 - accuracy: 0.8677 - val_loss: 0.4446 - val_accuracy: 0.8250\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.6213 - accuracy: 0.8650 - val_loss: 0.4024 - val_accuracy: 0.8183\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.7010 - accuracy: 0.8398 - val_loss: 0.3080 - val_accuracy: 0.8917\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5707 - accuracy: 0.8900 - val_loss: 0.3511 - val_accuracy: 0.8550\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.6896 - accuracy: 0.8588 - val_loss: 0.2857 - val_accuracy: 0.8883\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 996us/step - loss: 0.5750 - accuracy: 0.8725 - val_loss: 0.3087 - val_accuracy: 0.8867\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.5720 - accuracy: 0.8801 - val_loss: 0.2768 - val_accuracy: 0.9067\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 905us/step - loss: 0.6303 - accuracy: 0.8644 - val_loss: 0.3145 - val_accuracy: 0.8767\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.6140 - accuracy: 0.8784 - val_loss: 0.4329 - val_accuracy: 0.8117\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.5786 - accuracy: 0.8581 - val_loss: 0.2810 - val_accuracy: 0.8900\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 997us/step - loss: 0.5851 - accuracy: 0.8949 - val_loss: 0.3105 - val_accuracy: 0.8783\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.8848 - val_loss: 0.3831 - val_accuracy: 0.8217\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 998us/step - loss: 0.5084 - accuracy: 0.8804 - val_loss: 0.2905 - val_accuracy: 0.8883\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6471 - accuracy: 0.8825 - val_loss: 0.4294 - val_accuracy: 0.8183\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.6361 - accuracy: 0.8573 - val_loss: 0.2714 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 958us/step - loss: 0.5404 - accuracy: 0.8703 - val_loss: 0.3787 - val_accuracy: 0.8433\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.5255 - accuracy: 0.8921 - val_loss: 0.3340 - val_accuracy: 0.8733\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.5348 - accuracy: 0.8900 - val_loss: 0.3357 - val_accuracy: 0.8433\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.5440 - accuracy: 0.8778 - val_loss: 0.3439 - val_accuracy: 0.8567\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4602 - accuracy: 0.5031 - val_loss: 0.6747 - val_accuracy: 0.6467\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 1.1402 - accuracy: 0.6626 - val_loss: 0.5609 - val_accuracy: 0.7350\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.9958 - accuracy: 0.7284 - val_loss: 0.5971 - val_accuracy: 0.7100\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.9380 - accuracy: 0.7445 - val_loss: 0.5240 - val_accuracy: 0.7650\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.9101 - accuracy: 0.7695 - val_loss: 0.5628 - val_accuracy: 0.7283\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.8312 - accuracy: 0.8023 - val_loss: 0.4734 - val_accuracy: 0.8067\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.8708 - accuracy: 0.7871 - val_loss: 0.3674 - val_accuracy: 0.8367\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8054 - accuracy: 0.8209 - val_loss: 0.4871 - val_accuracy: 0.8033\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8399 - accuracy: 0.7852 - val_loss: 0.4507 - val_accuracy: 0.8283\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.8908 - accuracy: 0.8004 - val_loss: 0.3676 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.8386 - accuracy: 0.8315 - val_loss: 0.4370 - val_accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.8235 - accuracy: 0.8247 - val_loss: 0.3445 - val_accuracy: 0.8717\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.8198 - accuracy: 0.8110 - val_loss: 0.5274 - val_accuracy: 0.7850\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.8085 - accuracy: 0.7982 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9114 - accuracy: 0.8131 - val_loss: 0.3729 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.8368 - accuracy: 0.8208 - val_loss: 0.3124 - val_accuracy: 0.8867\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7377 - accuracy: 0.8447 - val_loss: 0.3557 - val_accuracy: 0.8733\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8193 - accuracy: 0.8372 - val_loss: 0.3515 - val_accuracy: 0.8633\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7816 - accuracy: 0.8473 - val_loss: 0.3852 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 859us/step - loss: 0.7673 - accuracy: 0.8508 - val_loss: 0.3652 - val_accuracy: 0.8717\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.7526 - accuracy: 0.8485 - val_loss: 0.4084 - val_accuracy: 0.8450\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8105 - accuracy: 0.8368 - val_loss: 0.3237 - val_accuracy: 0.8933\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8191 - accuracy: 0.8327 - val_loss: 0.3534 - val_accuracy: 0.8767\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7290 - accuracy: 0.8510 - val_loss: 0.3417 - val_accuracy: 0.8800\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.7037 - accuracy: 0.8565 - val_loss: 0.4331 - val_accuracy: 0.8483\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.7083 - accuracy: 0.8586 - val_loss: 0.3671 - val_accuracy: 0.8717\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7173 - accuracy: 0.8558 - val_loss: 0.3585 - val_accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6529 - accuracy: 0.8740 - val_loss: 0.4558 - val_accuracy: 0.8233\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7417 - accuracy: 0.8254 - val_loss: 0.3109 - val_accuracy: 0.8933\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6572 - accuracy: 0.8787 - val_loss: 0.3257 - val_accuracy: 0.8767\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6480 - accuracy: 0.8693 - val_loss: 0.3514 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.7596 - accuracy: 0.8493 - val_loss: 0.3699 - val_accuracy: 0.8533\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6942 - accuracy: 0.8583 - val_loss: 0.3470 - val_accuracy: 0.8700\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6839 - accuracy: 0.8465 - val_loss: 0.3372 - val_accuracy: 0.8583\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.6523 - accuracy: 0.8705 - val_loss: 0.4112 - val_accuracy: 0.8367\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.6250 - accuracy: 0.8772 - val_loss: 0.3469 - val_accuracy: 0.8617\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.6753 - accuracy: 0.8600 - val_loss: 0.4110 - val_accuracy: 0.8467\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.6092 - accuracy: 0.8584 - val_loss: 0.2913 - val_accuracy: 0.8900\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.6855 - accuracy: 0.8744 - val_loss: 0.4214 - val_accuracy: 0.8133\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.8751 - val_loss: 0.3218 - val_accuracy: 0.8783\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.6400 - accuracy: 0.8706 - val_loss: 0.3629 - val_accuracy: 0.8567\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.6162 - accuracy: 0.8565 - val_loss: 0.3620 - val_accuracy: 0.8417\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5982 - accuracy: 0.8668 - val_loss: 0.2645 - val_accuracy: 0.8967\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 796us/step - loss: 0.5916 - accuracy: 0.8709 - val_loss: 0.3938 - val_accuracy: 0.8367\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6414 - accuracy: 0.8463 - val_loss: 0.4150 - val_accuracy: 0.8067\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.6750 - accuracy: 0.8431 - val_loss: 0.3285 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.6290 - accuracy: 0.8701 - val_loss: 0.3676 - val_accuracy: 0.8583\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6468 - accuracy: 0.8650 - val_loss: 0.2994 - val_accuracy: 0.8817\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5444 - accuracy: 0.8822 - val_loss: 0.3345 - val_accuracy: 0.8517\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5939 - accuracy: 0.8677 - val_loss: 0.4215 - val_accuracy: 0.8150\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6826 - accuracy: 0.8469 - val_loss: 0.2874 - val_accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6120 - accuracy: 0.8786 - val_loss: 0.4750 - val_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5576 - accuracy: 0.8677 - val_loss: 0.3053 - val_accuracy: 0.8783\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6155 - accuracy: 0.8718 - val_loss: 0.3022 - val_accuracy: 0.8917\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5398 - accuracy: 0.8863 - val_loss: 0.3859 - val_accuracy: 0.8517\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6584 - accuracy: 0.8665 - val_loss: 0.3686 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6278 - accuracy: 0.8768 - val_loss: 0.4693 - val_accuracy: 0.7917\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.7126 - accuracy: 0.8489 - val_loss: 0.3395 - val_accuracy: 0.8567\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6080 - accuracy: 0.8744 - val_loss: 0.3145 - val_accuracy: 0.8967\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5386 - accuracy: 0.8966 - val_loss: 0.2414 - val_accuracy: 0.9300\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5361 - accuracy: 0.9028 - val_loss: 0.3693 - val_accuracy: 0.8500\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5543 - accuracy: 0.8798 - val_loss: 0.3928 - val_accuracy: 0.8300\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5477 - accuracy: 0.8760 - val_loss: 0.3031 - val_accuracy: 0.8800\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5682 - accuracy: 0.8808 - val_loss: 0.3961 - val_accuracy: 0.8550\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6205 - accuracy: 0.8665 - val_loss: 0.3232 - val_accuracy: 0.8733\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5214 - accuracy: 0.8890 - val_loss: 0.3762 - val_accuracy: 0.8617\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5553 - accuracy: 0.8733 - val_loss: 0.3813 - val_accuracy: 0.8383\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5468 - accuracy: 0.8771 - val_loss: 0.2909 - val_accuracy: 0.9033\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6641 - accuracy: 0.8780 - val_loss: 0.2567 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.4426 - accuracy: 0.9102 - val_loss: 0.2758 - val_accuracy: 0.9033\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5326 - accuracy: 0.9023 - val_loss: 0.4729 - val_accuracy: 0.7917\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5418 - accuracy: 0.8756 - val_loss: 0.2831 - val_accuracy: 0.9017\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5190 - accuracy: 0.8854 - val_loss: 0.3967 - val_accuracy: 0.8250\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.4982 - accuracy: 0.8861 - val_loss: 0.3545 - val_accuracy: 0.8700\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5090 - accuracy: 0.8848 - val_loss: 0.2800 - val_accuracy: 0.9067\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 925us/step - loss: 0.5257 - accuracy: 0.9008 - val_loss: 0.2955 - val_accuracy: 0.8867\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.4970 - accuracy: 0.8888 - val_loss: 0.2816 - val_accuracy: 0.8983\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.4307 - accuracy: 0.9111 - val_loss: 0.3396 - val_accuracy: 0.8767\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.5167 - accuracy: 0.8949 - val_loss: 0.2935 - val_accuracy: 0.8983\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5038 - accuracy: 0.9015 - val_loss: 0.2952 - val_accuracy: 0.8917\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.5408 - accuracy: 0.4759 - val_loss: 0.6604 - val_accuracy: 0.6450\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 1.0703 - accuracy: 0.6720 - val_loss: 0.5127 - val_accuracy: 0.7733\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 1.0124 - accuracy: 0.7369 - val_loss: 0.4726 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9921 - accuracy: 0.7522 - val_loss: 0.5830 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.9931 - accuracy: 0.7255 - val_loss: 0.3982 - val_accuracy: 0.8483\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8955 - accuracy: 0.7786 - val_loss: 0.4257 - val_accuracy: 0.8183\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9556 - accuracy: 0.7782 - val_loss: 0.4261 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8099 - accuracy: 0.8039 - val_loss: 0.5485 - val_accuracy: 0.7283\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8055 - accuracy: 0.7968 - val_loss: 0.4506 - val_accuracy: 0.8100\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.8134 - accuracy: 0.8084 - val_loss: 0.4715 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.8264 - accuracy: 0.7823 - val_loss: 0.5231 - val_accuracy: 0.7717\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.8895 - accuracy: 0.7709 - val_loss: 0.3757 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.8411 - accuracy: 0.8026 - val_loss: 0.4830 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.8655 - accuracy: 0.8037 - val_loss: 0.4802 - val_accuracy: 0.7817\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7962 - accuracy: 0.8106 - val_loss: 0.3544 - val_accuracy: 0.8733\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.7903 - accuracy: 0.8197 - val_loss: 0.3575 - val_accuracy: 0.8633\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 984us/step - loss: 0.8471 - accuracy: 0.8080 - val_loss: 0.3845 - val_accuracy: 0.8433\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 998us/step - loss: 0.8435 - accuracy: 0.8103 - val_loss: 0.4426 - val_accuracy: 0.8250\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.7277 - accuracy: 0.8207 - val_loss: 0.3716 - val_accuracy: 0.8533\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.7243 - accuracy: 0.8361 - val_loss: 0.4565 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8923 - accuracy: 0.7916 - val_loss: 0.3628 - val_accuracy: 0.8567\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.8306 - accuracy: 0.8141 - val_loss: 0.2880 - val_accuracy: 0.9017\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.7361 - accuracy: 0.8537 - val_loss: 0.3770 - val_accuracy: 0.8417\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.6333 - accuracy: 0.8576 - val_loss: 0.6618 - val_accuracy: 0.6633\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7952 - accuracy: 0.8030 - val_loss: 0.3779 - val_accuracy: 0.8367\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.7089 - accuracy: 0.8395 - val_loss: 0.3260 - val_accuracy: 0.8733\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.8607 - val_loss: 0.4247 - val_accuracy: 0.8117\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.8483 - val_loss: 0.5216 - val_accuracy: 0.7583\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 920us/step - loss: 0.6711 - accuracy: 0.8278 - val_loss: 0.3440 - val_accuracy: 0.8633\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.7260 - accuracy: 0.8366 - val_loss: 0.5611 - val_accuracy: 0.7283\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5991 - accuracy: 0.8647 - val_loss: 0.3454 - val_accuracy: 0.8650\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.6063 - accuracy: 0.8574 - val_loss: 0.3333 - val_accuracy: 0.8833\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.8541 - val_loss: 0.3543 - val_accuracy: 0.8733\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6430 - accuracy: 0.8646 - val_loss: 0.4201 - val_accuracy: 0.8317\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.6473 - accuracy: 0.8644 - val_loss: 0.3460 - val_accuracy: 0.8617\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.6361 - accuracy: 0.8554 - val_loss: 0.2920 - val_accuracy: 0.8683\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.7289 - accuracy: 0.8573 - val_loss: 0.3687 - val_accuracy: 0.8417\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.6590 - accuracy: 0.8629 - val_loss: 0.3944 - val_accuracy: 0.8250\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6550 - accuracy: 0.8481 - val_loss: 0.4189 - val_accuracy: 0.8383\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.8369 - val_loss: 0.4674 - val_accuracy: 0.7883\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7081 - accuracy: 0.8395 - val_loss: 0.4135 - val_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.6837 - accuracy: 0.8574 - val_loss: 0.3917 - val_accuracy: 0.8317\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4740 - accuracy: 0.5015 - val_loss: 0.5750 - val_accuracy: 0.7133\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 1.1077 - accuracy: 0.6797 - val_loss: 0.4946 - val_accuracy: 0.7750\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9136 - accuracy: 0.7618 - val_loss: 0.6161 - val_accuracy: 0.7183\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.9235 - accuracy: 0.7551 - val_loss: 0.4976 - val_accuracy: 0.8083\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9408 - accuracy: 0.7651 - val_loss: 0.5391 - val_accuracy: 0.7283\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.7887 - accuracy: 0.7994 - val_loss: 0.6003 - val_accuracy: 0.7050\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8601 - accuracy: 0.7918 - val_loss: 0.5079 - val_accuracy: 0.8133\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.8914 - accuracy: 0.8098 - val_loss: 0.4822 - val_accuracy: 0.8217\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.7853 - accuracy: 0.8251 - val_loss: 0.4126 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 972us/step - loss: 0.8144 - accuracy: 0.8239 - val_loss: 0.4863 - val_accuracy: 0.7950\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8035 - accuracy: 0.8207 - val_loss: 0.3632 - val_accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.9020 - accuracy: 0.8095 - val_loss: 0.4385 - val_accuracy: 0.8350\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8220 - accuracy: 0.8148 - val_loss: 0.4011 - val_accuracy: 0.8517\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8371 - accuracy: 0.8364 - val_loss: 0.3412 - val_accuracy: 0.8700\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7594 - accuracy: 0.8419 - val_loss: 0.4670 - val_accuracy: 0.8117\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7761 - accuracy: 0.8210 - val_loss: 0.4349 - val_accuracy: 0.8483\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7755 - accuracy: 0.8231 - val_loss: 0.4408 - val_accuracy: 0.8200\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7889 - accuracy: 0.8172 - val_loss: 0.4410 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7335 - accuracy: 0.8327 - val_loss: 0.4748 - val_accuracy: 0.8217\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 832us/step - loss: 0.7640 - accuracy: 0.8305 - val_loss: 0.3693 - val_accuracy: 0.8683\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.6856 - accuracy: 0.8671 - val_loss: 0.4984 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6961 - accuracy: 0.8329 - val_loss: 0.3694 - val_accuracy: 0.8767\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6364 - accuracy: 0.8653 - val_loss: 0.3892 - val_accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7413 - accuracy: 0.8497 - val_loss: 0.3803 - val_accuracy: 0.8483\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 855us/step - loss: 0.6839 - accuracy: 0.8750 - val_loss: 0.4223 - val_accuracy: 0.8483\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.6847 - accuracy: 0.8626 - val_loss: 0.2777 - val_accuracy: 0.8967\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.7811 - accuracy: 0.8460 - val_loss: 0.2989 - val_accuracy: 0.9067\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.8534 - val_loss: 0.3558 - val_accuracy: 0.8633\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.8109 - accuracy: 0.8212 - val_loss: 0.3700 - val_accuracy: 0.8550\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 786us/step - loss: 0.7097 - accuracy: 0.8527 - val_loss: 0.4467 - val_accuracy: 0.8383\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6843 - accuracy: 0.8519 - val_loss: 0.3967 - val_accuracy: 0.8550\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6480 - accuracy: 0.8651 - val_loss: 0.3048 - val_accuracy: 0.8917\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.6643 - accuracy: 0.8695 - val_loss: 0.4009 - val_accuracy: 0.8383\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.8629 - val_loss: 0.3927 - val_accuracy: 0.8400\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7110 - accuracy: 0.8463 - val_loss: 0.3468 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7908 - accuracy: 0.8412 - val_loss: 0.3734 - val_accuracy: 0.8700\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 868us/step - loss: 0.6420 - accuracy: 0.8857 - val_loss: 0.3494 - val_accuracy: 0.8833\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7614 - accuracy: 0.8612 - val_loss: 0.3980 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.8430 - val_loss: 0.4383 - val_accuracy: 0.8150\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 979us/step - loss: 0.5895 - accuracy: 0.8745 - val_loss: 0.3869 - val_accuracy: 0.8350\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.8785 - val_loss: 0.3342 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6576 - accuracy: 0.8666 - val_loss: 0.5155 - val_accuracy: 0.8050\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.7398 - accuracy: 0.8327 - val_loss: 0.3438 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.8456 - val_loss: 0.3804 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.8660 - val_loss: 0.3656 - val_accuracy: 0.8533\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.8420 - val_loss: 0.3092 - val_accuracy: 0.9017\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.3188 - accuracy: 0.5809 - val_loss: 0.7160 - val_accuracy: 0.6133\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 1.0354 - accuracy: 0.6854 - val_loss: 0.5346 - val_accuracy: 0.7450\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 1.0479 - accuracy: 0.7225 - val_loss: 0.5297 - val_accuracy: 0.7600\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9737 - accuracy: 0.7516 - val_loss: 0.4728 - val_accuracy: 0.8183\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.9927 - accuracy: 0.7575 - val_loss: 0.4913 - val_accuracy: 0.7883\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8804 - accuracy: 0.7835 - val_loss: 0.3723 - val_accuracy: 0.8483\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8687 - accuracy: 0.8117 - val_loss: 0.4433 - val_accuracy: 0.8283\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8040 - accuracy: 0.8122 - val_loss: 0.5295 - val_accuracy: 0.7583\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.8459 - accuracy: 0.8076 - val_loss: 0.4973 - val_accuracy: 0.7983\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.8804 - accuracy: 0.7925 - val_loss: 0.4521 - val_accuracy: 0.8300\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.7736 - accuracy: 0.8212 - val_loss: 0.5991 - val_accuracy: 0.7567\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.8167 - accuracy: 0.7913 - val_loss: 0.2904 - val_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8197 - accuracy: 0.8159 - val_loss: 0.5229 - val_accuracy: 0.7700\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 934us/step - loss: 0.7804 - accuracy: 0.8194 - val_loss: 0.3332 - val_accuracy: 0.8800\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 943us/step - loss: 0.8578 - accuracy: 0.8180 - val_loss: 0.4520 - val_accuracy: 0.8417\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 937us/step - loss: 0.7683 - accuracy: 0.8382 - val_loss: 0.3560 - val_accuracy: 0.8583\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.8461 - accuracy: 0.8247 - val_loss: 0.4746 - val_accuracy: 0.8083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.8465 - val_loss: 0.4726 - val_accuracy: 0.8317\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8453 - accuracy: 0.8134 - val_loss: 0.4645 - val_accuracy: 0.8250\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.7524 - accuracy: 0.8310 - val_loss: 0.3519 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6684 - accuracy: 0.8619 - val_loss: 0.5002 - val_accuracy: 0.7767\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.7315 - accuracy: 0.8329 - val_loss: 0.7432 - val_accuracy: 0.5783\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.8215 - accuracy: 0.8155 - val_loss: 0.3093 - val_accuracy: 0.8883\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.7471 - accuracy: 0.8519 - val_loss: 0.3841 - val_accuracy: 0.8617\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7361 - accuracy: 0.8379 - val_loss: 0.3730 - val_accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 985us/step - loss: 0.6513 - accuracy: 0.8704 - val_loss: 0.4563 - val_accuracy: 0.8100\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.8426 - val_loss: 0.4274 - val_accuracy: 0.8283\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.7037 - accuracy: 0.8489 - val_loss: 0.3707 - val_accuracy: 0.8567\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.7310 - accuracy: 0.8376 - val_loss: 0.4087 - val_accuracy: 0.8417\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7031 - accuracy: 0.8507 - val_loss: 0.2895 - val_accuracy: 0.8883\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6834 - accuracy: 0.8578 - val_loss: 0.3669 - val_accuracy: 0.8567\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.7025 - accuracy: 0.8579 - val_loss: 0.3348 - val_accuracy: 0.8817\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7120 - accuracy: 0.8545 - val_loss: 0.3670 - val_accuracy: 0.8517\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 0.7354 - accuracy: 0.8417 - val_loss: 0.4315 - val_accuracy: 0.8150\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.7149 - accuracy: 0.8438 - val_loss: 0.5733 - val_accuracy: 0.7100\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 966us/step - loss: 0.7488 - accuracy: 0.8077 - val_loss: 0.3829 - val_accuracy: 0.8517\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6879 - accuracy: 0.8543 - val_loss: 0.3335 - val_accuracy: 0.8733\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.7030 - accuracy: 0.8574 - val_loss: 0.3156 - val_accuracy: 0.8867\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.6243 - accuracy: 0.8910 - val_loss: 0.4060 - val_accuracy: 0.8300\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6033 - accuracy: 0.8653 - val_loss: 0.3732 - val_accuracy: 0.8550\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.5927 - accuracy: 0.8890 - val_loss: 0.3759 - val_accuracy: 0.8583\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6066 - accuracy: 0.8600 - val_loss: 0.3252 - val_accuracy: 0.8800\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.6054 - accuracy: 0.8673 - val_loss: 0.4010 - val_accuracy: 0.8217\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.6762 - accuracy: 0.8550 - val_loss: 0.3685 - val_accuracy: 0.8533\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5745 - accuracy: 0.8833 - val_loss: 0.3696 - val_accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 996us/step - loss: 0.5841 - accuracy: 0.8765 - val_loss: 0.3518 - val_accuracy: 0.8650\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.6595 - accuracy: 0.8630 - val_loss: 0.3910 - val_accuracy: 0.8533\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6314 - accuracy: 0.8599 - val_loss: 0.3308 - val_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6982 - accuracy: 0.8541 - val_loss: 0.3002 - val_accuracy: 0.8817\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7385 - accuracy: 0.8622 - val_loss: 0.3045 - val_accuracy: 0.8867\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3596 - accuracy: 0.5651 - val_loss: 0.7496 - val_accuracy: 0.5417\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.1572 - accuracy: 0.6214 - val_loss: 0.5335 - val_accuracy: 0.7450\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9724 - accuracy: 0.7298 - val_loss: 0.5167 - val_accuracy: 0.7700\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.9022 - accuracy: 0.7608 - val_loss: 0.4681 - val_accuracy: 0.8100\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.9468 - accuracy: 0.7806 - val_loss: 0.4461 - val_accuracy: 0.8317\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.8523 - accuracy: 0.8013 - val_loss: 0.4892 - val_accuracy: 0.7850\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.8809 - accuracy: 0.7943 - val_loss: 0.4805 - val_accuracy: 0.8250\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 899us/step - loss: 0.8086 - accuracy: 0.8100 - val_loss: 0.5808 - val_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8363 - accuracy: 0.7748 - val_loss: 0.5315 - val_accuracy: 0.7517\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.8657 - accuracy: 0.7915 - val_loss: 0.4853 - val_accuracy: 0.7767\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.8146 - accuracy: 0.8171 - val_loss: 0.4199 - val_accuracy: 0.8517\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.8840 - accuracy: 0.8167 - val_loss: 0.3927 - val_accuracy: 0.8350\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.8788 - accuracy: 0.8180 - val_loss: 0.4050 - val_accuracy: 0.8350\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7855 - accuracy: 0.8362 - val_loss: 0.4022 - val_accuracy: 0.8367\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7467 - accuracy: 0.8307 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.7209 - accuracy: 0.8284 - val_loss: 0.5404 - val_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.7971 - accuracy: 0.8114 - val_loss: 0.4175 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 999us/step - loss: 0.7337 - accuracy: 0.8528 - val_loss: 0.3817 - val_accuracy: 0.8517\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7822 - accuracy: 0.8424 - val_loss: 0.4527 - val_accuracy: 0.8300\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7869 - accuracy: 0.8374 - val_loss: 0.4028 - val_accuracy: 0.8467\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.8248 - accuracy: 0.8309 - val_loss: 0.2857 - val_accuracy: 0.9150\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.6571 - accuracy: 0.8738 - val_loss: 0.3996 - val_accuracy: 0.8367\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.6914 - accuracy: 0.8499 - val_loss: 0.4741 - val_accuracy: 0.8233\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.7496 - accuracy: 0.8291 - val_loss: 0.4387 - val_accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.6704 - accuracy: 0.8460 - val_loss: 0.3387 - val_accuracy: 0.8833\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.8728 - val_loss: 0.4537 - val_accuracy: 0.8200\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7129 - accuracy: 0.8444 - val_loss: 0.5234 - val_accuracy: 0.7383\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6490 - accuracy: 0.8557 - val_loss: 0.5035 - val_accuracy: 0.7600\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6272 - accuracy: 0.8526 - val_loss: 0.5231 - val_accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.7002 - accuracy: 0.8377 - val_loss: 0.4627 - val_accuracy: 0.8133\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.6906 - accuracy: 0.8364 - val_loss: 0.3998 - val_accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.6732 - accuracy: 0.8706 - val_loss: 0.4547 - val_accuracy: 0.8217\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6714 - accuracy: 0.8565 - val_loss: 0.4119 - val_accuracy: 0.8033\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.7249 - accuracy: 0.8362 - val_loss: 0.3235 - val_accuracy: 0.8783\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8151 - accuracy: 0.8232 - val_loss: 0.4254 - val_accuracy: 0.8350\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.8644 - val_loss: 0.4540 - val_accuracy: 0.8117\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.6083 - accuracy: 0.8615 - val_loss: 0.3724 - val_accuracy: 0.8517\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7071 - accuracy: 0.8491 - val_loss: 0.4129 - val_accuracy: 0.8283\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6820 - accuracy: 0.8414 - val_loss: 0.3605 - val_accuracy: 0.8550\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.5772 - accuracy: 0.8599 - val_loss: 0.4370 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 873us/step - loss: 0.5732 - accuracy: 0.8651 - val_loss: 0.4261 - val_accuracy: 0.8267\n",
      "11\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4564 - accuracy: 0.5718 - val_loss: 0.6977 - val_accuracy: 0.6267\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 1.1079 - accuracy: 0.6710 - val_loss: 0.6444 - val_accuracy: 0.6833\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 1.0071 - accuracy: 0.7195 - val_loss: 0.5468 - val_accuracy: 0.7483\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 1.0325 - accuracy: 0.7184 - val_loss: 0.5263 - val_accuracy: 0.7783\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.9904 - accuracy: 0.7459 - val_loss: 0.5372 - val_accuracy: 0.7817\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9172 - accuracy: 0.7847 - val_loss: 0.5625 - val_accuracy: 0.7633\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.9385 - accuracy: 0.7669 - val_loss: 0.4404 - val_accuracy: 0.8133\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 908us/step - loss: 0.9921 - accuracy: 0.7664 - val_loss: 0.4773 - val_accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8863 - accuracy: 0.7774 - val_loss: 0.3682 - val_accuracy: 0.8617\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.8929 - accuracy: 0.8181 - val_loss: 0.3960 - val_accuracy: 0.8467\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.8660 - accuracy: 0.8070 - val_loss: 0.5129 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8157 - accuracy: 0.8189 - val_loss: 0.4517 - val_accuracy: 0.8250\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9483 - accuracy: 0.7802 - val_loss: 0.3403 - val_accuracy: 0.8550\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8610 - accuracy: 0.8080 - val_loss: 0.4130 - val_accuracy: 0.8383\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.8410 - accuracy: 0.8256 - val_loss: 0.3698 - val_accuracy: 0.8567\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7762 - accuracy: 0.8382 - val_loss: 0.3224 - val_accuracy: 0.8817\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8454 - accuracy: 0.8202 - val_loss: 0.4030 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8712 - accuracy: 0.8158 - val_loss: 0.4302 - val_accuracy: 0.8200\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 919us/step - loss: 0.7335 - accuracy: 0.8329 - val_loss: 0.5127 - val_accuracy: 0.7633\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 897us/step - loss: 0.8200 - accuracy: 0.8051 - val_loss: 0.3397 - val_accuracy: 0.8717\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.8084 - accuracy: 0.8288 - val_loss: 0.3801 - val_accuracy: 0.8517\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.7768 - accuracy: 0.8264 - val_loss: 0.4157 - val_accuracy: 0.8317\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8088 - accuracy: 0.8190 - val_loss: 0.4151 - val_accuracy: 0.8383\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.6958 - accuracy: 0.8480 - val_loss: 0.3674 - val_accuracy: 0.8617\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8236 - accuracy: 0.8248 - val_loss: 0.4368 - val_accuracy: 0.8183\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.7382 - accuracy: 0.8335 - val_loss: 0.3090 - val_accuracy: 0.8717\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6984 - accuracy: 0.8468 - val_loss: 0.3394 - val_accuracy: 0.8683\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8829 - accuracy: 0.8302 - val_loss: 0.3495 - val_accuracy: 0.8600\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8203 - accuracy: 0.8351 - val_loss: 0.3753 - val_accuracy: 0.8300\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7052 - accuracy: 0.8532 - val_loss: 0.4330 - val_accuracy: 0.8100\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 894us/step - loss: 0.7256 - accuracy: 0.8640 - val_loss: 0.3497 - val_accuracy: 0.8617\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6855 - accuracy: 0.8578 - val_loss: 0.4560 - val_accuracy: 0.8083\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7088 - accuracy: 0.8443 - val_loss: 0.4486 - val_accuracy: 0.8133\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6840 - accuracy: 0.8551 - val_loss: 0.4606 - val_accuracy: 0.7817\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7412 - accuracy: 0.8533 - val_loss: 0.4038 - val_accuracy: 0.8167\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6898 - accuracy: 0.8404 - val_loss: 0.4246 - val_accuracy: 0.8150\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7363 - accuracy: 0.8333 - val_loss: 0.4047 - val_accuracy: 0.8217\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5917 - accuracy: 0.8690 - val_loss: 0.3907 - val_accuracy: 0.8283\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7365 - accuracy: 0.8393 - val_loss: 0.4625 - val_accuracy: 0.7800\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6481 - accuracy: 0.8511 - val_loss: 0.3611 - val_accuracy: 0.8633\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6330 - accuracy: 0.8660 - val_loss: 0.3404 - val_accuracy: 0.8800\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6685 - accuracy: 0.8496 - val_loss: 0.2609 - val_accuracy: 0.9067\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6787 - accuracy: 0.8548 - val_loss: 0.3128 - val_accuracy: 0.8917\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6560 - accuracy: 0.8526 - val_loss: 0.3196 - val_accuracy: 0.8850\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6096 - accuracy: 0.8754 - val_loss: 0.2770 - val_accuracy: 0.9167\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6281 - accuracy: 0.8680 - val_loss: 0.2412 - val_accuracy: 0.9183\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6453 - accuracy: 0.8631 - val_loss: 0.3819 - val_accuracy: 0.8483\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5820 - accuracy: 0.8697 - val_loss: 0.3847 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6267 - accuracy: 0.8476 - val_loss: 0.3543 - val_accuracy: 0.8400\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6683 - accuracy: 0.8448 - val_loss: 0.3114 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6407 - accuracy: 0.8607 - val_loss: 0.3530 - val_accuracy: 0.8500\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.5736 - accuracy: 0.8728 - val_loss: 0.3096 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5925 - accuracy: 0.8649 - val_loss: 0.4119 - val_accuracy: 0.8033\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6155 - accuracy: 0.8684 - val_loss: 0.3717 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5544 - accuracy: 0.8612 - val_loss: 0.2634 - val_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7291 - accuracy: 0.8630 - val_loss: 0.2405 - val_accuracy: 0.9267\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6928 - accuracy: 0.8595 - val_loss: 0.2855 - val_accuracy: 0.9033\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5614 - accuracy: 0.8689 - val_loss: 0.3696 - val_accuracy: 0.8400\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5831 - accuracy: 0.8735 - val_loss: 0.3843 - val_accuracy: 0.8233\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.6841 - accuracy: 0.8684 - val_loss: 0.2471 - val_accuracy: 0.9083\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.6115 - accuracy: 0.8797 - val_loss: 0.4033 - val_accuracy: 0.8250\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 917us/step - loss: 0.5725 - accuracy: 0.8668 - val_loss: 0.4670 - val_accuracy: 0.8017\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6184 - accuracy: 0.8561 - val_loss: 0.2780 - val_accuracy: 0.8983\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.5425 - accuracy: 0.8830 - val_loss: 0.3760 - val_accuracy: 0.8400\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6198 - accuracy: 0.8498 - val_loss: 0.3264 - val_accuracy: 0.8600\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.4945 - accuracy: 0.8853 - val_loss: 0.2238 - val_accuracy: 0.9217\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5292 - accuracy: 0.8962 - val_loss: 0.4551 - val_accuracy: 0.8300\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.5642 - accuracy: 0.8843 - val_loss: 0.3395 - val_accuracy: 0.8683\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5663 - accuracy: 0.8710 - val_loss: 0.2594 - val_accuracy: 0.9100\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6948 - accuracy: 0.8646 - val_loss: 0.3060 - val_accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6022 - accuracy: 0.8622 - val_loss: 0.3490 - val_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6194 - accuracy: 0.8781 - val_loss: 0.3277 - val_accuracy: 0.8767\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5747 - accuracy: 0.8794 - val_loss: 0.2999 - val_accuracy: 0.8900\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.4644 - accuracy: 0.9001 - val_loss: 0.3595 - val_accuracy: 0.8633\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.4920 - accuracy: 0.8856 - val_loss: 0.2623 - val_accuracy: 0.9083\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6375 - accuracy: 0.8751 - val_loss: 0.2889 - val_accuracy: 0.8917\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5384 - accuracy: 0.8919 - val_loss: 0.2612 - val_accuracy: 0.9083\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5334 - accuracy: 0.8894 - val_loss: 0.2775 - val_accuracy: 0.9083\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.4877 - accuracy: 0.8876 - val_loss: 0.3234 - val_accuracy: 0.8833\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.4351 - accuracy: 0.9017 - val_loss: 0.2880 - val_accuracy: 0.8883\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5066 - accuracy: 0.8798 - val_loss: 0.4147 - val_accuracy: 0.8383\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6231 - accuracy: 0.8815 - val_loss: 0.3486 - val_accuracy: 0.8817\n",
      "Epoch 83/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5758 - accuracy: 0.8846 - val_loss: 0.2974 - val_accuracy: 0.8883\n",
      "Epoch 84/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5300 - accuracy: 0.8953 - val_loss: 0.3127 - val_accuracy: 0.8883\n",
      "Epoch 85/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.5225 - accuracy: 0.8993 - val_loss: 0.2900 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5432 - accuracy: 0.8960 - val_loss: 0.3070 - val_accuracy: 0.8883\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5127 - accuracy: 0.5130 - val_loss: 0.7447 - val_accuracy: 0.5683\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 1.1774 - accuracy: 0.6151 - val_loss: 0.5228 - val_accuracy: 0.7633\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.9844 - accuracy: 0.7240 - val_loss: 0.5409 - val_accuracy: 0.7317\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 1.0051 - accuracy: 0.7370 - val_loss: 0.5413 - val_accuracy: 0.7683\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 1.0507 - accuracy: 0.7149 - val_loss: 0.5262 - val_accuracy: 0.7850\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0425 - accuracy: 0.7391 - val_loss: 0.4647 - val_accuracy: 0.8050\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8729 - accuracy: 0.7983 - val_loss: 0.5220 - val_accuracy: 0.7533\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.9660 - accuracy: 0.7482 - val_loss: 0.5043 - val_accuracy: 0.7850\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8649 - accuracy: 0.7881 - val_loss: 0.6266 - val_accuracy: 0.6433\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.9357 - accuracy: 0.7592 - val_loss: 0.4685 - val_accuracy: 0.8033\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8551 - accuracy: 0.7921 - val_loss: 0.4703 - val_accuracy: 0.8150\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.9188 - accuracy: 0.7877 - val_loss: 0.4352 - val_accuracy: 0.8167\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.9468 - accuracy: 0.7848 - val_loss: 0.4805 - val_accuracy: 0.8017\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 812us/step - loss: 0.8166 - accuracy: 0.8212 - val_loss: 0.5104 - val_accuracy: 0.8133\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.8648 - accuracy: 0.7992 - val_loss: 0.5261 - val_accuracy: 0.7650\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.8374 - accuracy: 0.8030 - val_loss: 0.4880 - val_accuracy: 0.7750\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.7841 - accuracy: 0.8324 - val_loss: 0.4620 - val_accuracy: 0.7850\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7420 - accuracy: 0.8193 - val_loss: 0.4938 - val_accuracy: 0.7833\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 932us/step - loss: 0.8033 - accuracy: 0.8155 - val_loss: 0.3996 - val_accuracy: 0.8283\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7928 - accuracy: 0.8313 - val_loss: 0.4920 - val_accuracy: 0.7883\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7726 - accuracy: 0.8233 - val_loss: 0.3483 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8223 - accuracy: 0.8409 - val_loss: 0.4286 - val_accuracy: 0.8300\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8990 - accuracy: 0.8045 - val_loss: 0.3599 - val_accuracy: 0.8717\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.6875 - accuracy: 0.8503 - val_loss: 0.3729 - val_accuracy: 0.8650\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7272 - accuracy: 0.8389 - val_loss: 0.3646 - val_accuracy: 0.8583\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8532 - accuracy: 0.8332 - val_loss: 0.5239 - val_accuracy: 0.7467\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7506 - accuracy: 0.8327 - val_loss: 0.3358 - val_accuracy: 0.8917\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8926 - accuracy: 0.8399 - val_loss: 0.4222 - val_accuracy: 0.8217\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7757 - accuracy: 0.8428 - val_loss: 0.4147 - val_accuracy: 0.8350\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7896 - accuracy: 0.8313 - val_loss: 0.4354 - val_accuracy: 0.8217\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7465 - accuracy: 0.8353 - val_loss: 0.4348 - val_accuracy: 0.8183\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.7596 - accuracy: 0.8202 - val_loss: 0.4574 - val_accuracy: 0.8217\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7961 - accuracy: 0.8251 - val_loss: 0.4314 - val_accuracy: 0.8367\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8327 - accuracy: 0.8242 - val_loss: 0.4135 - val_accuracy: 0.8400\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6823 - accuracy: 0.8388 - val_loss: 0.3699 - val_accuracy: 0.8633\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.7274 - accuracy: 0.8579 - val_loss: 0.5969 - val_accuracy: 0.7333\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8281 - accuracy: 0.7987 - val_loss: 0.4456 - val_accuracy: 0.8100\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7378 - accuracy: 0.8518 - val_loss: 0.2892 - val_accuracy: 0.9083\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.7081 - accuracy: 0.8650 - val_loss: 0.3633 - val_accuracy: 0.8767\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6746 - accuracy: 0.8692 - val_loss: 0.4663 - val_accuracy: 0.7967\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7760 - accuracy: 0.8428 - val_loss: 0.4257 - val_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6574 - accuracy: 0.8418 - val_loss: 0.4247 - val_accuracy: 0.8167\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7321 - accuracy: 0.8488 - val_loss: 0.4298 - val_accuracy: 0.8467\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6721 - accuracy: 0.8535 - val_loss: 0.4250 - val_accuracy: 0.8183\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.7543 - accuracy: 0.8407 - val_loss: 0.3633 - val_accuracy: 0.8617\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6436 - accuracy: 0.8537 - val_loss: 0.4394 - val_accuracy: 0.8017\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.7241 - accuracy: 0.8292 - val_loss: 0.3986 - val_accuracy: 0.8433\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7169 - accuracy: 0.8370 - val_loss: 0.4420 - val_accuracy: 0.8067\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7639 - accuracy: 0.8216 - val_loss: 0.3775 - val_accuracy: 0.8517\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6879 - accuracy: 0.8604 - val_loss: 0.4652 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 0.6536 - accuracy: 0.8353 - val_loss: 0.3963 - val_accuracy: 0.8417\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 958us/step - loss: 0.6343 - accuracy: 0.8637 - val_loss: 0.3910 - val_accuracy: 0.8300\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6863 - accuracy: 0.8540 - val_loss: 0.3981 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7794 - accuracy: 0.8507 - val_loss: 0.3766 - val_accuracy: 0.8483\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6344 - accuracy: 0.8442 - val_loss: 0.3428 - val_accuracy: 0.8567\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7693 - accuracy: 0.8535 - val_loss: 0.3727 - val_accuracy: 0.8533\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 823us/step - loss: 0.5738 - accuracy: 0.8688 - val_loss: 0.4142 - val_accuracy: 0.8417\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6438 - accuracy: 0.8594 - val_loss: 0.4122 - val_accuracy: 0.8550\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5044 - accuracy: 0.4943 - val_loss: 0.6466 - val_accuracy: 0.6650\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 1.1343 - accuracy: 0.6660 - val_loss: 0.5153 - val_accuracy: 0.7800\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 1.1513 - accuracy: 0.6918 - val_loss: 0.5847 - val_accuracy: 0.7367\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 1.1282 - accuracy: 0.6924 - val_loss: 0.4882 - val_accuracy: 0.7833\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9157 - accuracy: 0.7661 - val_loss: 0.4799 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8853 - accuracy: 0.7927 - val_loss: 0.5831 - val_accuracy: 0.7283\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8999 - accuracy: 0.7712 - val_loss: 0.4725 - val_accuracy: 0.8233\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.9228 - accuracy: 0.7764 - val_loss: 0.5711 - val_accuracy: 0.7233\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.9901 - accuracy: 0.7596 - val_loss: 0.4792 - val_accuracy: 0.8217\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8514 - accuracy: 0.8130 - val_loss: 0.5491 - val_accuracy: 0.7400\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8693 - accuracy: 0.7922 - val_loss: 0.5175 - val_accuracy: 0.8017\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8586 - accuracy: 0.8024 - val_loss: 0.4583 - val_accuracy: 0.8167\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8728 - accuracy: 0.8009 - val_loss: 0.5360 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8992 - accuracy: 0.7907 - val_loss: 0.5007 - val_accuracy: 0.8100\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8469 - accuracy: 0.7997 - val_loss: 0.4800 - val_accuracy: 0.7883\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.8005 - accuracy: 0.8192 - val_loss: 0.4919 - val_accuracy: 0.7800\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.7812 - accuracy: 0.8191 - val_loss: 0.4770 - val_accuracy: 0.7850\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7948 - accuracy: 0.8205 - val_loss: 0.4251 - val_accuracy: 0.8500\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8218 - accuracy: 0.8329 - val_loss: 0.4931 - val_accuracy: 0.7617\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7313 - accuracy: 0.8355 - val_loss: 0.5035 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.8090 - accuracy: 0.8251 - val_loss: 0.5614 - val_accuracy: 0.7617\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.7346 - accuracy: 0.8193 - val_loss: 0.3581 - val_accuracy: 0.8783\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.8400 - accuracy: 0.8273 - val_loss: 0.3941 - val_accuracy: 0.8350\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.6753 - accuracy: 0.8519 - val_loss: 0.4034 - val_accuracy: 0.8433\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.8051 - accuracy: 0.8415 - val_loss: 0.4676 - val_accuracy: 0.7950\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.8778 - accuracy: 0.8100 - val_loss: 0.4110 - val_accuracy: 0.8383\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.7598 - accuracy: 0.8333 - val_loss: 0.4838 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7640 - accuracy: 0.8239 - val_loss: 0.5059 - val_accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8303 - accuracy: 0.8149 - val_loss: 0.4087 - val_accuracy: 0.8300\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6553 - accuracy: 0.8618 - val_loss: 0.5270 - val_accuracy: 0.7633\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7212 - accuracy: 0.8237 - val_loss: 0.4051 - val_accuracy: 0.8417\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.8465 - val_loss: 0.3575 - val_accuracy: 0.8517\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7098 - accuracy: 0.8447 - val_loss: 0.3693 - val_accuracy: 0.8600\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7128 - accuracy: 0.8559 - val_loss: 0.4501 - val_accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.8547 - val_loss: 0.4301 - val_accuracy: 0.8350\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 943us/step - loss: 0.7171 - accuracy: 0.8537 - val_loss: 0.3504 - val_accuracy: 0.8533\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6615 - accuracy: 0.8598 - val_loss: 0.4551 - val_accuracy: 0.8400\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.6884 - accuracy: 0.8590 - val_loss: 0.3635 - val_accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6786 - accuracy: 0.8535 - val_loss: 0.5454 - val_accuracy: 0.7517\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6388 - accuracy: 0.8400 - val_loss: 0.4136 - val_accuracy: 0.8450\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.6133 - accuracy: 0.8644 - val_loss: 0.4269 - val_accuracy: 0.8067\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6185 - accuracy: 0.8617 - val_loss: 0.5147 - val_accuracy: 0.7850\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.7366 - accuracy: 0.8310 - val_loss: 0.4324 - val_accuracy: 0.7967\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7121 - accuracy: 0.8473 - val_loss: 0.3895 - val_accuracy: 0.8417\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7368 - accuracy: 0.8398 - val_loss: 0.4474 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5768 - accuracy: 0.8693 - val_loss: 0.3990 - val_accuracy: 0.8250\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5756 - accuracy: 0.8770 - val_loss: 0.4807 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6284 - accuracy: 0.8603 - val_loss: 0.5027 - val_accuracy: 0.7750\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6260 - accuracy: 0.8492 - val_loss: 0.3573 - val_accuracy: 0.8583\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6138 - accuracy: 0.8616 - val_loss: 0.4937 - val_accuracy: 0.8033\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.6362 - accuracy: 0.8576 - val_loss: 0.5244 - val_accuracy: 0.7633\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6211 - accuracy: 0.8302 - val_loss: 0.4452 - val_accuracy: 0.8017\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 804us/step - loss: 0.5871 - accuracy: 0.8630 - val_loss: 0.3852 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6690 - accuracy: 0.8554 - val_loss: 0.4239 - val_accuracy: 0.8483\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6253 - accuracy: 0.8589 - val_loss: 0.3757 - val_accuracy: 0.8683\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6474 - accuracy: 0.8546 - val_loss: 0.3782 - val_accuracy: 0.8467\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5022 - accuracy: 0.5232 - val_loss: 0.8437 - val_accuracy: 0.5883\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.1761 - accuracy: 0.6242 - val_loss: 0.5072 - val_accuracy: 0.7833\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 1.0655 - accuracy: 0.7181 - val_loss: 0.5693 - val_accuracy: 0.7433\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 1.0438 - accuracy: 0.7337 - val_loss: 0.5147 - val_accuracy: 0.7867\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9812 - accuracy: 0.7419 - val_loss: 0.3439 - val_accuracy: 0.8717\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9403 - accuracy: 0.7793 - val_loss: 0.5665 - val_accuracy: 0.7617\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.9054 - accuracy: 0.7970 - val_loss: 0.4315 - val_accuracy: 0.8550\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.9122 - accuracy: 0.7868 - val_loss: 0.5512 - val_accuracy: 0.7600\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.8280 - accuracy: 0.7994 - val_loss: 0.6660 - val_accuracy: 0.6650\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.8737 - accuracy: 0.7777 - val_loss: 0.4614 - val_accuracy: 0.8150\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.8863 - accuracy: 0.8164 - val_loss: 0.6429 - val_accuracy: 0.6200\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 995us/step - loss: 0.8326 - accuracy: 0.8080 - val_loss: 0.3676 - val_accuracy: 0.8650\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.8697 - accuracy: 0.8306 - val_loss: 0.4458 - val_accuracy: 0.8150\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 931us/step - loss: 0.8645 - accuracy: 0.8202 - val_loss: 0.3776 - val_accuracy: 0.8567\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.8533 - accuracy: 0.8191 - val_loss: 0.4142 - val_accuracy: 0.8517\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7851 - accuracy: 0.8416 - val_loss: 0.4156 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.7531 - accuracy: 0.8286 - val_loss: 0.4527 - val_accuracy: 0.8117\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.7848 - accuracy: 0.8370 - val_loss: 0.3516 - val_accuracy: 0.8650\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7957 - accuracy: 0.8246 - val_loss: 0.4095 - val_accuracy: 0.8317\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 944us/step - loss: 0.7635 - accuracy: 0.8264 - val_loss: 0.3635 - val_accuracy: 0.8733\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 973us/step - loss: 0.7956 - accuracy: 0.8425 - val_loss: 0.4766 - val_accuracy: 0.7833\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7939 - accuracy: 0.8217 - val_loss: 0.4171 - val_accuracy: 0.8400\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.7892 - accuracy: 0.8522 - val_loss: 0.3904 - val_accuracy: 0.8283\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.7708 - accuracy: 0.8335 - val_loss: 0.3847 - val_accuracy: 0.8550\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 990us/step - loss: 0.7929 - accuracy: 0.8362 - val_loss: 0.4177 - val_accuracy: 0.8400\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4808 - accuracy: 0.5588 - val_loss: 0.6898 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 1.2178 - accuracy: 0.6158 - val_loss: 0.5914 - val_accuracy: 0.6967\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 947us/step - loss: 1.0370 - accuracy: 0.7244 - val_loss: 0.6130 - val_accuracy: 0.7300\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 965us/step - loss: 1.0010 - accuracy: 0.7279 - val_loss: 0.4672 - val_accuracy: 0.7867\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.9258 - accuracy: 0.7628 - val_loss: 0.4002 - val_accuracy: 0.8317\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8993 - accuracy: 0.7945 - val_loss: 0.6239 - val_accuracy: 0.7133\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 941us/step - loss: 0.9447 - accuracy: 0.7579 - val_loss: 0.5321 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.9917 - accuracy: 0.7524 - val_loss: 0.4020 - val_accuracy: 0.8317\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.9153 - accuracy: 0.7901 - val_loss: 0.5337 - val_accuracy: 0.7767\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.8485 - accuracy: 0.7996 - val_loss: 0.4711 - val_accuracy: 0.8183\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 949us/step - loss: 0.8780 - accuracy: 0.8041 - val_loss: 0.5522 - val_accuracy: 0.7583\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 935us/step - loss: 0.8952 - accuracy: 0.7822 - val_loss: 0.4278 - val_accuracy: 0.8267\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 946us/step - loss: 0.8755 - accuracy: 0.8145 - val_loss: 0.4316 - val_accuracy: 0.8383\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 967us/step - loss: 0.8510 - accuracy: 0.8030 - val_loss: 0.5088 - val_accuracy: 0.7900\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.7941 - val_loss: 0.4568 - val_accuracy: 0.8083\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.8552 - accuracy: 0.8013 - val_loss: 0.4382 - val_accuracy: 0.8133\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 970us/step - loss: 0.8160 - accuracy: 0.8045 - val_loss: 0.4516 - val_accuracy: 0.8117\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7727 - accuracy: 0.8316 - val_loss: 0.5788 - val_accuracy: 0.7250\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8526 - accuracy: 0.7988 - val_loss: 0.4897 - val_accuracy: 0.7983\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8480 - accuracy: 0.8055 - val_loss: 0.4274 - val_accuracy: 0.8467\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.7700 - accuracy: 0.8545 - val_loss: 0.3790 - val_accuracy: 0.8517\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7449 - accuracy: 0.8513 - val_loss: 0.3861 - val_accuracy: 0.8567\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.8200 - accuracy: 0.8150 - val_loss: 0.3691 - val_accuracy: 0.8650\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8485 - accuracy: 0.8282 - val_loss: 0.3449 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.8116 - accuracy: 0.8271 - val_loss: 0.3640 - val_accuracy: 0.8683\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 0.7158 - accuracy: 0.8526 - val_loss: 0.4385 - val_accuracy: 0.8350\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 903us/step - loss: 0.7379 - accuracy: 0.8368 - val_loss: 0.3961 - val_accuracy: 0.8550\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7574 - accuracy: 0.8446 - val_loss: 0.4484 - val_accuracy: 0.8133\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7838 - accuracy: 0.8329 - val_loss: 0.3602 - val_accuracy: 0.8700\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6730 - accuracy: 0.8585 - val_loss: 0.3276 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 871us/step - loss: 0.7087 - accuracy: 0.8594 - val_loss: 0.4187 - val_accuracy: 0.8383\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6213 - accuracy: 0.8695 - val_loss: 0.4540 - val_accuracy: 0.8100\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6799 - accuracy: 0.8549 - val_loss: 0.3763 - val_accuracy: 0.8517\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.6435 - accuracy: 0.8739 - val_loss: 0.3103 - val_accuracy: 0.8983\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 975us/step - loss: 0.6002 - accuracy: 0.8759 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.6989 - accuracy: 0.8510 - val_loss: 0.4173 - val_accuracy: 0.8183\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6801 - accuracy: 0.8486 - val_loss: 0.4520 - val_accuracy: 0.7900\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.5997 - accuracy: 0.8764 - val_loss: 0.3952 - val_accuracy: 0.8317\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.7563 - accuracy: 0.8347 - val_loss: 0.4047 - val_accuracy: 0.8133\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6937 - accuracy: 0.8425 - val_loss: 0.3111 - val_accuracy: 0.8783\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6845 - accuracy: 0.8611 - val_loss: 0.3848 - val_accuracy: 0.8450\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6437 - accuracy: 0.8802 - val_loss: 0.3595 - val_accuracy: 0.8700\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6755 - accuracy: 0.8528 - val_loss: 0.4076 - val_accuracy: 0.8267\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7869 - accuracy: 0.8369 - val_loss: 0.3698 - val_accuracy: 0.8717\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.7100 - accuracy: 0.8536 - val_loss: 0.3516 - val_accuracy: 0.8600\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6190 - accuracy: 0.8751 - val_loss: 0.3514 - val_accuracy: 0.8617\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.7846 - accuracy: 0.8495 - val_loss: 0.3124 - val_accuracy: 0.8733\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7383 - accuracy: 0.8560 - val_loss: 0.4369 - val_accuracy: 0.8517\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 878us/step - loss: 0.7469 - accuracy: 0.8443 - val_loss: 0.4197 - val_accuracy: 0.8367\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5222 - accuracy: 0.8881 - val_loss: 0.3802 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6365 - accuracy: 0.8688 - val_loss: 0.3782 - val_accuracy: 0.8350\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6879 - accuracy: 0.8479 - val_loss: 0.3393 - val_accuracy: 0.8700\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6991 - accuracy: 0.8606 - val_loss: 0.4049 - val_accuracy: 0.8817\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6598 - accuracy: 0.8715 - val_loss: 0.4201 - val_accuracy: 0.8150\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5478 - accuracy: 0.5398 - val_loss: 0.8513 - val_accuracy: 0.4283\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 1.3252 - accuracy: 0.5318 - val_loss: 0.6823 - val_accuracy: 0.6133\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 1.1909 - accuracy: 0.6192 - val_loss: 0.5062 - val_accuracy: 0.7550\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 1.1062 - accuracy: 0.6966 - val_loss: 0.4397 - val_accuracy: 0.8150\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.9638 - accuracy: 0.7572 - val_loss: 0.5781 - val_accuracy: 0.7317\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.9709 - accuracy: 0.7419 - val_loss: 0.4563 - val_accuracy: 0.8017\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9385 - accuracy: 0.7684 - val_loss: 0.5570 - val_accuracy: 0.7683\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9347 - accuracy: 0.7605 - val_loss: 0.4856 - val_accuracy: 0.7900\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.9023 - accuracy: 0.7714 - val_loss: 0.5549 - val_accuracy: 0.7550\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.9078 - accuracy: 0.7772 - val_loss: 0.4630 - val_accuracy: 0.8167\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.8577 - accuracy: 0.8064 - val_loss: 0.4792 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.8265 - accuracy: 0.8064 - val_loss: 0.4767 - val_accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8601 - accuracy: 0.7938 - val_loss: 0.4142 - val_accuracy: 0.8367\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.8052 - accuracy: 0.8302 - val_loss: 0.5890 - val_accuracy: 0.7267\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.9089 - accuracy: 0.7930 - val_loss: 0.4525 - val_accuracy: 0.8200\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 964us/step - loss: 0.8777 - accuracy: 0.8000 - val_loss: 0.5026 - val_accuracy: 0.7750\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7961 - accuracy: 0.8120 - val_loss: 0.5195 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7541 - accuracy: 0.8297 - val_loss: 0.5191 - val_accuracy: 0.7800\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8431 - accuracy: 0.7954 - val_loss: 0.4750 - val_accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7978 - accuracy: 0.8195 - val_loss: 0.3757 - val_accuracy: 0.8533\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7801 - accuracy: 0.8234 - val_loss: 0.4981 - val_accuracy: 0.7967\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7220 - accuracy: 0.8306 - val_loss: 0.4396 - val_accuracy: 0.8350\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7692 - accuracy: 0.8257 - val_loss: 0.3994 - val_accuracy: 0.8700\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7281 - accuracy: 0.8461 - val_loss: 0.4104 - val_accuracy: 0.8450\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7930 - accuracy: 0.8183 - val_loss: 0.4010 - val_accuracy: 0.8400\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7723 - accuracy: 0.8356 - val_loss: 0.5081 - val_accuracy: 0.7667\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7125 - accuracy: 0.8378 - val_loss: 0.3882 - val_accuracy: 0.8483\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7662 - accuracy: 0.8313 - val_loss: 0.4615 - val_accuracy: 0.8200\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.7108 - accuracy: 0.8464 - val_loss: 0.4289 - val_accuracy: 0.8300\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 959us/step - loss: 0.7539 - accuracy: 0.8316 - val_loss: 0.4556 - val_accuracy: 0.8100\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.8580 - accuracy: 0.8154 - val_loss: 0.3733 - val_accuracy: 0.8583\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.7552 - accuracy: 0.8450 - val_loss: 0.3974 - val_accuracy: 0.8433\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6788 - accuracy: 0.8453 - val_loss: 0.3449 - val_accuracy: 0.8817\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6959 - accuracy: 0.8611 - val_loss: 0.4945 - val_accuracy: 0.7783\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7020 - accuracy: 0.8267 - val_loss: 0.3470 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7808 - accuracy: 0.8513 - val_loss: 0.4418 - val_accuracy: 0.8367\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7065 - accuracy: 0.8431 - val_loss: 0.2884 - val_accuracy: 0.9050\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7535 - accuracy: 0.8523 - val_loss: 0.3690 - val_accuracy: 0.8533\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7314 - accuracy: 0.8473 - val_loss: 0.3498 - val_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7307 - accuracy: 0.8427 - val_loss: 0.4412 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6887 - accuracy: 0.8589 - val_loss: 0.4043 - val_accuracy: 0.8233\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6419 - accuracy: 0.8500 - val_loss: 0.4810 - val_accuracy: 0.7800\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7277 - accuracy: 0.8269 - val_loss: 0.4114 - val_accuracy: 0.8433\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6544 - accuracy: 0.8528 - val_loss: 0.4582 - val_accuracy: 0.8250\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 829us/step - loss: 0.5875 - accuracy: 0.8560 - val_loss: 0.4293 - val_accuracy: 0.8267\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7279 - accuracy: 0.8291 - val_loss: 0.3671 - val_accuracy: 0.8650\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7048 - accuracy: 0.8429 - val_loss: 0.3485 - val_accuracy: 0.8783\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7179 - accuracy: 0.8435 - val_loss: 0.3498 - val_accuracy: 0.8533\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6723 - accuracy: 0.8546 - val_loss: 0.3196 - val_accuracy: 0.8767\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6932 - accuracy: 0.8540 - val_loss: 0.3830 - val_accuracy: 0.8367\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6912 - accuracy: 0.8500 - val_loss: 0.3506 - val_accuracy: 0.8767\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6410 - accuracy: 0.8491 - val_loss: 0.3730 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6374 - accuracy: 0.8497 - val_loss: 0.3314 - val_accuracy: 0.8700\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6607 - accuracy: 0.8644 - val_loss: 0.3047 - val_accuracy: 0.8783\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6468 - accuracy: 0.8790 - val_loss: 0.3386 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6009 - accuracy: 0.8782 - val_loss: 0.3998 - val_accuracy: 0.8433\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6747 - accuracy: 0.8574 - val_loss: 0.3242 - val_accuracy: 0.8767\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4557 - accuracy: 0.5264 - val_loss: 0.6391 - val_accuracy: 0.6467\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 1.1721 - accuracy: 0.6421 - val_loss: 0.5290 - val_accuracy: 0.7400\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 1.0309 - accuracy: 0.7253 - val_loss: 0.5879 - val_accuracy: 0.7233\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.9368 - accuracy: 0.7589 - val_loss: 0.6100 - val_accuracy: 0.6900\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 1.0008 - accuracy: 0.7262 - val_loss: 0.6207 - val_accuracy: 0.6750\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 853us/step - loss: 0.9413 - accuracy: 0.7603 - val_loss: 0.5403 - val_accuracy: 0.7650\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.9074 - accuracy: 0.7744 - val_loss: 0.4849 - val_accuracy: 0.8150\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.8854 - accuracy: 0.7930 - val_loss: 0.4665 - val_accuracy: 0.7850\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9040 - accuracy: 0.7718 - val_loss: 0.4684 - val_accuracy: 0.7917\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.9252 - accuracy: 0.7889 - val_loss: 0.4454 - val_accuracy: 0.8317\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8990 - accuracy: 0.8131 - val_loss: 0.4713 - val_accuracy: 0.7750\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8434 - accuracy: 0.8121 - val_loss: 0.4766 - val_accuracy: 0.8167\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8682 - accuracy: 0.7903 - val_loss: 0.4471 - val_accuracy: 0.8317\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8192 - accuracy: 0.7987 - val_loss: 0.3527 - val_accuracy: 0.8733\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7853 - accuracy: 0.8180 - val_loss: 0.4020 - val_accuracy: 0.8633\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.9116 - accuracy: 0.8074 - val_loss: 0.4056 - val_accuracy: 0.8317\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8288 - accuracy: 0.8166 - val_loss: 0.4513 - val_accuracy: 0.8083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7830 - accuracy: 0.7989 - val_loss: 0.4855 - val_accuracy: 0.7983\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7818 - accuracy: 0.8183 - val_loss: 0.3313 - val_accuracy: 0.8750\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7723 - accuracy: 0.8414 - val_loss: 0.4370 - val_accuracy: 0.8317\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7642 - accuracy: 0.8290 - val_loss: 0.3344 - val_accuracy: 0.8950\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.7724 - accuracy: 0.8333 - val_loss: 0.3522 - val_accuracy: 0.8817\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8499 - accuracy: 0.8122 - val_loss: 0.3530 - val_accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6714 - accuracy: 0.8449 - val_loss: 0.4334 - val_accuracy: 0.8217\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 793us/step - loss: 0.8013 - accuracy: 0.8170 - val_loss: 0.3701 - val_accuracy: 0.8717\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.7641 - accuracy: 0.8326 - val_loss: 0.5298 - val_accuracy: 0.7850\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.7133 - accuracy: 0.8331 - val_loss: 0.4133 - val_accuracy: 0.8233\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7632 - accuracy: 0.8117 - val_loss: 0.3662 - val_accuracy: 0.8450\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7441 - accuracy: 0.8230 - val_loss: 0.4234 - val_accuracy: 0.8167\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6555 - accuracy: 0.8344 - val_loss: 0.4077 - val_accuracy: 0.8200\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7191 - accuracy: 0.8252 - val_loss: 0.5377 - val_accuracy: 0.7450\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 807us/step - loss: 0.6749 - accuracy: 0.8285 - val_loss: 0.4520 - val_accuracy: 0.7900\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6617 - accuracy: 0.8472 - val_loss: 0.3433 - val_accuracy: 0.8633\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7711 - accuracy: 0.8213 - val_loss: 0.3791 - val_accuracy: 0.8517\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.6418 - accuracy: 0.8539 - val_loss: 0.4093 - val_accuracy: 0.8167\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7447 - accuracy: 0.8180 - val_loss: 0.3294 - val_accuracy: 0.8700\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6252 - accuracy: 0.8371 - val_loss: 0.3935 - val_accuracy: 0.8433\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6726 - accuracy: 0.8302 - val_loss: 0.3340 - val_accuracy: 0.8683\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.6760 - accuracy: 0.8457 - val_loss: 0.4068 - val_accuracy: 0.8100\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6292 - accuracy: 0.8435 - val_loss: 0.4242 - val_accuracy: 0.8050\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6002 - accuracy: 0.8568 - val_loss: 0.2978 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6195 - accuracy: 0.8574 - val_loss: 0.3704 - val_accuracy: 0.8467\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7209 - accuracy: 0.8537 - val_loss: 0.4054 - val_accuracy: 0.8467\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.5900 - accuracy: 0.8488 - val_loss: 0.4359 - val_accuracy: 0.8117\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6251 - accuracy: 0.8449 - val_loss: 0.3965 - val_accuracy: 0.8250\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7027 - accuracy: 0.8276 - val_loss: 0.2962 - val_accuracy: 0.8883\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5964 - accuracy: 0.8767 - val_loss: 0.3695 - val_accuracy: 0.8383\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 914us/step - loss: 0.6567 - accuracy: 0.8416 - val_loss: 0.3859 - val_accuracy: 0.8483\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5838 - accuracy: 0.8684 - val_loss: 0.3055 - val_accuracy: 0.8567\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6697 - accuracy: 0.8507 - val_loss: 0.4060 - val_accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6206 - accuracy: 0.8578 - val_loss: 0.2672 - val_accuracy: 0.8950\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6799 - accuracy: 0.8619 - val_loss: 0.3165 - val_accuracy: 0.8817\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5902 - accuracy: 0.8769 - val_loss: 0.3791 - val_accuracy: 0.8500\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.5424 - accuracy: 0.8777 - val_loss: 0.3269 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6061 - accuracy: 0.8847 - val_loss: 0.2882 - val_accuracy: 0.8850\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6220 - accuracy: 0.8508 - val_loss: 0.3259 - val_accuracy: 0.8700\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.5884 - accuracy: 0.8587 - val_loss: 0.3748 - val_accuracy: 0.8450\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 911us/step - loss: 0.6291 - accuracy: 0.8351 - val_loss: 0.3039 - val_accuracy: 0.8700\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6768 - accuracy: 0.8486 - val_loss: 0.3341 - val_accuracy: 0.8700\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6345 - accuracy: 0.8716 - val_loss: 0.4425 - val_accuracy: 0.8283\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 881us/step - loss: 0.5944 - accuracy: 0.8545 - val_loss: 0.3255 - val_accuracy: 0.8683\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.5592 - accuracy: 0.8717 - val_loss: 0.3291 - val_accuracy: 0.8783\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.6802 - accuracy: 0.8598 - val_loss: 0.2959 - val_accuracy: 0.8883\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 887us/step - loss: 0.6317 - accuracy: 0.8656 - val_loss: 0.2917 - val_accuracy: 0.8883\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5429 - accuracy: 0.8719 - val_loss: 0.3712 - val_accuracy: 0.8483\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.5805 - accuracy: 0.8678 - val_loss: 0.3770 - val_accuracy: 0.8600\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5211 - accuracy: 0.8793 - val_loss: 0.3235 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5113 - accuracy: 0.8925 - val_loss: 0.3740 - val_accuracy: 0.8350\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5520 - accuracy: 0.8667 - val_loss: 0.3445 - val_accuracy: 0.8683\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5805 - accuracy: 0.8790 - val_loss: 0.2901 - val_accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 826us/step - loss: 0.6560 - accuracy: 0.8734 - val_loss: 0.3677 - val_accuracy: 0.8533\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5458 - accuracy: 0.5246 - val_loss: 0.8617 - val_accuracy: 0.5267\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 1.2028 - accuracy: 0.6031 - val_loss: 0.5522 - val_accuracy: 0.7467\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 1.0882 - accuracy: 0.7134 - val_loss: 0.5549 - val_accuracy: 0.7367\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 1.0415 - accuracy: 0.7242 - val_loss: 0.5693 - val_accuracy: 0.7350\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 1.0064 - accuracy: 0.7480 - val_loss: 0.4342 - val_accuracy: 0.8400\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 1.0325 - accuracy: 0.7677 - val_loss: 0.5139 - val_accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9184 - accuracy: 0.7686 - val_loss: 0.3951 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9093 - accuracy: 0.8070 - val_loss: 0.5082 - val_accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8690 - accuracy: 0.8041 - val_loss: 0.5645 - val_accuracy: 0.7567\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9003 - accuracy: 0.7903 - val_loss: 0.4810 - val_accuracy: 0.8067\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.9020 - accuracy: 0.7951 - val_loss: 0.5948 - val_accuracy: 0.7117\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.9034 - accuracy: 0.7936 - val_loss: 0.4107 - val_accuracy: 0.8350\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9246 - accuracy: 0.8142 - val_loss: 0.4348 - val_accuracy: 0.8383\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.8903 - accuracy: 0.8059 - val_loss: 0.5214 - val_accuracy: 0.7817\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7972 - accuracy: 0.8232 - val_loss: 0.3574 - val_accuracy: 0.8633\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.9832 - accuracy: 0.8066 - val_loss: 0.4108 - val_accuracy: 0.8483\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.9116 - accuracy: 0.8041 - val_loss: 0.4132 - val_accuracy: 0.8550\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8170 - accuracy: 0.8401 - val_loss: 0.3930 - val_accuracy: 0.8433\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7513 - accuracy: 0.8474 - val_loss: 0.4929 - val_accuracy: 0.8217\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9358 - accuracy: 0.7881 - val_loss: 0.3872 - val_accuracy: 0.8650\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8744 - accuracy: 0.8339 - val_loss: 0.3514 - val_accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.7690 - accuracy: 0.8501 - val_loss: 0.3643 - val_accuracy: 0.8717\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7350 - accuracy: 0.8596 - val_loss: 0.4690 - val_accuracy: 0.8250\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8153 - accuracy: 0.8329 - val_loss: 0.4586 - val_accuracy: 0.8167\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7361 - accuracy: 0.8469 - val_loss: 0.4327 - val_accuracy: 0.8267\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7266 - accuracy: 0.8578 - val_loss: 0.3431 - val_accuracy: 0.8617\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7622 - accuracy: 0.8575 - val_loss: 0.3667 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7037 - accuracy: 0.8615 - val_loss: 0.4435 - val_accuracy: 0.8317\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.8126 - accuracy: 0.8359 - val_loss: 0.4432 - val_accuracy: 0.8300\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7000 - accuracy: 0.8469 - val_loss: 0.3984 - val_accuracy: 0.8617\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7402 - accuracy: 0.8582 - val_loss: 0.4477 - val_accuracy: 0.8150\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7744 - accuracy: 0.8359 - val_loss: 0.3612 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6025 - accuracy: 0.8780 - val_loss: 0.5267 - val_accuracy: 0.7617\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7145 - accuracy: 0.8512 - val_loss: 0.3548 - val_accuracy: 0.8733\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7206 - accuracy: 0.8486 - val_loss: 0.3955 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7216 - accuracy: 0.8468 - val_loss: 0.3921 - val_accuracy: 0.8383\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7338 - accuracy: 0.8511 - val_loss: 0.3225 - val_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6848 - accuracy: 0.8609 - val_loss: 0.4627 - val_accuracy: 0.8017\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6320 - accuracy: 0.8543 - val_loss: 0.3849 - val_accuracy: 0.8533\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7532 - accuracy: 0.8377 - val_loss: 0.4011 - val_accuracy: 0.8483\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.7649 - accuracy: 0.8531 - val_loss: 0.3172 - val_accuracy: 0.8867\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6113 - accuracy: 0.8850 - val_loss: 0.4848 - val_accuracy: 0.7850\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6806 - accuracy: 0.8524 - val_loss: 0.3146 - val_accuracy: 0.8800\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6578 - accuracy: 0.8644 - val_loss: 0.3140 - val_accuracy: 0.9083\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6497 - accuracy: 0.8680 - val_loss: 0.3523 - val_accuracy: 0.8467\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7222 - accuracy: 0.8425 - val_loss: 0.3769 - val_accuracy: 0.8483\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5966 - accuracy: 0.8809 - val_loss: 0.3320 - val_accuracy: 0.8733\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6695 - accuracy: 0.8608 - val_loss: 0.4277 - val_accuracy: 0.8450\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6154 - accuracy: 0.8706 - val_loss: 0.3102 - val_accuracy: 0.8767\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5992 - accuracy: 0.8759 - val_loss: 0.2979 - val_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6362 - accuracy: 0.8830 - val_loss: 0.3672 - val_accuracy: 0.8650\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6290 - accuracy: 0.8720 - val_loss: 0.3963 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7246 - accuracy: 0.8516 - val_loss: 0.3813 - val_accuracy: 0.8417\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5558 - accuracy: 0.8837 - val_loss: 0.3837 - val_accuracy: 0.8317\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6064 - accuracy: 0.8637 - val_loss: 0.4207 - val_accuracy: 0.8217\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7534 - accuracy: 0.8547 - val_loss: 0.2614 - val_accuracy: 0.8983\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6330 - accuracy: 0.8869 - val_loss: 0.4106 - val_accuracy: 0.8267\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5950 - accuracy: 0.8702 - val_loss: 0.5055 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6471 - accuracy: 0.8395 - val_loss: 0.3236 - val_accuracy: 0.8700\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5324 - accuracy: 0.8891 - val_loss: 0.2660 - val_accuracy: 0.9083\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6585 - accuracy: 0.8679 - val_loss: 0.2943 - val_accuracy: 0.8783\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5908 - accuracy: 0.8851 - val_loss: 0.4459 - val_accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6094 - accuracy: 0.8566 - val_loss: 0.4068 - val_accuracy: 0.8200\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5920 - accuracy: 0.8657 - val_loss: 0.4339 - val_accuracy: 0.8050\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5579 - accuracy: 0.8602 - val_loss: 0.3597 - val_accuracy: 0.8483\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.4837 - accuracy: 0.8879 - val_loss: 0.3933 - val_accuracy: 0.8200\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6242 - accuracy: 0.8587 - val_loss: 0.4174 - val_accuracy: 0.8217\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5278 - accuracy: 0.8909 - val_loss: 0.3159 - val_accuracy: 0.8733\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6322 - accuracy: 0.8712 - val_loss: 0.3218 - val_accuracy: 0.8717\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6009 - accuracy: 0.8838 - val_loss: 0.3484 - val_accuracy: 0.8550\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.5646 - accuracy: 0.8678 - val_loss: 0.3345 - val_accuracy: 0.8700\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.4980 - accuracy: 0.8982 - val_loss: 0.3852 - val_accuracy: 0.8433\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5241 - accuracy: 0.8833 - val_loss: 0.3577 - val_accuracy: 0.8600\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 0.5339 - accuracy: 0.8948 - val_loss: 0.2758 - val_accuracy: 0.8967\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6070 - accuracy: 0.8788 - val_loss: 0.2736 - val_accuracy: 0.8967\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6189 - accuracy: 0.8652 - val_loss: 0.3024 - val_accuracy: 0.8817\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4597 - accuracy: 0.5532 - val_loss: 0.6789 - val_accuracy: 0.6300\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 1.1804 - accuracy: 0.6256 - val_loss: 0.5120 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 1.1629 - accuracy: 0.6541 - val_loss: 0.4685 - val_accuracy: 0.7933\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 1.0197 - accuracy: 0.7235 - val_loss: 0.4743 - val_accuracy: 0.7917\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.9863 - accuracy: 0.7529 - val_loss: 0.4370 - val_accuracy: 0.7967\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8533 - accuracy: 0.7862 - val_loss: 0.5209 - val_accuracy: 0.7550\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.9464 - accuracy: 0.7696 - val_loss: 0.5062 - val_accuracy: 0.7883\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.9290 - accuracy: 0.7822 - val_loss: 0.4254 - val_accuracy: 0.8283\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.9169 - accuracy: 0.7895 - val_loss: 0.5355 - val_accuracy: 0.7683\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.9772 - accuracy: 0.7521 - val_loss: 0.4880 - val_accuracy: 0.7883\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8436 - accuracy: 0.7977 - val_loss: 0.3661 - val_accuracy: 0.8533\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.9041 - accuracy: 0.8025 - val_loss: 0.3331 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 909us/step - loss: 0.8594 - accuracy: 0.8140 - val_loss: 0.4743 - val_accuracy: 0.7950\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 984us/step - loss: 0.8623 - accuracy: 0.8102 - val_loss: 0.4661 - val_accuracy: 0.8117\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.9149 - accuracy: 0.8022 - val_loss: 0.4393 - val_accuracy: 0.8217\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.9006 - accuracy: 0.8004 - val_loss: 0.3745 - val_accuracy: 0.8467\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 815us/step - loss: 0.8123 - accuracy: 0.8250 - val_loss: 0.3979 - val_accuracy: 0.8417\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.8302 - accuracy: 0.8326 - val_loss: 0.6059 - val_accuracy: 0.6933\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8353 - accuracy: 0.7744 - val_loss: 0.4830 - val_accuracy: 0.7983\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8399 - accuracy: 0.8306 - val_loss: 0.4737 - val_accuracy: 0.8033\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 912us/step - loss: 0.8241 - accuracy: 0.8194 - val_loss: 0.4049 - val_accuracy: 0.8533\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8845 - accuracy: 0.8111 - val_loss: 0.3559 - val_accuracy: 0.8733\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7980 - accuracy: 0.8376 - val_loss: 0.4694 - val_accuracy: 0.8083\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.7396 - accuracy: 0.8428 - val_loss: 0.4595 - val_accuracy: 0.8117\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7635 - accuracy: 0.8241 - val_loss: 0.3952 - val_accuracy: 0.8583\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7320 - accuracy: 0.8284 - val_loss: 0.4511 - val_accuracy: 0.8117\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8710 - accuracy: 0.7956 - val_loss: 0.3834 - val_accuracy: 0.8517\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8222 - accuracy: 0.8238 - val_loss: 0.4068 - val_accuracy: 0.8283\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.7519 - accuracy: 0.8537 - val_loss: 0.4946 - val_accuracy: 0.7783\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7275 - accuracy: 0.8437 - val_loss: 0.4071 - val_accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7361 - accuracy: 0.8569 - val_loss: 0.4710 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7833 - accuracy: 0.8357 - val_loss: 0.4422 - val_accuracy: 0.8250\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5499 - accuracy: 0.4941 - val_loss: 0.5940 - val_accuracy: 0.7100\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 1.1153 - accuracy: 0.6580 - val_loss: 0.4915 - val_accuracy: 0.7933\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.9770 - accuracy: 0.7521 - val_loss: 0.4698 - val_accuracy: 0.8100\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.9885 - accuracy: 0.7589 - val_loss: 0.4342 - val_accuracy: 0.8300\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 850us/step - loss: 0.9327 - accuracy: 0.7775 - val_loss: 0.4132 - val_accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9170 - accuracy: 0.7796 - val_loss: 0.6715 - val_accuracy: 0.5933\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8460 - accuracy: 0.7677 - val_loss: 0.4707 - val_accuracy: 0.7967\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9551 - accuracy: 0.7629 - val_loss: 0.5002 - val_accuracy: 0.7617\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8343 - accuracy: 0.8075 - val_loss: 0.4519 - val_accuracy: 0.8267\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8481 - accuracy: 0.7972 - val_loss: 0.6076 - val_accuracy: 0.7117\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8994 - accuracy: 0.7830 - val_loss: 0.4028 - val_accuracy: 0.8433\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.8511 - accuracy: 0.8100 - val_loss: 0.4180 - val_accuracy: 0.8450\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.8501 - accuracy: 0.8160 - val_loss: 0.4996 - val_accuracy: 0.7950\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8813 - accuracy: 0.7899 - val_loss: 0.4449 - val_accuracy: 0.8300\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8382 - accuracy: 0.8206 - val_loss: 0.3270 - val_accuracy: 0.8850\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7786 - accuracy: 0.8433 - val_loss: 0.4028 - val_accuracy: 0.8433\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8434 - accuracy: 0.8166 - val_loss: 0.4366 - val_accuracy: 0.8350\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7592 - accuracy: 0.8432 - val_loss: 0.4848 - val_accuracy: 0.7767\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7535 - accuracy: 0.8446 - val_loss: 0.4082 - val_accuracy: 0.8433\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8012 - accuracy: 0.8174 - val_loss: 0.4502 - val_accuracy: 0.8217\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7615 - accuracy: 0.8300 - val_loss: 0.5311 - val_accuracy: 0.7650\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7879 - accuracy: 0.8116 - val_loss: 0.4312 - val_accuracy: 0.8183\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7496 - accuracy: 0.8243 - val_loss: 0.3471 - val_accuracy: 0.8800\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7609 - accuracy: 0.8400 - val_loss: 0.4506 - val_accuracy: 0.7800\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7967 - accuracy: 0.8151 - val_loss: 0.4336 - val_accuracy: 0.8267\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8151 - accuracy: 0.8047 - val_loss: 0.5751 - val_accuracy: 0.7400\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.7732 - accuracy: 0.8133 - val_loss: 0.3176 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7675 - accuracy: 0.8317 - val_loss: 0.4739 - val_accuracy: 0.8217\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7762 - accuracy: 0.8316 - val_loss: 0.3756 - val_accuracy: 0.8517\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8499 - accuracy: 0.8294 - val_loss: 0.2776 - val_accuracy: 0.9050\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.7730 - accuracy: 0.8441 - val_loss: 0.3642 - val_accuracy: 0.8483\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 957us/step - loss: 0.7287 - accuracy: 0.8500 - val_loss: 0.3658 - val_accuracy: 0.8617\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7216 - accuracy: 0.8602 - val_loss: 0.4855 - val_accuracy: 0.7567\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6922 - accuracy: 0.8463 - val_loss: 0.2918 - val_accuracy: 0.8983\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 991us/step - loss: 0.7658 - accuracy: 0.8527 - val_loss: 0.3318 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7069 - accuracy: 0.8435 - val_loss: 0.3998 - val_accuracy: 0.8383\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8114 - accuracy: 0.8106 - val_loss: 0.3601 - val_accuracy: 0.8433\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.8585 - val_loss: 0.4689 - val_accuracy: 0.7800\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.6483 - accuracy: 0.8468 - val_loss: 0.3249 - val_accuracy: 0.8567\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7415 - accuracy: 0.8404 - val_loss: 0.4788 - val_accuracy: 0.7950\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7329 - accuracy: 0.8293 - val_loss: 0.3687 - val_accuracy: 0.8400\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.6434 - accuracy: 0.8439 - val_loss: 0.4395 - val_accuracy: 0.7983\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 982us/step - loss: 0.6451 - accuracy: 0.8516 - val_loss: 0.3565 - val_accuracy: 0.8583\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5770 - accuracy: 0.8817 - val_loss: 0.3514 - val_accuracy: 0.8517\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6958 - accuracy: 0.8485 - val_loss: 0.4515 - val_accuracy: 0.8150\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 938us/step - loss: 0.5270 - accuracy: 0.8676 - val_loss: 0.4926 - val_accuracy: 0.7583\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.8177 - val_loss: 0.4012 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.8338 - val_loss: 0.4599 - val_accuracy: 0.7900\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6408 - accuracy: 0.8486 - val_loss: 0.3986 - val_accuracy: 0.8250\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 0.6816 - accuracy: 0.8482 - val_loss: 0.4067 - val_accuracy: 0.8350\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.6091 - accuracy: 0.5179 - val_loss: 0.8880 - val_accuracy: 0.4550\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.2060 - accuracy: 0.5987 - val_loss: 0.6037 - val_accuracy: 0.7150\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 960us/step - loss: 1.0581 - accuracy: 0.6980 - val_loss: 0.5400 - val_accuracy: 0.7583\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 916us/step - loss: 1.0589 - accuracy: 0.7151 - val_loss: 0.5620 - val_accuracy: 0.7400\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9534 - accuracy: 0.7703 - val_loss: 0.4547 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9786 - accuracy: 0.7683 - val_loss: 0.5584 - val_accuracy: 0.7750\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.9971 - accuracy: 0.7570 - val_loss: 0.4075 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8898 - accuracy: 0.8023 - val_loss: 0.5383 - val_accuracy: 0.8067\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 879us/step - loss: 0.9421 - accuracy: 0.7906 - val_loss: 0.4723 - val_accuracy: 0.8150\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8420 - accuracy: 0.8141 - val_loss: 0.4357 - val_accuracy: 0.8250\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8935 - accuracy: 0.7963 - val_loss: 0.5200 - val_accuracy: 0.7800\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8301 - accuracy: 0.8196 - val_loss: 0.4855 - val_accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.8243 - accuracy: 0.8186 - val_loss: 0.4223 - val_accuracy: 0.8367\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 968us/step - loss: 0.7736 - accuracy: 0.8422 - val_loss: 0.4618 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.8481 - accuracy: 0.8091 - val_loss: 0.4680 - val_accuracy: 0.8133\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.8114 - accuracy: 0.8256 - val_loss: 0.4947 - val_accuracy: 0.7750\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.7971 - accuracy: 0.8272 - val_loss: 0.3777 - val_accuracy: 0.8683\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7733 - accuracy: 0.8575 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8001 - accuracy: 0.8143 - val_loss: 0.3977 - val_accuracy: 0.8533\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.7494 - accuracy: 0.8523 - val_loss: 0.4697 - val_accuracy: 0.8617\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7686 - accuracy: 0.8284 - val_loss: 0.4980 - val_accuracy: 0.8100\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 955us/step - loss: 0.7292 - accuracy: 0.8393 - val_loss: 0.5117 - val_accuracy: 0.7583\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7701 - accuracy: 0.8208 - val_loss: 0.4174 - val_accuracy: 0.8283\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.8303 - val_loss: 0.5031 - val_accuracy: 0.7867\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.8613 - accuracy: 0.8179 - val_loss: 0.3659 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7004 - accuracy: 0.8469 - val_loss: 0.4712 - val_accuracy: 0.7900\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 928us/step - loss: 0.8429 - accuracy: 0.8113 - val_loss: 0.3882 - val_accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 867us/step - loss: 0.6433 - accuracy: 0.8654 - val_loss: 0.4766 - val_accuracy: 0.8050\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 929us/step - loss: 0.7210 - accuracy: 0.8313 - val_loss: 0.4194 - val_accuracy: 0.8483\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.6853 - accuracy: 0.8408 - val_loss: 0.3781 - val_accuracy: 0.8567\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 995us/step - loss: 0.7237 - accuracy: 0.8538 - val_loss: 0.4964 - val_accuracy: 0.7767\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7032 - accuracy: 0.8336 - val_loss: 0.4109 - val_accuracy: 0.8317\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6704 - accuracy: 0.8542 - val_loss: 0.4348 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.8008 - accuracy: 0.8194 - val_loss: 0.2873 - val_accuracy: 0.9133\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6979 - accuracy: 0.8752 - val_loss: 0.3503 - val_accuracy: 0.8817\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.7220 - accuracy: 0.8563 - val_loss: 0.3281 - val_accuracy: 0.8817\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 926us/step - loss: 0.6517 - accuracy: 0.8679 - val_loss: 0.4293 - val_accuracy: 0.8117\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6415 - accuracy: 0.8329 - val_loss: 0.3728 - val_accuracy: 0.8733\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6496 - accuracy: 0.8588 - val_loss: 0.3488 - val_accuracy: 0.8700\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6868 - accuracy: 0.8460 - val_loss: 0.4277 - val_accuracy: 0.8267\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6370 - accuracy: 0.8737 - val_loss: 0.3842 - val_accuracy: 0.8517\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.6530 - accuracy: 0.8648 - val_loss: 0.3640 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6426 - accuracy: 0.8510 - val_loss: 0.3772 - val_accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6917 - accuracy: 0.8456 - val_loss: 0.3887 - val_accuracy: 0.8417\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6460 - accuracy: 0.8557 - val_loss: 0.3977 - val_accuracy: 0.8450\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.7203 - accuracy: 0.8519 - val_loss: 0.3622 - val_accuracy: 0.8517\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.6769 - accuracy: 0.8657 - val_loss: 0.3079 - val_accuracy: 0.8867\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 888us/step - loss: 0.6568 - accuracy: 0.8678 - val_loss: 0.4362 - val_accuracy: 0.8317\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.8647 - val_loss: 0.3218 - val_accuracy: 0.8883\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6346 - accuracy: 0.8648 - val_loss: 0.3462 - val_accuracy: 0.8700\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6214 - accuracy: 0.8779 - val_loss: 0.3918 - val_accuracy: 0.8467\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.8535 - val_loss: 0.2474 - val_accuracy: 0.9217\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6072 - accuracy: 0.8796 - val_loss: 0.3325 - val_accuracy: 0.8550\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6633 - accuracy: 0.8709 - val_loss: 0.3332 - val_accuracy: 0.8683\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.8749 - val_loss: 0.3733 - val_accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6925 - accuracy: 0.8754 - val_loss: 0.2940 - val_accuracy: 0.8783\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8854 - val_loss: 0.4097 - val_accuracy: 0.8317\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6875 - accuracy: 0.8366 - val_loss: 0.3220 - val_accuracy: 0.8817\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.8790 - val_loss: 0.3926 - val_accuracy: 0.8367\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6896 - accuracy: 0.8560 - val_loss: 0.3222 - val_accuracy: 0.8717\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6205 - accuracy: 0.8635 - val_loss: 0.3135 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6059 - accuracy: 0.8585 - val_loss: 0.3929 - val_accuracy: 0.8550\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.5647 - accuracy: 0.8792 - val_loss: 0.3541 - val_accuracy: 0.8717\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5402 - accuracy: 0.8846 - val_loss: 0.3826 - val_accuracy: 0.8650\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5191 - accuracy: 0.8790 - val_loss: 0.4508 - val_accuracy: 0.7983\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6070 - accuracy: 0.8538 - val_loss: 0.3477 - val_accuracy: 0.8583\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5775 - accuracy: 0.8956 - val_loss: 0.4945 - val_accuracy: 0.7783\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5523 - accuracy: 0.8715 - val_loss: 0.3211 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6919 - accuracy: 0.8607 - val_loss: 0.2853 - val_accuracy: 0.9017\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.4528 - accuracy: 0.9061 - val_loss: 0.4101 - val_accuracy: 0.8117\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.6812 - accuracy: 0.8611 - val_loss: 0.3274 - val_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.5475 - accuracy: 0.8974 - val_loss: 0.4057 - val_accuracy: 0.8100\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.5177 - accuracy: 0.5184 - val_loss: 0.8487 - val_accuracy: 0.5167\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 1.2750 - accuracy: 0.5514 - val_loss: 0.6804 - val_accuracy: 0.6550\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 994us/step - loss: 1.0640 - accuracy: 0.6850 - val_loss: 0.5566 - val_accuracy: 0.7267\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0686 - accuracy: 0.7209 - val_loss: 0.5411 - val_accuracy: 0.7483\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 1.0530 - accuracy: 0.7112 - val_loss: 0.6339 - val_accuracy: 0.6900\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.9840 - accuracy: 0.7392 - val_loss: 0.5891 - val_accuracy: 0.7050\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9356 - accuracy: 0.7368 - val_loss: 0.5423 - val_accuracy: 0.7633\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.9730 - accuracy: 0.7448 - val_loss: 0.5183 - val_accuracy: 0.7350\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.8720 - accuracy: 0.7857 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 1.0241 - accuracy: 0.7272 - val_loss: 0.5124 - val_accuracy: 0.7850\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8813 - accuracy: 0.7975 - val_loss: 0.5856 - val_accuracy: 0.7417\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8876 - accuracy: 0.7817 - val_loss: 0.5397 - val_accuracy: 0.7567\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.9443 - accuracy: 0.7652 - val_loss: 0.4768 - val_accuracy: 0.8150\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8789 - accuracy: 0.7974 - val_loss: 0.4914 - val_accuracy: 0.8133\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8710 - accuracy: 0.8172 - val_loss: 0.3501 - val_accuracy: 0.8733\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8906 - accuracy: 0.8261 - val_loss: 0.5043 - val_accuracy: 0.7900\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8144 - accuracy: 0.8078 - val_loss: 0.4314 - val_accuracy: 0.8400\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.7924 - accuracy: 0.8258 - val_loss: 0.4035 - val_accuracy: 0.8550\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.7015 - accuracy: 0.8379 - val_loss: 0.4182 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7916 - accuracy: 0.8464 - val_loss: 0.4649 - val_accuracy: 0.8250\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.8092 - accuracy: 0.8356 - val_loss: 0.3630 - val_accuracy: 0.8767\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7260 - accuracy: 0.8576 - val_loss: 0.3935 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.7959 - accuracy: 0.8470 - val_loss: 0.4935 - val_accuracy: 0.8350\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7912 - accuracy: 0.8392 - val_loss: 0.4384 - val_accuracy: 0.8533\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6724 - accuracy: 0.8623 - val_loss: 0.3983 - val_accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7682 - accuracy: 0.8454 - val_loss: 0.4940 - val_accuracy: 0.8233\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7391 - accuracy: 0.8363 - val_loss: 0.3838 - val_accuracy: 0.8533\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7555 - accuracy: 0.8417 - val_loss: 0.3746 - val_accuracy: 0.8683\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7620 - accuracy: 0.8372 - val_loss: 0.4691 - val_accuracy: 0.8267\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7535 - accuracy: 0.8282 - val_loss: 0.3381 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7110 - accuracy: 0.8661 - val_loss: 0.4530 - val_accuracy: 0.8117\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.8488 - val_loss: 0.3958 - val_accuracy: 0.8483\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.8595 - val_loss: 0.4341 - val_accuracy: 0.7950\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.7916 - accuracy: 0.8386 - val_loss: 0.3675 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 977us/step - loss: 0.7244 - accuracy: 0.8696 - val_loss: 0.4039 - val_accuracy: 0.8167\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7383 - accuracy: 0.8302 - val_loss: 0.3600 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5957 - accuracy: 0.8796 - val_loss: 0.4250 - val_accuracy: 0.8517\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6678 - accuracy: 0.8571 - val_loss: 0.4395 - val_accuracy: 0.8367\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6132 - accuracy: 0.8631 - val_loss: 0.4535 - val_accuracy: 0.8067\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6912 - accuracy: 0.8561 - val_loss: 0.3319 - val_accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.8028 - accuracy: 0.8414 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7109 - accuracy: 0.8596 - val_loss: 0.3828 - val_accuracy: 0.8433\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7063 - accuracy: 0.8442 - val_loss: 0.3550 - val_accuracy: 0.8783\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 954us/step - loss: 0.6884 - accuracy: 0.8677 - val_loss: 0.3867 - val_accuracy: 0.8317\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.5786 - accuracy: 0.8780 - val_loss: 0.3184 - val_accuracy: 0.8733\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 948us/step - loss: 0.6749 - accuracy: 0.8734 - val_loss: 0.4514 - val_accuracy: 0.8283\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.7273 - accuracy: 0.8582 - val_loss: 0.3421 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6700 - accuracy: 0.8698 - val_loss: 0.3423 - val_accuracy: 0.8633\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.6377 - accuracy: 0.8675 - val_loss: 0.5180 - val_accuracy: 0.7700\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 0.6167 - accuracy: 0.8431 - val_loss: 0.3555 - val_accuracy: 0.8533\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.8753 - val_loss: 0.4351 - val_accuracy: 0.8117\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.5362 - accuracy: 0.8727 - val_loss: 0.5122 - val_accuracy: 0.7550\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.6683 - accuracy: 0.8568 - val_loss: 0.3663 - val_accuracy: 0.8517\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 987us/step - loss: 0.5901 - accuracy: 0.8657 - val_loss: 0.3701 - val_accuracy: 0.8533\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.6259 - accuracy: 0.8663 - val_loss: 0.4012 - val_accuracy: 0.8450\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5989 - accuracy: 0.8607 - val_loss: 0.3823 - val_accuracy: 0.8517\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5890 - accuracy: 0.8756 - val_loss: 0.4362 - val_accuracy: 0.8200\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6635 - accuracy: 0.8358 - val_loss: 0.3599 - val_accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6677 - accuracy: 0.8640 - val_loss: 0.4343 - val_accuracy: 0.8317\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.6204 - accuracy: 0.8734 - val_loss: 0.4768 - val_accuracy: 0.8200\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.6244 - accuracy: 0.8665 - val_loss: 0.3205 - val_accuracy: 0.8700\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.5731 - accuracy: 0.8891 - val_loss: 0.3697 - val_accuracy: 0.8483\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.8678 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.6815 - accuracy: 0.8496 - val_loss: 0.4648 - val_accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.5609 - accuracy: 0.8639 - val_loss: 0.4011 - val_accuracy: 0.8533\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 2s 1ms/step - loss: 1.5068 - accuracy: 0.5129 - val_loss: 0.8083 - val_accuracy: 0.5217\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 1.1530 - accuracy: 0.6411 - val_loss: 0.5711 - val_accuracy: 0.7317\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 1.0630 - accuracy: 0.7087 - val_loss: 0.4344 - val_accuracy: 0.8283\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9478 - accuracy: 0.7811 - val_loss: 0.5394 - val_accuracy: 0.7717\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9311 - accuracy: 0.7649 - val_loss: 0.4550 - val_accuracy: 0.8083\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.9677 - accuracy: 0.7651 - val_loss: 0.4728 - val_accuracy: 0.7983\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9074 - accuracy: 0.7738 - val_loss: 0.6041 - val_accuracy: 0.7050\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8989 - accuracy: 0.7783 - val_loss: 0.5186 - val_accuracy: 0.7683\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8980 - accuracy: 0.7974 - val_loss: 0.4748 - val_accuracy: 0.8100\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 942us/step - loss: 0.8718 - accuracy: 0.7893 - val_loss: 0.4719 - val_accuracy: 0.8017\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.9149 - accuracy: 0.7927 - val_loss: 0.4673 - val_accuracy: 0.8050\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8435 - accuracy: 0.8170 - val_loss: 0.4142 - val_accuracy: 0.8283\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.8310 - accuracy: 0.8146 - val_loss: 0.5076 - val_accuracy: 0.7817\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8265 - accuracy: 0.7975 - val_loss: 0.4213 - val_accuracy: 0.8317\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7529 - accuracy: 0.8313 - val_loss: 0.4655 - val_accuracy: 0.8217\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.9014 - accuracy: 0.7907 - val_loss: 0.4432 - val_accuracy: 0.8267\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7997 - accuracy: 0.8359 - val_loss: 0.4028 - val_accuracy: 0.8300\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8094 - accuracy: 0.8245 - val_loss: 0.3934 - val_accuracy: 0.8367\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8371 - accuracy: 0.8225 - val_loss: 0.4561 - val_accuracy: 0.8083\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7502 - accuracy: 0.8396 - val_loss: 0.4791 - val_accuracy: 0.7867\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7698 - accuracy: 0.8159 - val_loss: 0.4797 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8268 - accuracy: 0.8173 - val_loss: 0.4860 - val_accuracy: 0.7950\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7317 - accuracy: 0.8413 - val_loss: 0.3610 - val_accuracy: 0.8583\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7907 - accuracy: 0.8257 - val_loss: 0.3740 - val_accuracy: 0.8433\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9474 - accuracy: 0.7861 - val_loss: 0.4782 - val_accuracy: 0.8100\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.7569 - accuracy: 0.8308 - val_loss: 0.3636 - val_accuracy: 0.8783\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 980us/step - loss: 0.8078 - accuracy: 0.8390 - val_loss: 0.4846 - val_accuracy: 0.7767\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7454 - accuracy: 0.8316 - val_loss: 0.3340 - val_accuracy: 0.8783\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7518 - accuracy: 0.8519 - val_loss: 0.4246 - val_accuracy: 0.8283\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7946 - accuracy: 0.8423 - val_loss: 0.3270 - val_accuracy: 0.8817\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6849 - accuracy: 0.8739 - val_loss: 0.4769 - val_accuracy: 0.7900\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6875 - accuracy: 0.8469 - val_loss: 0.3651 - val_accuracy: 0.8467\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.8270 - accuracy: 0.8305 - val_loss: 0.3793 - val_accuracy: 0.8550\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6815 - accuracy: 0.8496 - val_loss: 0.3500 - val_accuracy: 0.8650\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8084 - accuracy: 0.8343 - val_loss: 0.4526 - val_accuracy: 0.8250\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6801 - accuracy: 0.8501 - val_loss: 0.4429 - val_accuracy: 0.8267\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7133 - accuracy: 0.8546 - val_loss: 0.4405 - val_accuracy: 0.8183\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 784us/step - loss: 0.7228 - accuracy: 0.8331 - val_loss: 0.5131 - val_accuracy: 0.7600\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6609 - accuracy: 0.8501 - val_loss: 0.4088 - val_accuracy: 0.8300\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7435 - accuracy: 0.8315 - val_loss: 0.4067 - val_accuracy: 0.8450\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6673 - accuracy: 0.8646 - val_loss: 0.4013 - val_accuracy: 0.8267\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6797 - accuracy: 0.8626 - val_loss: 0.4865 - val_accuracy: 0.7983\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.7421 - accuracy: 0.8507 - val_loss: 0.3251 - val_accuracy: 0.8717\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 930us/step - loss: 0.6407 - accuracy: 0.8583 - val_loss: 0.4709 - val_accuracy: 0.7983\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.6388 - accuracy: 0.8518 - val_loss: 0.3870 - val_accuracy: 0.8317\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6503 - accuracy: 0.8580 - val_loss: 0.3390 - val_accuracy: 0.8633\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7901 - accuracy: 0.8278 - val_loss: 0.4224 - val_accuracy: 0.8200\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6763 - accuracy: 0.8672 - val_loss: 0.3837 - val_accuracy: 0.8433\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6120 - accuracy: 0.8698 - val_loss: 0.4510 - val_accuracy: 0.7983\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5811 - accuracy: 0.8707 - val_loss: 0.3895 - val_accuracy: 0.8483\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6089 - accuracy: 0.8644 - val_loss: 0.5126 - val_accuracy: 0.8083\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6431 - accuracy: 0.8450 - val_loss: 0.3433 - val_accuracy: 0.8550\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6197 - accuracy: 0.8706 - val_loss: 0.3969 - val_accuracy: 0.8267\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.6646 - accuracy: 0.8549 - val_loss: 0.3279 - val_accuracy: 0.8700\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5689 - accuracy: 0.8763 - val_loss: 0.3494 - val_accuracy: 0.8533\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6494 - accuracy: 0.8648 - val_loss: 0.4936 - val_accuracy: 0.7733\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5588 - accuracy: 0.8693 - val_loss: 0.3536 - val_accuracy: 0.8583\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6111 - accuracy: 0.8662 - val_loss: 0.2792 - val_accuracy: 0.9017\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 813us/step - loss: 0.6102 - accuracy: 0.8788 - val_loss: 0.3749 - val_accuracy: 0.8483\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5872 - accuracy: 0.8677 - val_loss: 0.2517 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.5493 - accuracy: 0.8891 - val_loss: 0.3683 - val_accuracy: 0.8500\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6073 - accuracy: 0.8514 - val_loss: 0.2476 - val_accuracy: 0.9100\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6255 - accuracy: 0.8806 - val_loss: 0.2964 - val_accuracy: 0.8800\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 896us/step - loss: 0.6256 - accuracy: 0.8607 - val_loss: 0.3213 - val_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.5949 - accuracy: 0.8805 - val_loss: 0.3405 - val_accuracy: 0.8600\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6347 - accuracy: 0.8716 - val_loss: 0.3136 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6818 - accuracy: 0.8680 - val_loss: 0.3613 - val_accuracy: 0.8467\n",
      "Epoch 68/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.6466 - accuracy: 0.8516 - val_loss: 0.3234 - val_accuracy: 0.8750\n",
      "Epoch 69/100\n",
      "342/342 [==============================] - 0s 798us/step - loss: 0.6294 - accuracy: 0.8762 - val_loss: 0.3594 - val_accuracy: 0.8467\n",
      "Epoch 70/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6890 - accuracy: 0.8640 - val_loss: 0.3342 - val_accuracy: 0.8683\n",
      "Epoch 71/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6867 - accuracy: 0.8618 - val_loss: 0.3545 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.5988 - accuracy: 0.8763 - val_loss: 0.4177 - val_accuracy: 0.8183\n",
      "Epoch 73/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6258 - accuracy: 0.8708 - val_loss: 0.3481 - val_accuracy: 0.8417\n",
      "Epoch 74/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.4681 - accuracy: 0.9019 - val_loss: 0.3210 - val_accuracy: 0.8650\n",
      "Epoch 75/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5511 - accuracy: 0.8859 - val_loss: 0.3991 - val_accuracy: 0.8217\n",
      "Epoch 76/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.6049 - accuracy: 0.8652 - val_loss: 0.3562 - val_accuracy: 0.8550\n",
      "Epoch 77/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.4937 - accuracy: 0.8886 - val_loss: 0.3321 - val_accuracy: 0.8600\n",
      "Epoch 78/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.5802 - accuracy: 0.8803 - val_loss: 0.5254 - val_accuracy: 0.7683\n",
      "Epoch 79/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5893 - accuracy: 0.8550 - val_loss: 0.3180 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "342/342 [==============================] - 0s 971us/step - loss: 0.6241 - accuracy: 0.8673 - val_loss: 0.2785 - val_accuracy: 0.8883\n",
      "Epoch 81/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6137 - accuracy: 0.8756 - val_loss: 0.3059 - val_accuracy: 0.8700\n",
      "Epoch 82/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5719 - accuracy: 0.8843 - val_loss: 0.3603 - val_accuracy: 0.8567\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4987 - accuracy: 0.4982 - val_loss: 0.6974 - val_accuracy: 0.6017\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 1.1871 - accuracy: 0.6366 - val_loss: 0.5395 - val_accuracy: 0.7517\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.9968 - accuracy: 0.7427 - val_loss: 0.5104 - val_accuracy: 0.7683\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.9703 - accuracy: 0.7414 - val_loss: 0.4979 - val_accuracy: 0.8067\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 1.0127 - accuracy: 0.7290 - val_loss: 0.3914 - val_accuracy: 0.8500\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 1.0236 - accuracy: 0.7569 - val_loss: 0.4634 - val_accuracy: 0.8133\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.9218 - accuracy: 0.7871 - val_loss: 0.4602 - val_accuracy: 0.8100\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8891 - accuracy: 0.7735 - val_loss: 0.4156 - val_accuracy: 0.8383\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.9043 - accuracy: 0.7826 - val_loss: 0.5128 - val_accuracy: 0.7917\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.9079 - accuracy: 0.7747 - val_loss: 0.4986 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8246 - accuracy: 0.7903 - val_loss: 0.5540 - val_accuracy: 0.7517\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8660 - accuracy: 0.7949 - val_loss: 0.4044 - val_accuracy: 0.8467\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 962us/step - loss: 0.8442 - accuracy: 0.7918 - val_loss: 0.3648 - val_accuracy: 0.8583\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.8322 - accuracy: 0.8271 - val_loss: 0.4469 - val_accuracy: 0.8017\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8668 - accuracy: 0.8026 - val_loss: 0.5730 - val_accuracy: 0.7433\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8912 - accuracy: 0.8084 - val_loss: 0.4416 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7871 - accuracy: 0.8209 - val_loss: 0.4447 - val_accuracy: 0.8233\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7832 - accuracy: 0.8228 - val_loss: 0.4588 - val_accuracy: 0.8033\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7483 - accuracy: 0.8211 - val_loss: 0.4171 - val_accuracy: 0.8283\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8544 - accuracy: 0.7946 - val_loss: 0.4577 - val_accuracy: 0.8067\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7918 - accuracy: 0.7976 - val_loss: 0.3638 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8193 - accuracy: 0.8268 - val_loss: 0.4700 - val_accuracy: 0.8017\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7991 - accuracy: 0.8151 - val_loss: 0.4047 - val_accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7651 - accuracy: 0.8256 - val_loss: 0.3542 - val_accuracy: 0.8633\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7889 - accuracy: 0.8423 - val_loss: 0.5430 - val_accuracy: 0.7767\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8002 - accuracy: 0.8036 - val_loss: 0.4735 - val_accuracy: 0.8183\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7426 - accuracy: 0.8324 - val_loss: 0.4136 - val_accuracy: 0.8183\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 858us/step - loss: 0.7585 - accuracy: 0.8332 - val_loss: 0.3965 - val_accuracy: 0.8483\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7255 - accuracy: 0.8525 - val_loss: 0.3829 - val_accuracy: 0.8483\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6950 - accuracy: 0.8516 - val_loss: 0.4979 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7580 - accuracy: 0.8161 - val_loss: 0.3627 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7648 - accuracy: 0.8306 - val_loss: 0.4026 - val_accuracy: 0.8283\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.6442 - accuracy: 0.8472 - val_loss: 0.3873 - val_accuracy: 0.8433\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7185 - accuracy: 0.8419 - val_loss: 0.3892 - val_accuracy: 0.8367\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 915us/step - loss: 0.7713 - accuracy: 0.8323 - val_loss: 0.2826 - val_accuracy: 0.9067\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6583 - accuracy: 0.8585 - val_loss: 0.3464 - val_accuracy: 0.8617\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8042 - accuracy: 0.8334 - val_loss: 0.3463 - val_accuracy: 0.8633\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 986us/step - loss: 0.6138 - accuracy: 0.8743 - val_loss: 0.3477 - val_accuracy: 0.8817\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6603 - accuracy: 0.8582 - val_loss: 0.4591 - val_accuracy: 0.7800\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6565 - accuracy: 0.8452 - val_loss: 0.3751 - val_accuracy: 0.8400\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 936us/step - loss: 0.6832 - accuracy: 0.8683 - val_loss: 0.3126 - val_accuracy: 0.8883\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7663 - accuracy: 0.8482 - val_loss: 0.3764 - val_accuracy: 0.8567\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6515 - accuracy: 0.8715 - val_loss: 0.4460 - val_accuracy: 0.8200\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6464 - accuracy: 0.8607 - val_loss: 0.3403 - val_accuracy: 0.8583\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 885us/step - loss: 0.6579 - accuracy: 0.8715 - val_loss: 0.4001 - val_accuracy: 0.8550\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.8521 - val_loss: 0.3507 - val_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7902 - accuracy: 0.8321 - val_loss: 0.4418 - val_accuracy: 0.8050\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.8531 - val_loss: 0.5104 - val_accuracy: 0.7600\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7007 - accuracy: 0.8318 - val_loss: 0.3182 - val_accuracy: 0.8700\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6924 - accuracy: 0.8637 - val_loss: 0.2992 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6221 - accuracy: 0.8730 - val_loss: 0.3563 - val_accuracy: 0.8317\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 927us/step - loss: 0.5273 - accuracy: 0.8899 - val_loss: 0.3332 - val_accuracy: 0.8617\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 921us/step - loss: 0.6104 - accuracy: 0.8578 - val_loss: 0.4171 - val_accuracy: 0.8167\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6890 - accuracy: 0.8498 - val_loss: 0.4693 - val_accuracy: 0.8033\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6989 - accuracy: 0.8347 - val_loss: 0.3278 - val_accuracy: 0.8750\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4143 - accuracy: 0.5328 - val_loss: 0.6962 - val_accuracy: 0.6167\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 1.0657 - accuracy: 0.6976 - val_loss: 0.6673 - val_accuracy: 0.6467\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 1.0339 - accuracy: 0.6951 - val_loss: 0.5778 - val_accuracy: 0.7350\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9111 - accuracy: 0.7532 - val_loss: 0.6838 - val_accuracy: 0.6617\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 893us/step - loss: 0.9869 - accuracy: 0.7221 - val_loss: 0.4266 - val_accuracy: 0.8283\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.9829 - accuracy: 0.7794 - val_loss: 0.5199 - val_accuracy: 0.7900\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.9954 - accuracy: 0.7430 - val_loss: 0.4599 - val_accuracy: 0.8200\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.9351 - accuracy: 0.7995 - val_loss: 0.4694 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8563 - accuracy: 0.7965 - val_loss: 0.5666 - val_accuracy: 0.7167\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8392 - accuracy: 0.7957 - val_loss: 0.4825 - val_accuracy: 0.8017\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.9364 - accuracy: 0.7813 - val_loss: 0.3168 - val_accuracy: 0.8833\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.9656 - accuracy: 0.8210 - val_loss: 0.4524 - val_accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8130 - accuracy: 0.8215 - val_loss: 0.4972 - val_accuracy: 0.8033\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7749 - accuracy: 0.8457 - val_loss: 0.4866 - val_accuracy: 0.8067\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 961us/step - loss: 0.7801 - accuracy: 0.8261 - val_loss: 0.4065 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8241 - accuracy: 0.8329 - val_loss: 0.4539 - val_accuracy: 0.8183\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.8407 - accuracy: 0.8216 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8606 - accuracy: 0.8086 - val_loss: 0.3887 - val_accuracy: 0.8567\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 816us/step - loss: 0.8904 - accuracy: 0.8155 - val_loss: 0.4145 - val_accuracy: 0.8483\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.9043 - accuracy: 0.8139 - val_loss: 0.3428 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7041 - accuracy: 0.8518 - val_loss: 0.3604 - val_accuracy: 0.8700\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7393 - accuracy: 0.8596 - val_loss: 0.3624 - val_accuracy: 0.8767\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8027 - accuracy: 0.8230 - val_loss: 0.3751 - val_accuracy: 0.8733\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 924us/step - loss: 0.7415 - accuracy: 0.8529 - val_loss: 0.4194 - val_accuracy: 0.8483\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.7534 - accuracy: 0.8405 - val_loss: 0.3178 - val_accuracy: 0.8900\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7523 - accuracy: 0.8553 - val_loss: 0.4117 - val_accuracy: 0.8483\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8018 - accuracy: 0.8312 - val_loss: 0.4220 - val_accuracy: 0.8400\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7779 - accuracy: 0.8511 - val_loss: 0.4013 - val_accuracy: 0.8467\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7438 - accuracy: 0.8284 - val_loss: 0.3957 - val_accuracy: 0.8500\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6054 - accuracy: 0.8683 - val_loss: 0.4675 - val_accuracy: 0.8183\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 849us/step - loss: 0.6561 - accuracy: 0.8685 - val_loss: 0.4156 - val_accuracy: 0.8150\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4741 - accuracy: 0.5638 - val_loss: 0.8048 - val_accuracy: 0.5617\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 1.1844 - accuracy: 0.6216 - val_loss: 0.4736 - val_accuracy: 0.8100\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.9948 - accuracy: 0.7378 - val_loss: 0.5713 - val_accuracy: 0.7550\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 1.0109 - accuracy: 0.7516 - val_loss: 0.4787 - val_accuracy: 0.7850\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 989us/step - loss: 1.0441 - accuracy: 0.7380 - val_loss: 0.4458 - val_accuracy: 0.8033\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 951us/step - loss: 0.9506 - accuracy: 0.7772 - val_loss: 0.5857 - val_accuracy: 0.7233\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9412 - accuracy: 0.7476 - val_loss: 0.5540 - val_accuracy: 0.7700\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.9621 - accuracy: 0.7606 - val_loss: 0.5409 - val_accuracy: 0.7483\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8840 - accuracy: 0.7990 - val_loss: 0.4681 - val_accuracy: 0.8317\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9773 - accuracy: 0.7876 - val_loss: 0.4102 - val_accuracy: 0.8417\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.9190 - accuracy: 0.7968 - val_loss: 0.4140 - val_accuracy: 0.8483\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 1.0159 - accuracy: 0.7988 - val_loss: 0.3700 - val_accuracy: 0.8533\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.8118 - accuracy: 0.8378 - val_loss: 0.5555 - val_accuracy: 0.7733\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.8661 - accuracy: 0.7845 - val_loss: 0.4037 - val_accuracy: 0.8483\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8650 - accuracy: 0.8048 - val_loss: 0.4287 - val_accuracy: 0.8433\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8381 - accuracy: 0.8298 - val_loss: 0.4297 - val_accuracy: 0.8250\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 864us/step - loss: 0.8214 - accuracy: 0.8218 - val_loss: 0.4711 - val_accuracy: 0.7917\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8112 - accuracy: 0.8089 - val_loss: 0.4194 - val_accuracy: 0.8250\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7347 - accuracy: 0.8378 - val_loss: 0.4645 - val_accuracy: 0.8050\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 847us/step - loss: 0.8425 - accuracy: 0.8002 - val_loss: 0.4033 - val_accuracy: 0.8367\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7717 - accuracy: 0.8399 - val_loss: 0.4117 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6845 - accuracy: 0.8580 - val_loss: 0.4667 - val_accuracy: 0.8183\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7183 - accuracy: 0.8451 - val_loss: 0.3730 - val_accuracy: 0.8683\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8764 - accuracy: 0.8203 - val_loss: 0.3288 - val_accuracy: 0.8867\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7581 - accuracy: 0.8419 - val_loss: 0.4402 - val_accuracy: 0.8383\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7354 - accuracy: 0.8213 - val_loss: 0.4147 - val_accuracy: 0.8450\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7825 - accuracy: 0.8364 - val_loss: 0.4024 - val_accuracy: 0.8517\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7457 - accuracy: 0.8433 - val_loss: 0.4774 - val_accuracy: 0.7900\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7349 - accuracy: 0.8341 - val_loss: 0.4773 - val_accuracy: 0.7767\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8104 - accuracy: 0.8026 - val_loss: 0.3766 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6992 - accuracy: 0.8642 - val_loss: 0.3342 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7056 - accuracy: 0.8416 - val_loss: 0.4365 - val_accuracy: 0.8317\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.7066 - accuracy: 0.8538 - val_loss: 0.4224 - val_accuracy: 0.8567\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7401 - accuracy: 0.8516 - val_loss: 0.3794 - val_accuracy: 0.8567\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7679 - accuracy: 0.8491 - val_loss: 0.2920 - val_accuracy: 0.9133\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5932 - accuracy: 0.8829 - val_loss: 0.3295 - val_accuracy: 0.8883\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7164 - accuracy: 0.8602 - val_loss: 0.4078 - val_accuracy: 0.8317\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6604 - accuracy: 0.8654 - val_loss: 0.4323 - val_accuracy: 0.8300\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 865us/step - loss: 0.6423 - accuracy: 0.8549 - val_loss: 0.3374 - val_accuracy: 0.8783\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7295 - accuracy: 0.8502 - val_loss: 0.3507 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.8073 - accuracy: 0.8474 - val_loss: 0.3510 - val_accuracy: 0.8717\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.6745 - accuracy: 0.8705 - val_loss: 0.3320 - val_accuracy: 0.8867\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6176 - accuracy: 0.8738 - val_loss: 0.3558 - val_accuracy: 0.8733\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6607 - accuracy: 0.8663 - val_loss: 0.5291 - val_accuracy: 0.7367\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5818 - accuracy: 0.8534 - val_loss: 0.3531 - val_accuracy: 0.8717\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7851 - accuracy: 0.8494 - val_loss: 0.3476 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6511 - accuracy: 0.8577 - val_loss: 0.3187 - val_accuracy: 0.8783\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5862 - accuracy: 0.8819 - val_loss: 0.3503 - val_accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5544 - accuracy: 0.8857 - val_loss: 0.4896 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6942 - accuracy: 0.8353 - val_loss: 0.2971 - val_accuracy: 0.8833\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6040 - accuracy: 0.8659 - val_loss: 0.3091 - val_accuracy: 0.8900\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6409 - accuracy: 0.8698 - val_loss: 0.3724 - val_accuracy: 0.8467\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5900 - accuracy: 0.8539 - val_loss: 0.4730 - val_accuracy: 0.7633\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.6467 - accuracy: 0.8482 - val_loss: 0.3227 - val_accuracy: 0.8683\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6913 - accuracy: 0.8557 - val_loss: 0.3558 - val_accuracy: 0.8667\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 2ms/step - loss: 1.4783 - accuracy: 0.5703 - val_loss: 0.6153 - val_accuracy: 0.6717\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 1.1342 - accuracy: 0.6384 - val_loss: 0.5898 - val_accuracy: 0.7017\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 1.1001 - accuracy: 0.6904 - val_loss: 0.5928 - val_accuracy: 0.7133\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.9404 - accuracy: 0.7475 - val_loss: 0.5024 - val_accuracy: 0.7933\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 882us/step - loss: 1.0018 - accuracy: 0.7400 - val_loss: 0.6054 - val_accuracy: 0.7100\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 1.0269 - accuracy: 0.7480 - val_loss: 0.5449 - val_accuracy: 0.7650\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.8914 - accuracy: 0.7772 - val_loss: 0.3977 - val_accuracy: 0.8400\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.9054 - accuracy: 0.7836 - val_loss: 0.5427 - val_accuracy: 0.7917\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8984 - accuracy: 0.7922 - val_loss: 0.4916 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.8771 - accuracy: 0.8030 - val_loss: 0.4493 - val_accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.8736 - accuracy: 0.7885 - val_loss: 0.4360 - val_accuracy: 0.8233\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.8961 - accuracy: 0.7914 - val_loss: 0.4257 - val_accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7807 - accuracy: 0.8173 - val_loss: 0.4228 - val_accuracy: 0.8350\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7974 - accuracy: 0.8238 - val_loss: 0.4593 - val_accuracy: 0.8117\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8091 - accuracy: 0.8094 - val_loss: 0.4638 - val_accuracy: 0.7983\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8033 - accuracy: 0.8178 - val_loss: 0.3357 - val_accuracy: 0.8783\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7834 - accuracy: 0.8397 - val_loss: 0.4543 - val_accuracy: 0.8083\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7967 - accuracy: 0.8289 - val_loss: 0.5676 - val_accuracy: 0.7600\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.7989 - accuracy: 0.8252 - val_loss: 0.4338 - val_accuracy: 0.8167\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7626 - accuracy: 0.8310 - val_loss: 0.3694 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.8758 - accuracy: 0.8027 - val_loss: 0.3258 - val_accuracy: 0.8817\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.7747 - accuracy: 0.8269 - val_loss: 0.3955 - val_accuracy: 0.8383\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8496 - accuracy: 0.8162 - val_loss: 0.3425 - val_accuracy: 0.8783\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7546 - accuracy: 0.8436 - val_loss: 0.3813 - val_accuracy: 0.8417\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7375 - accuracy: 0.8397 - val_loss: 0.3541 - val_accuracy: 0.8650\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7378 - accuracy: 0.8418 - val_loss: 0.3789 - val_accuracy: 0.8617\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8080 - accuracy: 0.8281 - val_loss: 0.3457 - val_accuracy: 0.8833\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7769 - accuracy: 0.8265 - val_loss: 0.3193 - val_accuracy: 0.8883\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7658 - accuracy: 0.8281 - val_loss: 0.4306 - val_accuracy: 0.8433\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7690 - accuracy: 0.8128 - val_loss: 0.4296 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.7192 - accuracy: 0.8372 - val_loss: 0.5015 - val_accuracy: 0.7917\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7994 - accuracy: 0.8099 - val_loss: 0.4373 - val_accuracy: 0.7867\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6995 - accuracy: 0.8394 - val_loss: 0.4048 - val_accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8626 - accuracy: 0.8021 - val_loss: 0.3710 - val_accuracy: 0.8650\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7070 - accuracy: 0.8483 - val_loss: 0.4474 - val_accuracy: 0.8183\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.6934 - accuracy: 0.8379 - val_loss: 0.4688 - val_accuracy: 0.7950\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.7791 - accuracy: 0.8151 - val_loss: 0.3594 - val_accuracy: 0.8700\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7724 - accuracy: 0.8356 - val_loss: 0.4424 - val_accuracy: 0.8017\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6246 - accuracy: 0.8550 - val_loss: 0.3120 - val_accuracy: 0.8917\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6725 - accuracy: 0.8554 - val_loss: 0.2969 - val_accuracy: 0.8933\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6764 - accuracy: 0.8613 - val_loss: 0.3768 - val_accuracy: 0.8633\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 839us/step - loss: 0.6435 - accuracy: 0.8547 - val_loss: 0.3708 - val_accuracy: 0.8550\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.6240 - accuracy: 0.8479 - val_loss: 0.3824 - val_accuracy: 0.8567\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7360 - accuracy: 0.8452 - val_loss: 0.3963 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 0.6470 - accuracy: 0.8667 - val_loss: 0.3372 - val_accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5779 - accuracy: 0.8652 - val_loss: 0.4019 - val_accuracy: 0.8300\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.5784 - accuracy: 0.8479 - val_loss: 0.4082 - val_accuracy: 0.8400\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7260 - accuracy: 0.8172 - val_loss: 0.4386 - val_accuracy: 0.8117\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6503 - accuracy: 0.8439 - val_loss: 0.3662 - val_accuracy: 0.8383\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6630 - accuracy: 0.8457 - val_loss: 0.3062 - val_accuracy: 0.8867\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.5611 - accuracy: 0.8869 - val_loss: 0.3841 - val_accuracy: 0.8550\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 933us/step - loss: 0.5759 - accuracy: 0.8596 - val_loss: 0.5224 - val_accuracy: 0.7800\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.5985 - accuracy: 0.8566 - val_loss: 0.4438 - val_accuracy: 0.8217\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.6227 - accuracy: 0.8495 - val_loss: 0.3526 - val_accuracy: 0.8633\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7362 - accuracy: 0.8576 - val_loss: 0.4164 - val_accuracy: 0.8500\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.5357 - accuracy: 0.8721 - val_loss: 0.3844 - val_accuracy: 0.8633\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.5550 - accuracy: 0.8689 - val_loss: 0.5650 - val_accuracy: 0.7467\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6718 - accuracy: 0.8302 - val_loss: 0.3443 - val_accuracy: 0.8767\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 940us/step - loss: 0.5671 - accuracy: 0.8792 - val_loss: 0.3761 - val_accuracy: 0.8383\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6847 - accuracy: 0.8594 - val_loss: 0.3938 - val_accuracy: 0.8467\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4753 - accuracy: 0.5125 - val_loss: 0.6636 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 939us/step - loss: 1.1375 - accuracy: 0.6472 - val_loss: 0.6311 - val_accuracy: 0.6683\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 1.0280 - accuracy: 0.7213 - val_loss: 0.5284 - val_accuracy: 0.7733\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.9831 - accuracy: 0.7416 - val_loss: 0.5745 - val_accuracy: 0.7633\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.9558 - accuracy: 0.7472 - val_loss: 0.5263 - val_accuracy: 0.7750\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 1.0211 - accuracy: 0.7412 - val_loss: 0.4919 - val_accuracy: 0.8017\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.9696 - accuracy: 0.7718 - val_loss: 0.5058 - val_accuracy: 0.7717\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.9020 - accuracy: 0.7971 - val_loss: 0.5591 - val_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 0.8868 - accuracy: 0.7814 - val_loss: 0.5998 - val_accuracy: 0.7150\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.8652 - accuracy: 0.7869 - val_loss: 0.4413 - val_accuracy: 0.8433\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.8585 - accuracy: 0.8085 - val_loss: 0.4730 - val_accuracy: 0.7883\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.8006 - accuracy: 0.8128 - val_loss: 0.4482 - val_accuracy: 0.8183\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.8013 - accuracy: 0.8109 - val_loss: 0.6061 - val_accuracy: 0.6883\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.9141 - accuracy: 0.7528 - val_loss: 0.3776 - val_accuracy: 0.8600\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8596 - accuracy: 0.8163 - val_loss: 0.3830 - val_accuracy: 0.8683\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7994 - accuracy: 0.8329 - val_loss: 0.3809 - val_accuracy: 0.8767\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7601 - accuracy: 0.8493 - val_loss: 0.5406 - val_accuracy: 0.7400\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7631 - accuracy: 0.8251 - val_loss: 0.4931 - val_accuracy: 0.7833\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9044 - accuracy: 0.7613 - val_loss: 0.4248 - val_accuracy: 0.8433\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.8098 - accuracy: 0.8273 - val_loss: 0.4454 - val_accuracy: 0.8250\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7329 - accuracy: 0.8455 - val_loss: 0.3963 - val_accuracy: 0.8400\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.8389 - accuracy: 0.8318 - val_loss: 0.4116 - val_accuracy: 0.8350\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7575 - accuracy: 0.8336 - val_loss: 0.4713 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7487 - accuracy: 0.8381 - val_loss: 0.4404 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.7712 - accuracy: 0.8285 - val_loss: 0.3864 - val_accuracy: 0.8483\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 891us/step - loss: 0.9046 - accuracy: 0.8281 - val_loss: 0.3379 - val_accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7782 - accuracy: 0.8165 - val_loss: 0.3994 - val_accuracy: 0.8583\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.7168 - accuracy: 0.8529 - val_loss: 0.4204 - val_accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7270 - accuracy: 0.8637 - val_loss: 0.4564 - val_accuracy: 0.7850\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.7612 - accuracy: 0.8260 - val_loss: 0.3497 - val_accuracy: 0.8633\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7269 - accuracy: 0.8528 - val_loss: 0.4366 - val_accuracy: 0.7967\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7042 - accuracy: 0.8476 - val_loss: 0.5942 - val_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.6433 - accuracy: 0.8452 - val_loss: 0.4122 - val_accuracy: 0.8233\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.6891 - accuracy: 0.8607 - val_loss: 0.3936 - val_accuracy: 0.8283\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7908 - accuracy: 0.8412 - val_loss: 0.3538 - val_accuracy: 0.8600\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6702 - accuracy: 0.8462 - val_loss: 0.3819 - val_accuracy: 0.8400\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7079 - accuracy: 0.8503 - val_loss: 0.5716 - val_accuracy: 0.7033\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6834 - accuracy: 0.8366 - val_loss: 0.5061 - val_accuracy: 0.7583\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.7411 - accuracy: 0.8310 - val_loss: 0.3278 - val_accuracy: 0.8783\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6823 - accuracy: 0.8575 - val_loss: 0.4007 - val_accuracy: 0.8350\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 983us/step - loss: 0.7739 - accuracy: 0.8338 - val_loss: 0.3881 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 974us/step - loss: 0.7407 - accuracy: 0.8433 - val_loss: 0.5010 - val_accuracy: 0.7950\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6909 - accuracy: 0.8210 - val_loss: 0.3022 - val_accuracy: 0.8850\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.6860 - accuracy: 0.8412 - val_loss: 0.3708 - val_accuracy: 0.8483\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6239 - accuracy: 0.8696 - val_loss: 0.3395 - val_accuracy: 0.8800\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.6652 - accuracy: 0.8600 - val_loss: 0.4633 - val_accuracy: 0.8233\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7457 - accuracy: 0.8304 - val_loss: 0.3653 - val_accuracy: 0.8550\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6612 - accuracy: 0.8496 - val_loss: 0.5043 - val_accuracy: 0.7983\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.6716 - accuracy: 0.8365 - val_loss: 0.3740 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7632 - accuracy: 0.8482 - val_loss: 0.3084 - val_accuracy: 0.8867\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7019 - accuracy: 0.8741 - val_loss: 0.4608 - val_accuracy: 0.7817\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6816 - accuracy: 0.8590 - val_loss: 0.4941 - val_accuracy: 0.7750\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 907us/step - loss: 0.7215 - accuracy: 0.8288 - val_loss: 0.3456 - val_accuracy: 0.8617\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 880us/step - loss: 0.6190 - accuracy: 0.8721 - val_loss: 0.4117 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 889us/step - loss: 0.5746 - accuracy: 0.8676 - val_loss: 0.3746 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.6408 - accuracy: 0.8465 - val_loss: 0.3643 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7070 - accuracy: 0.8422 - val_loss: 0.3420 - val_accuracy: 0.8550\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5610 - accuracy: 0.8756 - val_loss: 0.3905 - val_accuracy: 0.8283\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7031 - accuracy: 0.8444 - val_loss: 0.5437 - val_accuracy: 0.7633\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 906us/step - loss: 0.6639 - accuracy: 0.8553 - val_loss: 0.4056 - val_accuracy: 0.8367\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6036 - accuracy: 0.8672 - val_loss: 0.3514 - val_accuracy: 0.8550\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6401 - accuracy: 0.8522 - val_loss: 0.4164 - val_accuracy: 0.8367\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 918us/step - loss: 0.5207 - accuracy: 0.8815 - val_loss: 0.4862 - val_accuracy: 0.8217\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.4234 - accuracy: 0.5513 - val_loss: 0.5541 - val_accuracy: 0.7267\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 1.0588 - accuracy: 0.7116 - val_loss: 0.5966 - val_accuracy: 0.7250\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 843us/step - loss: 1.0424 - accuracy: 0.7156 - val_loss: 0.5530 - val_accuracy: 0.7433\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.9811 - accuracy: 0.7549 - val_loss: 0.6281 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9405 - accuracy: 0.7519 - val_loss: 0.4498 - val_accuracy: 0.8167\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.9486 - accuracy: 0.7889 - val_loss: 0.4942 - val_accuracy: 0.8067\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.9425 - accuracy: 0.7676 - val_loss: 0.4966 - val_accuracy: 0.7917\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.9497 - accuracy: 0.7784 - val_loss: 0.5639 - val_accuracy: 0.7200\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 846us/step - loss: 0.8586 - accuracy: 0.8068 - val_loss: 0.4529 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8652 - accuracy: 0.7987 - val_loss: 0.5029 - val_accuracy: 0.7950\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 822us/step - loss: 0.8248 - accuracy: 0.8063 - val_loss: 0.5791 - val_accuracy: 0.7417\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 801us/step - loss: 0.8246 - accuracy: 0.7926 - val_loss: 0.5768 - val_accuracy: 0.6867\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.8246 - accuracy: 0.7833 - val_loss: 0.4375 - val_accuracy: 0.8383\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8903 - accuracy: 0.8040 - val_loss: 0.4458 - val_accuracy: 0.8533\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.8511 - accuracy: 0.8282 - val_loss: 0.5458 - val_accuracy: 0.8017\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8352 - accuracy: 0.8198 - val_loss: 0.4716 - val_accuracy: 0.8317\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8196 - accuracy: 0.8248 - val_loss: 0.3852 - val_accuracy: 0.8800\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 825us/step - loss: 0.7723 - accuracy: 0.8432 - val_loss: 0.4295 - val_accuracy: 0.8317\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 819us/step - loss: 0.7558 - accuracy: 0.8456 - val_loss: 0.4579 - val_accuracy: 0.8050\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7410 - accuracy: 0.8260 - val_loss: 0.4582 - val_accuracy: 0.8100\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8295 - accuracy: 0.8222 - val_loss: 0.3474 - val_accuracy: 0.8650\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.8303 - accuracy: 0.8233 - val_loss: 0.3950 - val_accuracy: 0.8383\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 910us/step - loss: 0.8976 - accuracy: 0.8330 - val_loss: 0.5354 - val_accuracy: 0.7300\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8636 - accuracy: 0.7845 - val_loss: 0.4430 - val_accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.7292 - accuracy: 0.8461 - val_loss: 0.3706 - val_accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 841us/step - loss: 0.7660 - accuracy: 0.8456 - val_loss: 0.3490 - val_accuracy: 0.8783\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.8222 - accuracy: 0.8402 - val_loss: 0.3418 - val_accuracy: 0.8733\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 1ms/step - loss: 0.7738 - accuracy: 0.8434 - val_loss: 0.6350 - val_accuracy: 0.6600\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.7988 - accuracy: 0.8210 - val_loss: 0.3555 - val_accuracy: 0.8800\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 835us/step - loss: 0.7241 - accuracy: 0.8571 - val_loss: 0.3555 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.8409 - accuracy: 0.8388 - val_loss: 0.3809 - val_accuracy: 0.8550\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 828us/step - loss: 0.7379 - accuracy: 0.8503 - val_loss: 0.3722 - val_accuracy: 0.8683\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.7284 - accuracy: 0.8553 - val_loss: 0.4145 - val_accuracy: 0.8233\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 923us/step - loss: 0.6762 - accuracy: 0.8528 - val_loss: 0.3818 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7509 - accuracy: 0.8598 - val_loss: 0.3133 - val_accuracy: 0.8983\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7573 - accuracy: 0.8514 - val_loss: 0.3024 - val_accuracy: 0.8900\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.6908 - accuracy: 0.8530 - val_loss: 0.3625 - val_accuracy: 0.8683\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.6961 - accuracy: 0.8547 - val_loss: 0.3764 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6548 - accuracy: 0.8562 - val_loss: 0.3420 - val_accuracy: 0.8683\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6748 - accuracy: 0.8604 - val_loss: 0.3369 - val_accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.6639 - accuracy: 0.8396 - val_loss: 0.3499 - val_accuracy: 0.8650\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.6779 - accuracy: 0.8537 - val_loss: 0.3522 - val_accuracy: 0.8833\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.5698 - accuracy: 0.8867 - val_loss: 0.3665 - val_accuracy: 0.8567\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.7555 - accuracy: 0.8646 - val_loss: 0.3154 - val_accuracy: 0.8783\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.5888 - accuracy: 0.8660 - val_loss: 0.3662 - val_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5923 - accuracy: 0.8611 - val_loss: 0.3261 - val_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6883 - accuracy: 0.8442 - val_loss: 0.3162 - val_accuracy: 0.8700\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7059 - accuracy: 0.8602 - val_loss: 0.4092 - val_accuracy: 0.8183\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6967 - accuracy: 0.8496 - val_loss: 0.3870 - val_accuracy: 0.8233\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6967 - accuracy: 0.8391 - val_loss: 0.3512 - val_accuracy: 0.8650\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.6178 - accuracy: 0.8604 - val_loss: 0.3773 - val_accuracy: 0.8567\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7432 - accuracy: 0.8440 - val_loss: 0.3902 - val_accuracy: 0.8150\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5666 - accuracy: 0.8714 - val_loss: 0.4194 - val_accuracy: 0.8283\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.5362 - accuracy: 0.8624 - val_loss: 0.3416 - val_accuracy: 0.8683\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.7635 - accuracy: 0.8368 - val_loss: 0.4527 - val_accuracy: 0.8133\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6025 - accuracy: 0.8696 - val_loss: 0.3306 - val_accuracy: 0.8667\n",
      "Epoch 1/100\n",
      "342/342 [==============================] - 1s 1ms/step - loss: 1.3931 - accuracy: 0.5363 - val_loss: 0.6343 - val_accuracy: 0.6650\n",
      "Epoch 2/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 1.0345 - accuracy: 0.6979 - val_loss: 0.5893 - val_accuracy: 0.6983\n",
      "Epoch 3/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 1.0004 - accuracy: 0.7146 - val_loss: 0.6005 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.9094 - accuracy: 0.7393 - val_loss: 0.4774 - val_accuracy: 0.8017\n",
      "Epoch 5/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 1.0281 - accuracy: 0.7331 - val_loss: 0.5059 - val_accuracy: 0.7833\n",
      "Epoch 6/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.9724 - accuracy: 0.7508 - val_loss: 0.5472 - val_accuracy: 0.7533\n",
      "Epoch 7/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.9928 - accuracy: 0.7390 - val_loss: 0.4472 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "342/342 [==============================] - 0s 857us/step - loss: 0.9675 - accuracy: 0.7720 - val_loss: 0.4892 - val_accuracy: 0.8067\n",
      "Epoch 9/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.9325 - accuracy: 0.7863 - val_loss: 0.4908 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8756 - accuracy: 0.7792 - val_loss: 0.4147 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.8887 - accuracy: 0.7968 - val_loss: 0.3999 - val_accuracy: 0.8367\n",
      "Epoch 12/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.9517 - accuracy: 0.7862 - val_loss: 0.4782 - val_accuracy: 0.8033\n",
      "Epoch 13/100\n",
      "342/342 [==============================] - 0s 892us/step - loss: 0.9447 - accuracy: 0.7773 - val_loss: 0.4856 - val_accuracy: 0.8033\n",
      "Epoch 14/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.8232 - accuracy: 0.8185 - val_loss: 0.4635 - val_accuracy: 0.8167\n",
      "Epoch 15/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.7883 - accuracy: 0.8250 - val_loss: 0.4911 - val_accuracy: 0.7867\n",
      "Epoch 16/100\n",
      "342/342 [==============================] - 0s 852us/step - loss: 0.8504 - accuracy: 0.8132 - val_loss: 0.3890 - val_accuracy: 0.8450\n",
      "Epoch 17/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.9111 - accuracy: 0.8101 - val_loss: 0.4761 - val_accuracy: 0.8117\n",
      "Epoch 18/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.7687 - accuracy: 0.8250 - val_loss: 0.4309 - val_accuracy: 0.8400\n",
      "Epoch 19/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.8027 - accuracy: 0.8313 - val_loss: 0.5045 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7728 - accuracy: 0.8183 - val_loss: 0.4512 - val_accuracy: 0.8100\n",
      "Epoch 21/100\n",
      "342/342 [==============================] - 0s 953us/step - loss: 0.8417 - accuracy: 0.8089 - val_loss: 0.3784 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "342/342 [==============================] - 0s 956us/step - loss: 0.7931 - accuracy: 0.8348 - val_loss: 0.4237 - val_accuracy: 0.8417\n",
      "Epoch 23/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.7662 - accuracy: 0.8364 - val_loss: 0.4381 - val_accuracy: 0.8067\n",
      "Epoch 24/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.7477 - accuracy: 0.8451 - val_loss: 0.3860 - val_accuracy: 0.8517\n",
      "Epoch 25/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7431 - accuracy: 0.8365 - val_loss: 0.4930 - val_accuracy: 0.8083\n",
      "Epoch 26/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.7347 - accuracy: 0.8258 - val_loss: 0.4613 - val_accuracy: 0.8033\n",
      "Epoch 27/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.7741 - accuracy: 0.8237 - val_loss: 0.5652 - val_accuracy: 0.7517\n",
      "Epoch 28/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7830 - accuracy: 0.8199 - val_loss: 0.3473 - val_accuracy: 0.8850\n",
      "Epoch 29/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.7093 - accuracy: 0.8542 - val_loss: 0.3501 - val_accuracy: 0.8633\n",
      "Epoch 30/100\n",
      "342/342 [==============================] - 0s 883us/step - loss: 0.7089 - accuracy: 0.8439 - val_loss: 0.4099 - val_accuracy: 0.8317\n",
      "Epoch 31/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7361 - accuracy: 0.8296 - val_loss: 0.5272 - val_accuracy: 0.7533\n",
      "Epoch 32/100\n",
      "342/342 [==============================] - 0s 875us/step - loss: 0.6979 - accuracy: 0.8413 - val_loss: 0.3799 - val_accuracy: 0.8467\n",
      "Epoch 33/100\n",
      "342/342 [==============================] - 0s 895us/step - loss: 0.6122 - accuracy: 0.8688 - val_loss: 0.4526 - val_accuracy: 0.7950\n",
      "Epoch 34/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.7252 - accuracy: 0.8400 - val_loss: 0.3650 - val_accuracy: 0.8617\n",
      "Epoch 35/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.7700 - accuracy: 0.8267 - val_loss: 0.3502 - val_accuracy: 0.8517\n",
      "Epoch 36/100\n",
      "342/342 [==============================] - 0s 876us/step - loss: 0.6812 - accuracy: 0.8494 - val_loss: 0.3776 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "342/342 [==============================] - 0s 886us/step - loss: 0.6986 - accuracy: 0.8512 - val_loss: 0.3830 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "342/342 [==============================] - 0s 872us/step - loss: 0.7550 - accuracy: 0.8405 - val_loss: 0.5107 - val_accuracy: 0.7617\n",
      "Epoch 39/100\n",
      "342/342 [==============================] - 0s 870us/step - loss: 0.6618 - accuracy: 0.8234 - val_loss: 0.2859 - val_accuracy: 0.8900\n",
      "Epoch 40/100\n",
      "342/342 [==============================] - 0s 884us/step - loss: 0.6113 - accuracy: 0.8738 - val_loss: 0.4611 - val_accuracy: 0.8067\n",
      "Epoch 41/100\n",
      "342/342 [==============================] - 0s 831us/step - loss: 0.7309 - accuracy: 0.8331 - val_loss: 0.4709 - val_accuracy: 0.8083\n",
      "Epoch 42/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.6876 - accuracy: 0.8331 - val_loss: 0.3165 - val_accuracy: 0.8717\n",
      "Epoch 43/100\n",
      "342/342 [==============================] - 0s 945us/step - loss: 0.6952 - accuracy: 0.8533 - val_loss: 0.4088 - val_accuracy: 0.8433\n",
      "Epoch 44/100\n",
      "342/342 [==============================] - 0s 834us/step - loss: 0.6676 - accuracy: 0.8471 - val_loss: 0.3637 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "342/342 [==============================] - 0s 837us/step - loss: 0.6760 - accuracy: 0.8577 - val_loss: 0.3390 - val_accuracy: 0.8683\n",
      "Epoch 46/100\n",
      "342/342 [==============================] - 0s 854us/step - loss: 0.5207 - accuracy: 0.8853 - val_loss: 0.4580 - val_accuracy: 0.7783\n",
      "Epoch 47/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.7281 - accuracy: 0.8231 - val_loss: 0.2537 - val_accuracy: 0.9117\n",
      "Epoch 48/100\n",
      "342/342 [==============================] - 0s 848us/step - loss: 0.6274 - accuracy: 0.8936 - val_loss: 0.2875 - val_accuracy: 0.9017\n",
      "Epoch 49/100\n",
      "342/342 [==============================] - 0s 851us/step - loss: 0.5822 - accuracy: 0.8730 - val_loss: 0.3130 - val_accuracy: 0.8867\n",
      "Epoch 50/100\n",
      "342/342 [==============================] - 0s 861us/step - loss: 0.6246 - accuracy: 0.8577 - val_loss: 0.3338 - val_accuracy: 0.8700\n",
      "Epoch 51/100\n",
      "342/342 [==============================] - 0s 836us/step - loss: 0.6456 - accuracy: 0.8638 - val_loss: 0.3960 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "342/342 [==============================] - 0s 845us/step - loss: 0.6714 - accuracy: 0.8540 - val_loss: 0.3486 - val_accuracy: 0.8600\n",
      "Epoch 53/100\n",
      "342/342 [==============================] - 0s 874us/step - loss: 0.5515 - accuracy: 0.8793 - val_loss: 0.4558 - val_accuracy: 0.8033\n",
      "Epoch 54/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5931 - accuracy: 0.8532 - val_loss: 0.3246 - val_accuracy: 0.8717\n",
      "Epoch 55/100\n",
      "342/342 [==============================] - 0s 898us/step - loss: 0.7101 - accuracy: 0.8466 - val_loss: 0.3924 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6085 - accuracy: 0.8754 - val_loss: 0.3907 - val_accuracy: 0.8450\n",
      "Epoch 57/100\n",
      "342/342 [==============================] - 0s 901us/step - loss: 0.5863 - accuracy: 0.8588 - val_loss: 0.3112 - val_accuracy: 0.8967\n",
      "Epoch 58/100\n",
      "342/342 [==============================] - 0s 866us/step - loss: 0.6383 - accuracy: 0.8853 - val_loss: 0.4132 - val_accuracy: 0.8383\n",
      "Epoch 59/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5809 - accuracy: 0.8812 - val_loss: 0.3920 - val_accuracy: 0.8183\n",
      "Epoch 60/100\n",
      "342/342 [==============================] - 0s 877us/step - loss: 0.5639 - accuracy: 0.8722 - val_loss: 0.5409 - val_accuracy: 0.7817\n",
      "Epoch 61/100\n",
      "342/342 [==============================] - 0s 869us/step - loss: 0.6099 - accuracy: 0.8673 - val_loss: 0.5716 - val_accuracy: 0.7633\n",
      "Epoch 62/100\n",
      "342/342 [==============================] - 0s 860us/step - loss: 0.5628 - accuracy: 0.8592 - val_loss: 0.4156 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "342/342 [==============================] - 0s 863us/step - loss: 0.5499 - accuracy: 0.8692 - val_loss: 0.3421 - val_accuracy: 0.8717\n",
      "Epoch 64/100\n",
      "342/342 [==============================] - 0s 913us/step - loss: 0.6176 - accuracy: 0.8782 - val_loss: 0.3319 - val_accuracy: 0.8650\n",
      "Epoch 65/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.5159 - accuracy: 0.8920 - val_loss: 0.3771 - val_accuracy: 0.8383\n",
      "Epoch 66/100\n",
      "342/342 [==============================] - 0s 842us/step - loss: 0.6041 - accuracy: 0.8685 - val_loss: 0.4526 - val_accuracy: 0.8350\n",
      "Epoch 67/100\n",
      "342/342 [==============================] - 0s 904us/step - loss: 0.5894 - accuracy: 0.8672 - val_loss: 0.3321 - val_accuracy: 0.8683\n"
     ]
    }
   ],
   "source": [
    "#Set class weights\n",
    "train_acc_master = []\n",
    "train_recall_master = []\n",
    "train_prec_master = []\n",
    "\n",
    "test_acc_master = []\n",
    "test_recall_master = []\n",
    "test_prec_master = []\n",
    "\n",
    "for x in range(6,12):\n",
    "    print(x)\n",
    "    class_weight = {0: 1.,\n",
    "                    1: x }\n",
    "\n",
    "    #Create empty arrays to hold metrics\n",
    "    train_accuracy_array_2 = []\n",
    "    train_recall_array_2 = []\n",
    "    train_precision_array_2 = []\n",
    "\n",
    "    test_accuracy_array_2 = []\n",
    "    test_recall_array_2 = []\n",
    "    test_precision_array_2 = []\n",
    "\n",
    "\n",
    "    for i in range(0,20):\n",
    "        #Create function to build model\n",
    "        def build_model_2(n_hidden=3, n_neurons = 30, learn=3e-3, dropout_rate=0.04):\n",
    "            model = keras.models.Sequential()\n",
    "            model.add(keras.layers.InputLayer(input_shape=[18]))\n",
    "            for layer in range(n_hidden):\n",
    "                model.add(keras.layers.Dropout(dropout_rate))\n",
    "                model.add(keras.layers.Dense(n_neurons, activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "            model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "            opt = keras.optimizers.Nadam(learning_rate=learn)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "\n",
    "        #Create Keras regressor based on this build\n",
    "        keras_classifier_2 = keras.wrappers.scikit_learn.KerasRegressor(build_model_2)\n",
    "        early_stopping = EarlyStopping(patience = 20, restore_best_weights=True)\n",
    "        model_2 = keras_classifier_2.fit(xTrain, yTrain, epochs=100, batch_size=8,validation_data=(xTest, yTest),callbacks=[early_stopping],class_weight=class_weight)\n",
    "\n",
    "        #get predictions for xtrain and x test\n",
    "        y_pred_train_2 = keras_classifier_2.predict(xTrain)\n",
    "        y_pred_test_2 = keras_classifier_2.predict(xTest)\n",
    "\n",
    "        #Get metrics\n",
    "        train_acc_2 = accuracy_score(yTrain , np.rint(y_pred_train_2))*100\n",
    "        train_recall_2 = recall_score(yTrain , np.rint(y_pred_train_2))*100\n",
    "        train_prec_2 = precision_score(yTrain , np.rint(y_pred_train_2))*100\n",
    "\n",
    "        test_acc_2 = accuracy_score(yTest , np.rint(y_pred_test_2))*100\n",
    "        test_recall_2 = recall_score(yTest , np.rint(y_pred_test_2))*100\n",
    "        test_prec_2 = precision_score(yTest , np.rint(y_pred_test_2))*100\n",
    "\n",
    "        #Insert metrics into relevant arrays\n",
    "        train_accuracy_array_2.append(train_acc_2)\n",
    "        train_recall_array_2.append(train_recall_2)\n",
    "        train_precision_array_2.append(train_prec_2)\n",
    "\n",
    "        test_accuracy_array_2.append(test_acc_2)\n",
    "        test_recall_array_2.append(test_recall_2)\n",
    "        test_precision_array_2.append(test_prec_2)\n",
    "    \n",
    "    #Get mean value of each metric \n",
    "    train_mean_acc = avg_list(train_accuracy_array_2)\n",
    "    train_mean_recall = avg_list(train_recall_array_2)\n",
    "    train_mean_prec = avg_list(train_precision_array_2)\n",
    "    \n",
    "    test_mean_acc = avg_list(test_accuracy_array_2)\n",
    "    test_mean_recall = avg_list(test_recall_array_2)\n",
    "    test_mean_prec = avg_list(test_precision_array_2)\n",
    "    \n",
    "    #Insert mean values into master array\n",
    "    train_acc_master.append(train_mean_acc)\n",
    "    train_recall_master.append(train_mean_recall)\n",
    "    train_prec_master.append(train_mean_prec)\n",
    "\n",
    "    test_acc_master.append(test_mean_acc)\n",
    "    test_recall_master.append(test_mean_recall)\n",
    "    test_prec_master.append(test_mean_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1 Training Accuracy = 95.05122575923893\n",
      "1:1 Training Recall = 87.39185750636132\n",
      "1:1 Training Precision = 80.57199210614803\n",
      "1:1 Test Accuracy = 93.12500000000001\n",
      "1:1 Test Recall = 79.88888888888889\n",
      "1:1 Test Precision = 76.15818571972707\n",
      "\n",
      "\n",
      "1:2 Training Accuracy = 94.86644712769848\n",
      "1:2 Training Recall = 87.98982188295167\n",
      "1:2 Training Precision = 79.1077103698233\n",
      "1:2 Test Accuracy = 92.95833333333334\n",
      "1:2 Test Recall = 81.0\n",
      "1:2 Test Precision = 74.81599655062638\n",
      "\n",
      "\n",
      "1:3 Training Accuracy = 94.11452616172704\n",
      "1:3 Training Recall = 89.058524173028\n",
      "1:3 Training Precision = 75.09596792662505\n",
      "1:3 Test Accuracy = 92.15833333333333\n",
      "1:3 Test Recall = 81.33333333333333\n",
      "1:3 Test Precision = 71.09619468434752\n",
      "\n",
      "\n",
      "1:4 Training Accuracy = 93.38638858397364\n",
      "1:4 Training Recall = 90.45801526717558\n",
      "1:4 Training Precision = 71.708422317583\n",
      "1:4 Test Accuracy = 90.45000000000002\n",
      "1:4 Test Recall = 82.0\n",
      "1:4 Test Precision = 64.77076069143624\n",
      "\n",
      "\n",
      "1:5 Training Accuracy = 92.53018660812293\n",
      "1:5 Training Recall = 89.55470737913485\n",
      "1:5 Training Precision = 68.99570640696359\n",
      "1:5 Test Accuracy = 90.53333333333333\n",
      "1:5 Test Recall = 82.27777777777776\n",
      "1:5 Test Precision = 65.05066290702673\n",
      "\n",
      "\n",
      "1:6 Training Accuracy = 91.71789242590557\n",
      "1:6 Training Recall = 90.07633587786259\n",
      "1:6 Training Precision = 66.07824676976057\n",
      "1:6 Test Accuracy = 89.55833333333332\n",
      "1:6 Test Recall = 82.66666666666666\n",
      "1:6 Test Precision = 61.692787589857176\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(train_acc_master)+1):\n",
    "    x=i-1\n",
    "    print('1:' +str(i) +' Training Accuracy = ' + str(train_acc_master[x]))\n",
    "    print('1:' +str(i) +' Training Recall = ' + str(train_recall_master[x]))\n",
    "    print('1:' +str(i) +' Training Precision = ' + str(train_prec_master[x]))\n",
    "    print('1:' +str(i) +' Test Accuracy = ' + str(test_acc_master[x]))\n",
    "    print('1:' +str(i) +' Test Recall = ' + str(test_recall_master[x]))\n",
    "    print('1:' +str(i) +' Test Precision = ' + str(test_prec_master[x]))\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train accuracy: 91.71789242590557\n",
      "Mean train recall: 90.07633587786259\n",
      "Mean train precision: 66.07824676976057\n",
      "Mean test accuracy: 89.55833333333332\n",
      "Mean test recall: 82.66666666666666\n",
      "Mean test precision: 61.692787589857176\n"
     ]
    }
   ],
   "source": [
    "print('Mean train accuracy: ' + str(avg_list(train_accuracy_array_2)))\n",
    "print('Mean train recall: ' + str(avg_list(train_recall_array_2)))\n",
    "print('Mean train precision: ' + str(avg_list(train_precision_array_2)))\n",
    "\n",
    "print('Mean test accuracy: ' + str(avg_list(test_accuracy_array_2)))\n",
    "print('Mean test recall: ' + str(avg_list(test_recall_array_2)))\n",
    "print('Mean test precision: ' + str(avg_list(test_precision_array_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2210,  130],\n",
       "       [  30,  363]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 94.14562751555067\n",
      "Train recall: 0.9236641221374046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[474,  36],\n",
       "       [ 17,  73]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91.16666666666666\n",
      "Test recall: 0.8111111111111111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cc950b3fd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix for train\n",
    "y_pred_train = keras_classifier_2.predict(xTrain)\n",
    "confusion_matrix_train = sklearn.metrics.confusion_matrix(yTrain, np.rint(y_pred_train))\n",
    "confusion_matrix_train\n",
    "\n",
    "\n",
    "print('Train accuracy: ' + str(accuracy_score(yTrain , np.rint(y_pred_train))*100))\n",
    "print('Train recall: ' + str(recall_score(yTrain , np.rint(y_pred_train))))\n",
    "\n",
    "\n",
    "# Confusion matrix for test\n",
    "y_pred = keras_classifier_2.predict(xTest)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(yTest, np.rint(y_pred))\n",
    "confusion_matrix\n",
    "\n",
    "print('Test accuracy: ' + str(accuracy_score(yTest, np.rint(y_pred))*100))\n",
    "print('Test recall: ' + str(recall_score(yTest, np.rint(y_pred))))\n",
    "\n",
    "#Learning curves\n",
    "pd.DataFrame(model_2.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
